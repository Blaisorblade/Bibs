%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Paolo Giosu√© Giarrusso at 2016-03-24 11:12:29 +0100 


%% Saved with string encoding Unicode (UTF-8) 


@string{acm = {ACM}}

@string{acmaddr = {}}

@string{acp4is = {Proc.\ AOSD Workshop on Aspects, Components, and Patterns for Infrastructure Software (ACP4IS)}}

@string{addisonwesleylongman = {Addison-Wesley}}

@string{aosd = {AOSD}}

@string{apsec = {Proc.\ Asia-Pacific Software Engineering Conf.\ (APSEC)}}

@string{ase = {Proc.\ Int'l Conf.\ Automated Software Engineering (ASE)}}

@string{btw = {Proc.\ GI-Fachtagung Datenbanksysteme f{\"u}r Business, Technologie und Web (BTW)}}

@string{cacm = {Commun.\ ACM}}

@string{cambridge = {Cambridge University Press}}

@string{cc = {Proc.\ Int'l Conf.\ Compiler Construction (CC)}}

@string{ccpe = {Concurrency and Computation: Practice and Experience}}

@string{chi = {Proc.\ Conf.\ Human Factors in Computing Systems (CHI)}}

@string{cpe = {Biennal Conf. Innovative Data Systems Research}}

@string{csmr = {Proc.\ European Conf.\ on Software Maintenance and Reengineering (CSMR)}}

@string{csur = {ACM Computing Surveys (CSUR)}}

@string{diplomarbeit = {Master's Thesis ({Diplomarbeit})}}

@string{dsl = {DSL}}

@string{ecoop = {ECOOP}}

@string{elsevier = {Elsevier}}

@string{elsevieraddr = {Amsterdam}}

@string{esecfse = {Proc.\ Europ.\ Software Engineering Conf./Foundations of Software Engineering (ESEC/FSE)}}

@string{etx = {Proc.\ OOPSLA Workshop on Eclipse Technology eXchange (ETX)}}

@string{etxe = {Proc.\ ECOOP Workshop on Eclipse Technology eXchange (ETX)}}

@string{eurosys = {Proc.\ European Conference on Computer Systems (EuroSys)}}

@string{fase = {Proc.\ Int'l Conf.\ Fundamental Approaches to Software Engineering}}

@string{fosd = {Proc.\ GPCE Workshop on Feature-Oriented Software Development (FOSD)}}

@string{fpca = {FPCA}}

@string{fse = {Proc.\ Int'l Symposium Foundations of Software Engineering (FSE)}}

@string{gcse = {Proc.\ Int'l Conf.\ Generative and Component-Based Software Engineering (GCSE)}}

@string{gi = {Gesellschaft f{\"u}r Informatik (GI)}}

@string{giaddr = {Bonn}}

@string{gpce = {GPCE}}

@string{hosc = {HOSC}}

@string{icdcs = {Proc.\ Int'l Conf.\ Distributed Computing Systems (ICDCS)}}

@string{icfp = {ICFP}}

@string{icmt = {Proc.\ Int'l Conf.\ Theory and Practice of Model Transformations (ICMT)}}

@string{icpc = {Proc.\ Int'l Conf.\ Program Comprehension (ICPC)}}

@string{icre = {Proc.\ Int'l Conf.\ Requirements Engineering (ICRE)}}

@string{icse = {Proc.\ Int'l Conf.\ Software Engineering (ICSE)}}

@string{icsecomp = {Comp.\ Int'l Conf.\ Software Engineering (ICSE)}}

@string{icsm = {Proc.\ Int'l Conf.\ Software Maintenance (ICSM)}}

@string{icsr = {Proc.\ Int'l Conf.\ Software Reuse (ICSR)}}

@string{ieee = {IEEE Computer Society}}

@string{ieeeaddr = {Los Alamitos, CA}}

@string{ieeeaddrp = {Piscataway, NJ}}

@string{ieeeaddrw = {Washington, DC}}

@string{ieeesoftware = {IEEE Software}}

@string{infcomput = {Information and Computation}}

@string{ipdps = {Proc. Int'l. Parallel and Distributed Processing Symp.}}

@string{iwpc = {Proc.\ Int'l Workshop on Program Comprehension (IWPC)}}

@string{jase = {Automated Software Engineering}}

@string{jfp = {JFP}}

@string{jot = {Journal of Object Technology (JOT)}}

@string{kde = {IEEE Trans. Knowledge and Data Engineering}}

@string{kluwer = {Kluwer}}

@string{ldta = {Proc.\ Workshop on Language Descriptions, Tools and Applications (LDTA)}}

@string{lfp = {Proc.\ ACM Conf.\ on LISP and Functional Programming}}

@string{lnbip = {Lecture Notes in Business Information Processing}}

@string{lncs = {LNCS}}

@string{lzi = {Leibniz-Zentrum f{\"u}r Informatik (LZI)}}

@string{lziaddr = {Wadern}}

@string{macs = {Proc.\ ICSE Workshop on Modeling and Analysis of Concerns in Software (MACS)}}

@string{mdtech = {School of Computer Science, University of Magdeburg}}

@string{models = {Proc.\ Int'l Conf.\ Model Driven Engineering Languages and Systems (MoDELS)}}

@string{netobjectdays = {Proc. Int'l Conf.\ Object-Oriented and Internet-based Technologies, Concepts, and Applications for a Networked World (Net.ObjectDays)}}

@string{newyork = {New York}}

@string{oopsla = {OOPSLA}}

@string{oopslacomp = {Companion Int'l Conf.\ Object-Oriented Programming, Systems, Languages and Applications}}

@string{patech = {Department of Informatics and Mathematics, University of Passau}}

@string{pepm = {PEPM}}

@string{pldi = {PLDI}}

@string{plpv = {Programming Languages meets Program Verification}}

@string{popl = {POPL}}

@string{re = {Proc.\ Int'l Requirements Engineering Conf. (RE)}}

@string{sac = {Proc.\ Symp.\ Applied Computing (SAC)}}

@string{sc = {Proc.\ Int'l Conf.\ Software Composition (SC)}}

@string{scam = {Proc.\ Int'l Workshop Source Code Analysis and Manipulation (SCAM)}}

@string{scp = {Sci. Comput. Program.}}

@string{setmdm = {Proc.\ EDBT Workshop on Software Engineering for Tailor-made Data Management}}

@string{sigmod = {Proc.\ Int'l SIGMOD Conf.\ on Management of Data (SIGMOD)}}

@string{sigplannot = {SIGPLAN Notices}}

@string{sigsoftnotice = {SIGSOFT Softw. Eng. Notes}}

@string{sle = {Proc.\ Conf.\ Software Language Engineering (SLE)}}

@string{spe = {Software: Practice and Experience}}

@string{splc = {Proc.\ Int'l Software Product Line Conference (SPLC)}}

@string{split = {Proc.\ SPLC Workshop on Software Product Line Testing (SPLiT)}}

@string{springer = {Springer-Verlag}}

@string{springeraddr = {}}

@string{springeraddr-not = {Berlin/Heidelberg}}

@string{springeraddrbhn = {Berlin/Heidelberg/New York}}

@string{springeraddrl = {London}}

@string{springeraddrnj = {Secaucus, NJ}}

@string{springeraddrnl = {Dordrecht}}

@string{springeraddrny = {New York}}

@string{springerbase = {Springer}}

@string{springernl = {Springer Netherlands}}

@string{tcs = {Theoretical Computer Science}}

@string{tocs = {ACM Trans. Comp. Syst. (TOCS)}}

@string{tods = {ACM Trans. Database Systems (TODS)}}

@string{tools = {Proc.\ Int'l Conf.\ Objects, Models, Components, Patterns (TOOLS EUROPE)}}

@string{toplas = {TOPLAS}}

@string{tosem = {ACM Trans. Softw. Eng. Methodol. (TOSEM)}}

@string{tpds = {IEEE Trans.\ Parallel Distr.\ Systems (TPDS)}}

@string{tse = {IEEE Trans.\ Softw.\ Eng. (TSE)}}

@string{vamos = {Proc.\ Int'l Workshop on Variability Modelling of Software-intensive Systems (VaMoS)}}

@string{visple = {Proc.\ SPLC Workshop on Visualization in Software Product Line Engineering (ViSPLE)}}

@string{wcre = {Proc.\ Working Conf.\ Reverse Engineering (WCRE)}}

@string{wgp = {Proc.\ SIGPLAN Workshop on Generic Programming}}

@string{wiley = {John Wiley \& Sons, Inc.}}

@string{wileyaddr = {New York, NY}}

@string{wrt = {Proc.\ ECOOP Workshop on Refactoring Tools (WRT)}}


@inproceedings{Lempsink2009typesafe,
	Abstract = {The UNIX diff program finds the difference between two text files using a classic algorithm for determining the longest common subsequence; however, when working with structured input (e.g. program code), we often want to find the difference between tree-like data (e.g. the abstract syntax tree). In a functional programming language such as Haskell, we can represent this data with a family of (mutually recursive) datatypes. In this paper, we describe a functional, datatype-generic implementation of diff (and the associated program patch). Our approach requires advanced type system features to preserve type safety; therefore, we present the code in Agda, a dependently-typed language well-suited to datatype-generic programming. In order to establish the usefulness of our work, we show that its efficiency can be improved with memoization and that it can also be defined in Haskell.},
	Address = {New York, NY, USA},
	Author = {{Lempsink}, Eelco and {Leather}, Sean and {L{\"o}h}, Andres},
	Booktitle = {Proceedings of the 2009 {{ACM SIGPLAN Workshop}} on {{Generic Programming}}},
	Date-Added = {2016-03-24 10:12:28 +0000},
	Date-Modified = {2016-03-24 10:12:28 +0000},
	Doi = {10.1145/1596614.1596624},
	File = {Lempsink et al - 2009 - Type-safe Diff for Families of Datatypes.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/85CGCP4M/Lempsink et al - 2009 - Type-safe Diff for Families of Datatypes.pdf:application/pdf},
	Isbn = {978-1-60558-510-9},
	Keywords = {datatype-generic programming,dependent types,edit distance},
	Pages = {61--72},
	Publisher = {{ACM}},
	Series = {WGP '09},
	Timestamp = {2016-03-09T14:33:35Z},
	Title = {Type-safe {{Diff}} for {{Families}} of {{Datatypes}}},
	Urldate = {2016-03-09},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1596614.1596624}}

@inproceedings{Marlow2004making,
	Abstract = {Higher-order languages that encourage currying are implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	Address = {New York, NY, USA},
	Author = {{Marlow}, Simon and {Jones}, Simon Peyton},
	Booktitle = {Proceedings of the ninth {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2016-03-01 10:01:59 +0000},
	Date-Modified = {2016-03-01 10:02:38 +0000},
	Doi = {10.1145/1016850.1016856},
	Isbn = {1-58113-905-5},
	Pages = {4--15},
	Publisher = {{ACM}},
	Series = {ICFP '04},
	Shorttitle = {Making a fast curry},
	Timestamp = {2016-02-29T20:19:58Z},
	Title = {Making a fast curry: push/enter vs. eval/apply for higher-order languages},
	Urldate = {2016-02-29},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1016850.1016856}}

@article{Marlow2006making,
	Abstract = {Higher-order languages that encourage currying are typically implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other. Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell. Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	Author = {{Marlow}, Simon and {Jones}, Simon Peyton},
	Date-Added = {2016-03-01 10:01:15 +0000},
	Date-Modified = {2016-03-01 10:01:41 +0000},
	Doi = {10.1017/S0956796806005995},
	Issn = {1469-7653},
	Journal = {Journal of Functional Programming},
	Number = {4-5},
	Pages = {415--449},
	Shorttitle = {Making a fast curry},
	Timestamp = {2016-02-29T20:20:03Z},
	Title = {Making a fast curry: push/enter vs. eval/apply for higher-order languages},
	Urldate = {2016-02-29},
	Volume = {16},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/S0956796806005995}}

@inproceedings{Bolingbroke2009types,
	Abstract = {It is common for compilers to derive the calling convention of a function from its type. Doing so is simple and modular but misses many optimisation opportunities, particularly in lazy, higher-order functional languages with extensive use of currying. We restore the lost opportunities by defining Strict Core, a new intermediate language whose type system makes the missing distinctions: laziness is explicit, and functions take multiple arguments and return multiple results.},
	Address = {New York, NY, USA},
	Author = {{Bolingbroke}, Maximilian C. and {Peyton Jones}, Simon L.},
	Booktitle = {Proceedings of the {{2nd ACM SIGPLAN Symposium}} on {{Haskell}}},
	Date-Added = {2016-02-29 20:10:50 +0000},
	Date-Modified = {2016-02-29 20:12:40 +0000},
	Doi = {10.1145/1596638.1596640},
	File = {Bolingbroke_Peyton Jones - 2009 - Types Are Calling Conventions.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/7JN4CHH4/Bolingbroke_Peyton Jones - 2009 - Types Are Calling Conventions.pdf:application/pdf},
	Isbn = {978-1-60558-508-6},
	Keywords = {arity,calling conventions,intermediate language,strictness,unboxing,uncurrying},
	Pages = {1--12},
	Publisher = {{ACM}},
	Series = {Haskell '09},
	Timestamp = {2016-02-08T23:14:19Z},
	Title = {Types Are Calling Conventions},
	Urldate = {2016-02-08},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1596638.1596640}}

@inproceedings{Sergey2014modular,
	Abstract = {Since the mid '80s, compiler writers for functional languages (especially lazy ones) have been writing papers about identifying and exploiting thunks and lambdas that are used only once. However it has proved difficult to achieve both power and simplicity in practice. We describe a new, modular analysis for a higher-order language, which is both simple and effective, and present measurements of its use in a full-scale, state of the art optimising compiler. The analysis finds many single-entry thunks and one-shot lambdas and enables a number of program optimisations.},
	Address = {New York, NY, USA},
	Author = {{Sergey}, Ilya and {Vytiniotis}, Dimitrios and {Peyton Jones}, Simon},
	Booktitle = {Proceedings of the 41st {{ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
	Date-Added = {2016-03-01 09:29:17 +0000},
	Date-Modified = {2016-03-01 09:29:48 +0000},
	Doi = {10.1145/2535838.2535861},
	File = {Sergey et al - 2014 - Modular, Higher-order Cardinality Analysis in Theory and Practice.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/W5U3IS6V/Sergey et al - 2014 - Modular, Higher-order Cardinality Analysis in Theory and Practice.pdf:application/pdf},
	Isbn = {978-1-4503-2544-8},
	Keywords = {cardinality analysis,Compilers,functional programming languages,haskell,Lazy Evaluation,operational semantics,Program optimisation,static analysis,thunks,types and effects},
	Pages = {335--347},
	Publisher = {{ACM}},
	Series = {POPL '14},
	Timestamp = {2016-03-01T09:25:28Z},
	Title = {Modular, Higher-order Cardinality Analysis in Theory and Practice},
	Urldate = {2016-03-01},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2535838.2535861}}

@article{amadio2013certifying,
	Abstract = {We present a so-called labelling method to insert cost annotations in a higher-order functional program, to certify their correctness with respect to a standard compilation chain to assembly code including safe memory management, and to reason on them in a higher-order Hoare logic.},
	Author = {Amadio, Roberto M. and R{\'e}gis-Gianas, Yann},
	Date-Added = {2015-08-06 13:46:55 +0000},
	Date-Modified = {2015-08-06 13:47:06 +0000},
	File = {Amadio_R{\'e}gis-Gianas - 2013 - Certifying and reasoning about cost annotations of functional programs.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/QIMQX25D/Amadio_R{\'e}gis-Gianas - 2013 - Certifying and reasoning about cost annotations of functional programs.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/GEU6IAJB/inria-00629473v2.html:text/html},
	Journal = {Higher-Order and Symbolic Computation},
	Language = {en},
	Month = jan,
	Timestamp = {2015-07-02 13:23:15},
	Title = {Certifying and reasoning about cost annotations of functional programs},
	Url = {https://hal.inria.fr/inria-00629473/document},
	Urldate = {2015-03-26},
	Year = {2013},
	Bdsk-Url-1 = {https://hal.inria.fr/inria-00629473/document}}

@article{Dwork84,
	Abstract = {The problem of unification of terms is log-space complete for P. In deriving this lower bound no use is made of the potentially concise representation of terms by directed acyclic graphs. In addition, the problem remains complete even if infinite substitutions are allowed. A consequence of this result is that parallelism cannot significantly improve on the best sequential solutions for unification. However, we show that for the problem of term matching, an important subcase of unification, there is a good parallel algorithm using O(log2n) time and nO(1) processors on a PRAM. For the O(log2n) parallel time upper bound we assume that the terms are represented by directed acyclic graphs; if the longer string representation is used we obtain an O(log n) parallel time bound.},
	Author = {Dwork, Cynthia and Kanellakis, Paris C. and Mitchell, John C.},
	Date-Added = {2015-04-14 13:44:04 +0000},
	Date-Modified = {2015-04-14 13:44:11 +0000},
	Doi = {10.1016/0743-1066(84)90022-0},
	File = {ScienceDirect Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/7WQ67ZTB/0743106684900220.html:text/html},
	Issn = {0743-1066},
	Journal = {The Journal of Logic Programming},
	Month = jun,
	Number = {1},
	Pages = {35--50},
	Timestamp = {2015-04-14 13:23:50},
	Title = {On the sequential nature of unification},
	Url = {http://www.sciencedirect.com/science/article/pii/0743106684900220},
	Urldate = {2015-04-14},
	Volume = {1},
	Year = {1984},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0743106684900220},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0743-1066(84)90022-0}}

@inproceedings{Krishnaswami15,
	Author = {Neelakantan R. Krishnaswami and Pierre Pradic and Nick Benton},
	Booktitle = {Principles of Programming Languages (POPL)},
	Date-Added = {2014-11-22 16:57:20 +0000},
	Date-Modified = {2014-11-24 08:41:36 +0000},
	Month = jan,
	Title = {Integrating Linear and Dependent Types},
	Url = {http://www.cs.bham.ac.uk/~krishnan/dlnl-paper.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cs.bham.ac.uk/~krishnan/dlnl-paper.pdf}}

@article{Burstall1977,
	Abstract = {A system of rules for transforming programs is described, with the programs in the form of recursion equations. An initially very simple, lucid, and hopefully correct program is transformed into a more efficient one by altering the recursion structure. Illustrative examples of program transformations are given, and a tentative implementation is described. Alternative structures for programs are shown, and a possible initial phase for an automatic or semiautomatic program-manipulation system is indicated.},
	Author = {Burstall, R. M. and Darlington, John},
	Date-Added = {2014-04-24 13:01:50 +0000},
	Date-Modified = {2014-04-24 13:01:50 +0000},
	Doi = {10.1145/321992.321996},
	File = {ACM Full Text PDF:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6TRIHBF6/Burstall and Darlington - 1977 - A Transformation System for Developing Recursive P.pdf:application/pdf},
	Issn = {0004-5411},
	Journal = {J. ACM},
	Month = jan,
	Number = {1},
	Pages = {44\textendash{}67},
	Title = {A Transformation System for Developing Recursive Programs},
	Url = {http://doi.acm.org/10.1145/321992.321996},
	Urldate = {2014-04-23},
	Volume = {24},
	Year = {1977},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/321992.321996},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/321992.321996}}

@inproceedings{Bernardy10,
	Acmid = {1863592},
	Address = {New York, NY, USA},
	Author = {Bernardy, Jean-Philippe and Jansson, Patrik and Paterson, Ross},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-31 17:47:02 +0000},
	Date-Modified = {2014-03-31 17:47:03 +0000},
	Doi = {10.1145/1863543.1863592},
	Isbn = {978-1-60558-794-3},
	Keywords = {abstraction theorem, free theorems, pure type system},
	Location = {Baltimore, Maryland, USA},
	Numpages = {12},
	Pages = {345--356},
	Publisher = {ACM},
	Series = {ICFP '10},
	Title = {Parametricity and Dependent Types},
	Url = {http://doi.acm.org/10.1145/1863543.1863592},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863592},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863592}}

@inproceedings{Yakushev:2009:GPF,
	Abstract = {Many datatype-generic functions need access to the recursive positions in the structure of the datatype, and therefore adopt a fixed point view on datatypes. Examples include variants of fold that traverse the data following the recursive structure, or the Zipper data structure that enables navigation along the recursive positions. However, Hindley-Milner-inspired type systems with algebraic datatypes make it difficult to express fixed points for anything but regular datatypes. Many real-life examples such as abstract syntax trees are in fact systems of mutually recursive datatypes and therefore excluded. Using Haskell's GADTs and type families, we describe a technique that allows a fixed-point view for systems of mutually recursive datatypes. We demonstrate that our approach is widely applicable by giving several examples of generic functions for this view, most prominently the Zipper.},
	Acmid = {1596585},
	Address = {New York, NY, USA},
	Annote = {Why is compos not recursive?
composRec f = to . f . fmap (composRec f) . from

Sec. 2.2: Can't one just write "derive Functor"?

Sec. 4.1: promoted kinds? (Doesn't work so easily).},
	Author = {Yakushev, Alexey Rodriguez and Holdermans, Stefan and L\"{o}h, Andres and Jeuring, Johan},
	Booktitle = {Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
	Conference = {ICFP},
	Date-Added = {2014-03-13 11:11:47 +0000},
	Date-Modified = {2014-03-13 17:34:12 +0000},
	Doi = {10.1145/1596550.1596585},
	Isbn = {978-1-60558-332-7},
	Keywords = {datatype-generic programming, fixed points, haskell, mutually recursive datatypes},
	Location = {Edinburgh, Scotland},
	Numpages = {12},
	Pages = {233--244},
	Publisher = {ACM},
	Series = {ICFP '09},
	Title = {Generic Programming with Fixed Points for Mutually Recursive Datatypes},
	Url = {http://doi.acm.org/10.1145/1596550.1596585},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596550.1596585},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596550.1596585}}

@inproceedings{Jay11TSP,
	Acmid = {2034808},
	Address = {New York, NY, USA},
	Annote = {They don't distinguish T and Expr T:
> A consequence of the type of B is that our notion of quotation is type-preserving: if a program has type T , then its representation has type T , too. This shows that different quotations may have different types. An alternative would be to follow Rendel, Ostermann, and Hofer and introduce a new type Expr T of program representations so that terms cannot be confused with their representations; we leave this for future work.

Moreover, all their interpreters would also work for terms which haven't been quoted.

So I think this "future work" is impossible --- but they say otherwise in conclusions:
> A more interesting challenge is whether the results in this paper can be applied to a strongly normalising calculus. After all, if the basic calculus is strongly normalising, why shouldn't the interpretations be so too? To put it another way, can the Y operator be replaced by something that is strongly normalising?

[Their self-interpreters seem to work without Y --- but they use let rec, which is desugared to Y.]

> Is there a self-interpreter that is adequate, in the sense of Rendel, Ostermann, and Hofer? This seems plausible, at the price of making everything somewhat more obscure. Is there a self-interpreter for a language with decidable type-checking? This is a harder question, since it is not clear how to factorise the application of a term to a type.

==

Moreover, can one write interesting self-interpreters? Well, at least by now they can show a self-optimizer apparently, so things aren't so bad maybe.

Can we also discuss why they don't fall prey to G{\"o}del's incompleteness theorem/Tarski undefinability theorem? (But they don't have decidable typechecking, nor is theirs a total language?)
(It's also not like they can type everything, say E --- their system is funny there. Also, they don't support explicit type annotations in the source language.).

See also:
7.5 Adequacy
A weakness of our approach is that the type system does not distinguish terms from their quotations. [...] In the meantime, observe that there is not much scope for confusion, as there is a simple test for being a quotation [...]

> The approach of Rendel, Ostermann, and Hofer can be characterised as follows. A function at one level of the type hierarchy can be tagged to become a data structure at the next level. This requires a countable sequence of levels

> The other notable difference is that both applications of terms to types, and type abstractions, are explicit in their work but implicit here. This saves us from having to factorise type applications, but at the cost of type inference being undecidable.

> They presented a self-recogniser (not strong), and left open the problems of writing an equality checker and a self-enactor.},
	Author = {Jay, Barry and Palsberg, Jens},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-22 16:36:20 +0000},
	Date-Modified = {2014-03-30 11:18:26 +0000},
	Doi = {10.1145/2034773.2034808},
	Isbn = {978-1-4503-0865-6},
	Keywords = {pattern matching, self-interpretation},
	Location = {Tokyo, Japan},
	Numpages = {12},
	Pages = {247--258},
	Publisher = {ACM},
	Series = {ICFP '11},
	Title = {Typed Self-interpretation by Pattern Matching},
	Url = {http://doi.acm.org/10.1145/2034773.2034808},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034808},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034808}}

@article{Nanevski08,
	Abstract = { ABSTRACT We consider the problem of reconciling a dependently typed functional language with imperative features such as mutable higher-order state, pointer aliasing, and nontermination. We propose Hoare type theory (HTT), which incorporates Hoare-style specifications into types, making it possible to statically track and enforce correct use of side effects.The main feature of HTT is the Hoare type {P}x:A{Q} specifying computations with precondition P and postcondition Q that return a result of type A. Hoare types can be nested, combined with other types, and abstracted, leading to a smooth integration with higher-order functions and type polymorphism.We further show that in the presence of type polymorphism, it becomes possible to interpret the Hoare types in the ``small footprint'' manner, as advocated by separation logic, whereby specifications tightly describe the state required by the computation.We establish that HTT is sound and compositional, in the sense that separate verifications of individual program components suffice to ensure the correctness of the composite program. },
	Author = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
	Date-Added = {2014-03-16 23:51:29 +0000},
	Date-Modified = {2014-03-16 23:52:01 +0000},
	Doi = {10.1017/S0956796808006953},
	Issn = {1469-7653},
	Issue = {Special Double Issue 5-6},
	Journal = {Journal of Functional Programming},
	Month = {9},
	Numpages = {47},
	Pages = {865--911},
	Title = {Hoare type theory, polymorphism and separation},
	Url = {http://journals.cambridge.org/article_S0956796808006953},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {http://journals.cambridge.org/article_S0956796808006953},
	Bdsk-Url-2 = {http://dx.doi.org/10.1017/S0956796808006953}}

@inproceedings{Nanevski:2006:PSH,
	Abstract = {In previous work, we proposed a Hoare Type Theory (HTT) which combines effectful higher-order functions, dependent types and Hoare Logic specifications into a unified framework. However, the framework did not support polymorphism, and ailed to provide a modular treatment of state in specifications. In this paper, we address these shortcomings by showing that the addition of polymorphism alone is sufficient for capturing modular state specifications in the style of Separation Logic. Furthermore, we argue that polymorphism is an essential ingredient of the extension, as the treatment of higher-order functions requires operations not encodable via the spatial connectives of Separation Logic.},
	Acmid = {1159812},
	Address = {New York, NY, USA},
	Author = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
	Booktitle = {Proceedings of the Eleventh ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-16 12:51:31 +0000},
	Date-Modified = {2014-03-16 12:51:47 +0000},
	Doi = {10.1145/1159803.1159812},
	Isbn = {1-59593-309-3},
	Keywords = {hoare logic, separation logic, type theory},
	Location = {Portland, Oregon, USA},
	Numpages = {12},
	Pages = {62--73},
	Publisher = {ACM},
	Series = {ICFP '06},
	Title = {Polymorphism and Separation in Hoare Type Theory},
	Url = {http://doi.acm.org/10.1145/1159803.1159812},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1159803.1159812},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1159803.1159812}}

@inproceedings{Ahmed09sri,
	Abstract = {Mitchell's notion of representation independence is a particularly useful application of Reynolds' relational parametricity -- two different implementations of an abstract data type can be shown contextually equivalent so long as there exists a relation between their type representations that is preserved by their operations. There have been a number of methods proposed for proving representation independence in various pure extensions of System F (where data abstraction is achieved through existential typing), as well as in Algol- or Java-like languages (where data abstraction is achieved through the use of local mutable state). However, none of these approaches addresses the interaction of existential type abstraction and local state. In particular, none allows one to prove representation independence results for generative ADTs -- i.e. ADTs that both maintain some local state and define abstract types whose internal representations are dependent on that local state.

In this paper, we present a syntactic, logical-relations-based method for proving representation independence of generative ADTs in a language supporting polymorphic types, existential types, general recursive types, and unrestricted ML-style mutable references. We demonstrate the effectiveness of our method by using it to prove several interesting contextual equivalences that involve a close interaction between existential typing and local state, as well as some well-known equivalences from the literature (such as Pitts and Stark's "awkward" example) that have caused trouble for previous logical-relations-based methods.

The success of our method relies on two key technical innovations. First, in order to handle generative ADTs, we develop a possible-worlds model in which relational interpretations of types are allowed to grow over time in a manner that is tightly coupled with changes to some local state. Second, we employ a step-indexed stratification of possible worlds, which facilitates a simplified account of mutable references of higher type.},
	Acmid = {1480925},
	Address = {New York, NY, USA},
	Author = {Ahmed, Amal and Dreyer, Derek and Rossberg, Andreas},
	Booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	Date-Added = {2014-03-04 21:38:25 +0000},
	Date-Modified = {2014-03-04 21:38:50 +0000},
	Doi = {10.1145/1480881.1480925},
	Isbn = {978-1-60558-379-2},
	Keywords = {abstract data types, existential types, local state, representation independence, step-indexed logical relations},
	Location = {Savannah, GA, USA},
	Numpages = {14},
	Pages = {340--353},
	Publisher = {ACM},
	Series = {POPL '09},
	Title = {State-dependent Representation Independence},
	Url = {http://doi.acm.org/10.1145/1480881.1480925},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480881.1480925},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480881.1480925}}

@article{Appel01,
	Abstract = {The proofs of "traditional" proof carrying code (PCC) are type-specialized in the sense that they require axioms about a specific type system. In contrast, the proofs of foundational PCC explicitly define all required types and explicitly prove all the required properties of those types assuming only a fixed foundation of mathematics such as higher-order logic. Foundational PCC is both more flexible and more secure than type-specialized PCC.For foundational PCC we need semantic models of type systems on von Neumann machines. Previous models have been either too weak (lacking general recursive types and first-class function-pointers), too complex (requiring machine-checkable proofs of large bodies of computability theory), or not obviously applicable to von Neumann machines. Our new model is strong, simple, and works either in Œª-calculus or on Pentiums.},
	Acmid = {504712},
	Address = {New York, NY, USA},
	Annote = {This paper "Proposes the ``step-indexed'' logical-relations model, now an essential tool in scaling parametricity to real languages".
I've read Sec. 1 and 2, with a safety proof for omega and Y, and I've been mind-blown.},
	Author = {Appel, Andrew W. and McAllester, David},
	Date-Added = {2014-03-04 14:00:56 +0000},
	Date-Modified = {2014-03-04 14:02:35 +0000},
	Doi = {10.1145/504709.504712},
	Issn = {0164-0925},
	Issue_Date = {September 2001},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Month = sep,
	Number = {5},
	Numpages = {27},
	Pages = {657--683},
	Publisher = {ACM},
	Rating = {5},
	Title = {An Indexed Model of Recursive Types for Foundational Proof-carrying Code},
	Url = {http://doi.acm.org/10.1145/504709.504712},
	Volume = {23},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/504709.504712},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/504709.504712}}

@inproceedings{Dunfield13,
	Abstract = {Bidirectional typechecking, in which terms either synthesize a type or are checked against a known type, has become popular for its scalability (unlike Damas-Milner type inference, bidirectional typing remains decidable even for very expressive type systems), its error reporting, and its relative ease of implementation. Following design principles from proof theory, bidirectional typing can be applied to many type constructs. The principles underlying a bidirectional approach to polymorphism, however, are less obvious. We give a declarative, bidirectional account of higher-rank polymorphism, grounded in proof theory; this calculus enjoys many properties such as eta-reduction and predictability of annotations. We give an algorithm for implementing the declarative system; our algorithm is remarkably simple and well-behaved, despite being both sound and complete.},
	Acmid = {2500582},
	Address = {New York, NY, USA},
	Annote = {> "Following design principles from proof theory, bidirectional typing can be applied to many type constructs."

Related to our "DSL design" paper?},
	Author = {Dunfield, Joshua and Krishnaswami, Neelakantan R.},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-02-11 14:38:41 +0000},
	Date-Modified = {2014-02-11 16:16:53 +0000},
	Doi = {10.1145/2500365.2500582},
	Isbn = {978-1-4503-2326-0},
	Keywords = {bidirectional typechecking, higher-rank polymorphism},
	Location = {Boston, Massachusetts, USA},
	Numpages = {14},
	Pages = {429--442},
	Publisher = {ACM},
	Rating = {4},
	Series = {ICFP '13},
	Title = {Complete and Easy Bidirectional Typechecking for Higher-rank Polymorphism},
	Url = {http://doi.acm.org/10.1145/2500365.2500582},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500582},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500582}}

@article{Peyton-Jones98,
	Abstract = {Many compilers do some of their work by means of correctness-preserving, and hopefully performance-improving, program transformations. The Glasgow Haskell Compiler (GHC) takes this idea of ``compilation by transformation'' as its war-cry, trying to express as much as possible of the compilation process in the form of program transformations.

This paper reports on our practical experience of the transformational approach to compilation, in the context of a substantial compiler.},
	Acmid = {299621},
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Peyton Jones, Simon L. and Santos, Andr{\'e} L. M.},
	Date-Added = {2014-02-09 22:08:08 +0000},
	Date-Modified = {2014-02-09 23:35:14 +0000},
	Doi = {10.1016/S0167-6423(97)00029-4},
	Issn = {0167-6423},
	Issue_Date = {Sept. 1998},
	Journal = {Sci. Comput. Program.},
	Keywords = {compilers, functional languages, let-floating, linear type system, optimisation, second-order lambda calculus, strictness analysis, transformation},
	Month = sep,
	Number = {1-3},
	Numpages = {45},
	Pages = {3--47},
	Publisher = {Elsevier North-Holland, Inc.},
	Rating = {5},
	Title = {A Transformation-based Optimiser for Haskell},
	Url = {http://dx.doi.org/10.1016/S0167-6423(97)00029-4},
	Volume = {32},
	Year = {1998},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0167-6423(97)00029-4}}

@incollection{Odersky03,
	Abstract = {We design and study vObj, a calculus and dependent type system for objects and classes which can have types as members. Type members can be aliases, abstract types, or new types. The type system can model the essential concepts of JAVA's inner classes as well as virtual types and family polymorphism found in BETA or GBETA. It can also model most concepts of SML-style module systems, including sharing constraints and higher-order functors, but excluding applicative functors. The type system can thus be used as a basis for unifying concepts that so far existed in parallel in advanced object systems and in module systems. The paper presents results on confluence of the calculus, soundness of the type system, and undecidability of type checking.},
	Author = {Odersky, Martin and Cremet, Vincent and R{\"o}ckl, Christine and Zenger, Matthias},
	Booktitle = {ECOOP 2003 -- Object-Oriented Programming},
	Date-Added = {2013-12-10 15:38:29 +0000},
	Date-Modified = {2013-12-10 15:38:40 +0000},
	Doi = {10.1007/978-3-540-45070-2_10},
	Editor = {Cardelli, Luca},
	Isbn = {978-3-540-40531-3},
	Pages = {201-224},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A Nominal Theory of Objects with Dependent Types},
	Url = {http://dx.doi.org/10.1007/978-3-540-45070-2_10},
	Volume = {2743},
	Year = {2003},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-45070-2_10}}

@article{Rompf13a,
	Author = {Rompf, Tiark and Amin, Nada and Moors, Adriaan and Haller, Philipp and Odersky, Martin},
	Date-Added = {2013-12-10 15:16:28 +0000},
	Date-Modified = {2013-12-10 15:16:31 +0000},
	Doi = {10.1007/s10990-013-9096-9},
	Issn = {1388-3690},
	Journal = {Higher-Order and Symbolic Computation},
	Keywords = {Code generation; Domain-specific languages; Linguistic reuse; Language virtualization},
	Language = {English},
	Pages = {1-43},
	Publisher = {Springer US},
	Title = {Scala-Virtualized: linguistic reuse for deep embeddings},
	Url = {http://dx.doi.org/10.1007/s10990-013-9096-9},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-013-9096-9}}

@inproceedings{Breazu-Tannen91logical,
	Abstract = {We study issues that arise in programming with primitive recursion over non-free datatypes such as lists, bags and sets. Programs written in this style can lack a meaning in the sense that their outputs may be sensitive to the choice of input expression. We are, thus, naturally lead to a set-theoretic denotational semantics with partial functions. We set up a logic for reasoning about the definedness of terms and a deterministic and terminating evaluator. The logic is shown to be sound in the model, and its recursion free fragment is shown to be complete for proving definedness of recursion free programs. The logic is then shown to be as strong as the evaluator, and this implies that the evaluator is compatible with the provable equivalence between different set (or bag, or list) expression . Oftentimes,the same non-free datatype may have different presentations, and it is not clear a priori whether programming and reasoning with the two presentations are equivalent. We formulate these questions, precisely, in the context of alternative presentations of the list, bag, and set datatypes and study some aspects of these questions. In particular, we establish back-and-forth translations between the two presentations, from which it follows that they are equally expressive, and prove results relating proofs of program properties, in the two presentations.},
	Acmid = {758814},
	Address = {London, UK, UK},
	Annote = {This paper discusses denotational, operational and equational semantics for sets, bags and lists, both in cons-nil representation [let's call it insert representation, following Grust] and in empty-singleton-union representation [let's call it union representation, again following Grust]. Among other results, they show that these representations are interconvertible.
Given an algebra (i.e. fold) in union representation, one can build one in insert representation easily:
cons head tail = union (singleton head) tail
nil = empty
Given an algebra (i.e. fold) in insert representation, one can build one in union representation using the functional representation of difference lists, that is, by encoding lists as their prepend function of type [t] -> [t]
empty = id
singleton el = (tail -> cons el tail) = cons el
union x y = (tail -> (x . y) tail) = x . y.

nil is only used to reify difference lists to standard ones.

Meta-notes:
Grust cites this paper in his PhD thesis to show that it is hard to convert from insert queries (that is, folds) into union queries. The reason is that the translation they present is higher-order.},
	Author = {Breazu-Tannen, Val and Subrahmanyam, Ramesh},
	Booktitle = {Proceedings of the 18th International Colloquium on Automata, Languages and Programming},
	Date-Added = {2013-11-23 02:32:24 +0000},
	Date-Modified = {2013-11-23 02:43:46 +0000},
	Isbn = {3-540-54233-7},
	Numpages = {16},
	Pages = {60--75},
	Publisher = {Springer-Verlag},
	Series = {ICALP '91},
	Title = {Logical and Computational Aspects of Programming with Sets/Bags/Lists},
	Url = {http://link.springer.com/chapter/10.1007/3-540-54233-7_125},
	Year = {1991},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=646245.758814},
	Bdsk-Url-2 = {http://dl.acm.org/citation.cfm?id=111713.111718},
	Bdsk-Url-3 = {http://link.springer.com/chapter/10.1007/3-540-54233-7_125}}

@article{Harper93,
	Abstract = {The Edinburgh Logical Framework (LF) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed &lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-L{\"o}f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in LF via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.},
	Acmid = {138060},
	Address = {New York, NY, USA},
	Annote = {This paper describes the Edinburgh Logical Framework, LF for short, which is the first part of the foundation of Twelf; this paper includes no logic programming elements.

LF includes a minimal dependent lambda-calculus, where types and values can abstract on values. Nothing can abstract on types; but everything of interest can be represented as values, including types of the embedded logic. By accepting these restrictions, various problems 

When needed, such one can abstract over such values to construct types, exactly like in a universe construction --- for instance obj : holtype -> Type in the encoding of higher-order logic. However, universe constructions need be used even in some cases which would usually be handled via polymorphism (again for higher-order logic, see HOAS abstraction and application for the embedded logic).

Moreover, it includes an approach for embedding logics which includes:

- Sorts of the metatheory of the logic (term, formula, individual, etc.) are represented as types in LF.
- Judgements of the represented theory are represented as types, while proofs are terms inhabiting those types, and proof rules are constructors of those terms. Proof checking reduces to type-checking.
- Martin-L{\"o}f's hypothetical and schematic/general judgements are encoded as types of functions producing judgements and taking, respectively, judgements or individuals.
- Binding is handled through higher-order abstract syntax (not cited by name in the paper, but used in all examples and emphasized as important). This way, the handling of binding is rather easy (as usual with HOAS).
- Derived rules can be proven easily, while proving admissibility is much harder.
- A definition of adequacy for encodings as a biijection which is compositional, that is commutes with substitution.

Many of these ideas are reflected in formalizations present in Harper's "Practical Foundations of Programming Languages".

According to the authors, the encoding is similar to AUTOMATH but separates better object and meta-level.

The writing style is precise but overall rather academic.},
	Author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon},
	Date-Added = {2013-11-19 18:59:05 +0000},
	Date-Modified = {2013-11-19 19:17:39 +0000},
	Doi = {10.1145/138027.138060},
	Issn = {0004-5411},
	Issue_Date = {Jan. 1993},
	Journal = {J. ACM},
	Keywords = {formal systems, interactive theorem proving, proof checking, typed lambda calculus},
	Month = jan,
	Number = {1},
	Numpages = {42},
	Pages = {143--184},
	Publisher = {ACM},
	Rating = {4},
	Read = {1},
	Title = {A Framework for Defining Logics},
	Url = {http://doi.acm.org/10.1145/138027.138060},
	Volume = {40},
	Year = {1993},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/138027.138060},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/138027.138060}}

@inproceedings{Nerella13,
	Abstract = {Object oriented programming languages raised the level of abstraction by supporting the explicit first class query constructs in the programming codes. The query constructs can be optimized by leveraging the techniques of query optimization from the domain of databases. The existing optimization approaches such as JQL, however, incur high run time overhead as optimizations are performed only at run time. Therefore, in this paper, we propose an approach that performs the query optimization at compile time utilizing the metadata annotations in the source code. The proposed approach first collects the data from the sample execution of the program and extracts the essential metadata for the string valued attributes. Then, the annotations consisting of the metadata values associated with string attributes are generated in the source code and the histograms are built using those annotations. The selectivity estimates of the predicates and the joins in the query are computed from the histograms. Next, the query plan is generated at compile time through the maximum selectivity heuristic. The query plan is modified at run time in cases of significant updates to the string data. The approach also incorporates the cache heuristics that determine whether to cache the query result or not. The cached query results are incrementally maintained up-to-date. Our experimental results demonstrate that our approach has reduced the run time of the program more than the earlier approaches such as JQL.},
	Author = {Nerella, Venkata Krishna Suhas and Madria, Sanjay K. and Weigert, Thomas},
	Booktitle = {Computer Software and Applications Conference (COMPSAC), 2013 IEEE 37th Annual},
	Date-Added = {2013-11-19 14:53:53 +0000},
	Date-Modified = {2013-11-19 14:53:55 +0000},
	Doi = {10.1109/COMPSAC.2013.56},
	Keywords = {Benchmark testing;Histograms;Java;Maintenance engineering;Optimization;Query processing;Time-frequency analysis;Annotations;Compile time;Query Plan;Selectivity;string data},
	Pages = {313-318},
	Title = {Optimization of Object Queries on Collections Using Annotations for the String Valued Attributes},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/COMPSAC.2013.56}}

@inproceedings{Aspinall96,
	Abstract = {The need for subtyping in type-systems with dependent types has been realized for some years. But it is hard to prove that systems combining the two features have fundamental properties such as subject reduction. Here we investigate a subtyping extension of the system ŒªP, which is an abstract version of the type system of the Edinburgh Logical Framework LF. By using an equivalent formulation, we establish some important properties of the new system ŒªP‚©Ω, including subject reduction. Our analysis culminates in a complete and terminating algorithm which establishes the decidability of type-checking},
	Author = {Aspinall, D. and Compagnoni, A.},
	Booktitle = {Logic in Computer Science, 1996. LICS '96. Proceedings., Eleventh Annual IEEE Symposium on},
	Date-Added = {2013-11-19 14:52:44 +0000},
	Date-Modified = {2013-11-19 14:52:47 +0000},
	Doi = {10.1109/LICS.1996.561307},
	Issn = {1043-6871},
	Keywords = {decidability;programming theory;type theory;Edinburgh Logical Framework;decidability;dependent types;subject reduction;subtyping;terminating algorithm;type-checking;type-systems;Algorithm design and analysis;Application software;Computer languages;Computer science;Encoding;Laboratories;Logic programming},
	Pages = {86-97},
	Title = {Subtyping dependent types},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LICS.1996.561307}}

@inproceedings{Parr11,
	Abstract = {Despite the power of Parser Expression Grammars (PEGs) and GLR, parsing is not a solved problem. Adding nondeterminism (parser speculation) to traditional LL and LR parsers can lead to unexpected parse-time behavior and introduces practical issues with error handling, single-step debugging, and side-effecting embedded grammar actions. This paper introduces the LL(*) parsing strategy and an associated grammar analysis algorithm that constructs LL(*) parsing decisions from ANTLR grammars. At parse-time, decisions gracefully throttle up from conventional fixed k>=1 lookahead to arbitrary lookahead and, finally, fail over to backtracking depending on the complexity of the parsing decision and the input symbols. LL(*) parsing strength reaches into the context-sensitive languages, in some cases beyond what GLR and PEGs can express. By statically removing as much speculation as possible, LL(*) provides the expressivity of PEGs while retaining LL's good error handling and unrestricted grammar actions. Widespread use of ANTLR (over 70,000 downloads/year) shows that it is effective for a wide variety of applications.},
	Acmid = {1993548},
	Address = {New York, NY, USA},
	Author = {Parr, Terence and Fisher, Kathleen},
	Booktitle = {Proceedings of the 32Nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
	Date-Added = {2013-11-19 11:40:05 +0000},
	Date-Modified = {2013-11-19 11:40:21 +0000},
	Doi = {10.1145/1993498.1993548},
	Isbn = {978-1-4503-0663-8},
	Keywords = {augmented transition networks, backtracking, context-sensitive parsing, deterministic finite automata, glr, memoization, nondeterministic parsing, peg, semantic predicates, subset construction, syntactic predicates},
	Location = {San Jose, California, USA},
	Numpages = {12},
	Pages = {425--436},
	Publisher = {ACM},
	Series = {PLDI '11},
	Title = {LL(*): The Foundation of the ANTLR Parser Generator},
	Url = {http://doi.acm.org/10.1145/1993498.1993548},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1993498.1993548},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1993498.1993548}}

@inproceedings{Eisenberg12,
	Acmid = {2364522},
	Address = {New York, NY, USA},
	Author = {Eisenberg, Richard A. and Weirich, Stephanie},
	Booktitle = {Proceedings of the 2012 symposium on Haskell symposium},
	Date-Added = {2013-11-04 18:05:36 +0000},
	Date-Modified = {2013-11-04 18:05:37 +0000},
	Doi = {10.1145/2364506.2364522},
	Isbn = {978-1-4503-1574-6},
	Keywords = {dependently typed programming, gadts, haskell, singletons},
	Location = {Copenhagen, Denmark},
	Numpages = {14},
	Pages = {117--130},
	Publisher = {ACM},
	Series = {Haskell '12},
	Title = {Dependently typed programming with singletons},
	Url = {http://doi.acm.org/10.1145/2364506.2364522},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2364506.2364522},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2364506.2364522}}

@inproceedings{Sujeeth13Forge,
	Abstract = {Domain-specific languages provide a promising path to automatically compile high-level code to parallel, heterogeneous, and distributed hardware. However, in practice high performance DSLs still require considerable software expertise to develop and force users into tool-chains that hinder prototyping and debugging. To address these problems, we present Forge, a new meta DSL for declaratively specifying high performance embedded DSLs. Forge provides DSL authors with high-level abstractions (e.g., data structures, parallel patterns, effects) for specifying their DSL in a way that permits high performance. From this high-level specification, Forge automatically generates both a na{\"\i}ve Scala library implementation of the DSL and a high performance version using the Delite DSL framework. Users of a Forge-generated DSL can prototype their application using the library version, and then switch to the Delite version to run on multicore CPUs, GPUs, and clusters without changing the application code. Forge-generated Delite DSLs perform within 2x of hand-optimized C++ and up to 40x better than Spark, an alternative high-level distributed programming environment. Compared to a manually implemented Delite DSL, Forge provides a factor of 3-6x reduction in lines of code and does not sacrifice any performance. Furthermore, Forge specifications can be generated from existing Scala libraries, are easy to maintain, shield DSL developers from changes in the Delite framework, and enable DSLs to be retargeted to other frameworks transparently.},
	Acmid = {2517220},
	Address = {New York, NY, USA},
	Author = {Sujeeth, Arvind K. and Gibbons, Austin and Brown, Kevin J. and Lee, HyoukJoong and Rompf, Tiark and Odersky, Martin and Olukotun, Kunle},
	Booktitle = {Proceedings of the 12th international conference on Generative programming: concepts \&\#38; experiences},
	Date-Added = {2013-10-29 02:44:59 +0000},
	Date-Modified = {2013-10-29 02:45:12 +0000},
	Doi = {10.1145/2517208.2517220},
	Isbn = {978-1-4503-2373-4},
	Keywords = {code generation, domain-specific languages, multi-stage programming, parallel programming},
	Location = {Indianapolis, Indiana, USA},
	Numpages = {10},
	Pages = {145--154},
	Publisher = {ACM},
	Series = {GPCE '13},
	Title = {Forge: generating a high performance DSL implementation from a declarative specification},
	Url = {http://doi.acm.org/10.1145/2517208.2517220},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2517208.2517220},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2517208.2517220}}

@inproceedings{Abel13,
	Abstract = {Inductive datatypes provide mechanisms to define finite data such as finite lists and trees via constructors and allow programmers to analyze and manipulate finite data via pattern matching. In this paper, we develop a dual approach for working with infinite data structures such as streams. Infinite data inhabits coinductive datatypes which denote greatest fixpoints. Unlike finite data which is defined by constructors we define infinite data by observations. Dual to pattern matching, a tool for analyzing finite data, we develop the concept of copattern matching, which allows us to synthesize infinite data. This leads to a symmetric language design where pattern matching on finite and infinite data can be mixed.

We present a core language for programming with infinite structures by observations together with its operational semantics based on (co)pattern matching and describe coverage of copatterns. Our language naturally supports both call-by-name and call-by-value interpretations and can be seamlessly integrated into existing languages like Haskell and ML. We prove type soundness for our language and sketch how copatterns open new directions for solving problems in the interaction of coinductive and dependent types.},
	Acmid = {2429075},
	Address = {New York, NY, USA},
	Author = {Abel, Andreas and Pientka, Brigitte and Thibodeau, David and Setzer, Anton},
	Booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-10-24 03:00:20 +0000},
	Date-Modified = {2013-10-24 03:01:07 +0000},
	Doi = {10.1145/2429069.2429075},
	Isbn = {978-1-4503-1832-7},
	Keywords = {coinduction, functional programming, introduction vs. elimination, message passing, pattern matching},
	Location = {Rome, Italy},
	Numpages = {12},
	Pages = {27--38},
	Publisher = {ACM},
	Series = {POPL '13},
	Title = {Copatterns: programming infinite structures by observations},
	Url = {http://doi.acm.org/10.1145/2429069.2429075},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2429069.2429075},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2429069.2429075}}

@inproceedings{Abel13a,
	Abstract = {In this paper, we study strong normalization of a core language based on System F-omega which supports programming with finite and infinite structures. Building on our prior work, finite data such as finite lists and trees are defined via constructors and manipulated via pattern matching, while infinite data such as streams and infinite trees is defined by observations and synthesized via copattern matching. In this work, we take a type-based approach to strong normalization by tracking size information about finite and infinite data in the type. This guarantees compositionality. More importantly, the duality of pattern and copatterns provide a unifying semantic concept which allows us for the first time to elegantly and uniformly support both well-founded induction and coinduction by mere rewriting. The strong normalization proof is structured around Girard's reducibility candidates. As such our system allows for non-determinism and does not rely on coverage. Since System F-omega is general enough that it can be the target of compilation for the Calculus of Constructions, this work is a significant step towards representing observation-centric infinite data in proof assistants such as Coq and Agda.},
	Acmid = {2500591},
	Address = {New York, NY, USA},
	Author = {Abel, Andreas M. and Pientka, Brigitte},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-10-24 02:59:43 +0000},
	Date-Modified = {2013-10-24 03:01:18 +0000},
	Doi = {10.1145/2500365.2500591},
	Isbn = {978-1-4503-2326-0},
	Keywords = {coinduction, pattern matching, productivity, recursion, strong normalization, type-based termination},
	Location = {Boston, Massachusetts, USA},
	Numpages = {12},
	Pages = {185--196},
	Publisher = {ACM},
	Series = {ICFP '13},
	Title = {Wellfounded recursion with copatterns: a unified approach to termination and productivity},
	Url = {http://doi.acm.org/10.1145/2500365.2500591},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500591},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500591}}

@article{Plotkin77,
	Abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on LCF. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ‚ä• in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called ``fully abstract''. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
	Author = {G.D. Plotkin},
	Date-Added = {2013-10-13 03:09:08 +0000},
	Date-Modified = {2013-10-13 03:09:11 +0000},
	Journal = {Theoretical Computer Science},
	Nodoi = {10.1016/0304-3975(77)90044-5},
	Noissn = {0304-3975},
	Nourl = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	Number = 3,
	Pages = {223 - 255},
	Prg = {2013-06-10, Cai},
	Title = {{LCF} considered as a programming language},
	Volume = 5,
	Year = 1977,
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0304-3975(77)90044-5}}

@article{Appel97,
	Abstract = {Functional-language compilers often perform optimizations based on beta and delta reduction. To avoid speculative optimizations that can blow up the code size, we might wish to use only shrinking reduction rules guaranteed to make the program smaller: these include dead-variable elimination, constant folding, and a restricted beta rule that inlines only functions that are called just once. The restricted beta rule leads to a shrinking rewrite system that has not previously been studied. We show some efficient normalization algorithms that are immediately useful in optimizing compilers; and we give a confluence proof for our system, showing that the choice of normalization algorithm does not affect final code quality.},
	Author = {Appel, Andrew W. and Jim, Trevor},
	Date-Added = {2013-10-10 15:51:15 +0000},
	Date-Modified = {2013-10-10 15:51:16 +0000},
	Issue = {05},
	Journal = JFP,
	Noissn = {1469-7653},
	Nomonth = sep,
	Nourl = {http://journals.cambridge.org/article_S0956796897002839},
	Numpages = {26},
	Pages = {515--540},
	Title = {Shrinking lambda expressions in linear time},
	Volume = {7},
	Year = {1997}}

@inproceedings{Bhatotia11,
	Abstract = {Many online data sets evolve over time as new entries are slowly added and existing entries are deleted or modified. Taking advantage of this, systems for incremental bulk data processing, such as Google's Percolator, can achieve efficient updates. To achieve this efficiency, however, these systems lose compatibility with the simple programming models offered by non-incremental systems, e.g., MapReduce, and more importantly, requires the programmer to implement application-specific dynamic algorithms, ultimately increasing algorithm and code complexity.

In this paper, we describe the architecture, implementation, and evaluation of Incoop, a generic MapReduce framework for incremental computations. Incoop detects changes to the input and automatically updates the output by employing an efficient, fine-grained result reuse mechanism. To achieve efficiency without sacrificing transparency, we adopt recent advances in the area of programming languages to identify the shortcomings of task-level memoization approaches, and to address these shortcomings by using several novel techniques: a storage system, a contraction phase for Reduce tasks, and an affinity-based scheduling algorithm. We have implemented Incoop by extending the Hadoop framework, and evaluated it by considering several applications and case studies. Our results show significant performance improvements without changing a single line of application code.},
	Acmid = {2038923},
	Address = {New York, NY, USA},
	Articleno = {7},
	Author = {Bhatotia, Pramod and Wieder, Alexander and Rodrigues, Rodrigo and Acar, Umut A. and Pasquin, Rafael},
	Booktitle = {Proceedings of the 2nd ACM Symposium on Cloud Computing},
	Date-Added = {2013-10-09 04:16:34 +0000},
	Date-Modified = {2013-10-09 04:16:58 +0000},
	Doi = {10.1145/2038916.2038923},
	Isbn = {978-1-4503-0976-9},
	Keywords = {memoization, self-adjusting computation, stability},
	Location = {Cascais, Portugal},
	Numpages = {14},
	Pages = {7:1--7:14},
	Publisher = {ACM},
	Series = {SOCC '11},
	Title = {Incoop: MapReduce for incremental computations},
	Url = {http://doi.acm.org/10.1145/2038916.2038923},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2038916.2038923},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2038916.2038923}}

@phdthesis{Acar05,
	Author = {Acar, Umut A},
	Date-Added = {2013-10-08 23:54:44 +0000},
	Date-Modified = {2013-10-08 23:54:50 +0000},
	School = {Princeton University},
	Title = {Self-Adjusting Computation},
	Year = {2005}}

@inproceedings{Axelsson13,
	Acmid = {2500614},
	Address = {New York, NY, USA},
	Author = {Axelsson, Emil and Claessen, Koen},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-10-02 11:47:06 +0000},
	Date-Modified = {2013-10-02 11:47:07 +0000},
	Doi = {10.1145/2500365.2500614},
	Isbn = {978-1-4503-2326-0},
	Keywords = {circular programming, embedded languages, higher-order syntax},
	Location = {Boston, Massachusetts, USA},
	Numpages = {6},
	Pages = {257--262},
	Publisher = {ACM},
	Series = {ICFP '13},
	Title = {Using circular programs for higher-order syntax: functional pearl},
	Url = {http://doi.acm.org/10.1145/2500365.2500614},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500614},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500614}}

@inproceedings{Brown11,
	Abstract = {Computing systems are becoming increasingly parallel and heterogeneous, and therefore new applications must be capable of exploiting parallelism in order to continue achieving high performance. However, targeting these emerging devices often requires using multiple disparate programming models and making decisions that can limit forward scalability. In previous work we proposed the use of domain-specific languages (DSLs) to provide high-level abstractions that enable transformations to high performance parallel code without degrading programmer productivity. In this paper we present a new end-to-end system for building, compiling, and executing DSL applications on parallel heterogeneous hardware, the Delite Compiler Framework and Runtime. The framework lifts embedded DSL applications to an intermediate representation (IR), performs generic, parallel, and domain-specific optimizations, and generates an execution graph that targets multiple heterogeneous hardware devices. Finally we present results comparing the performance of several machine learning applications written in OptiML, a DSL for machine learning that utilizes Delite, to C++ and MATLAB implementations. We find that the implicitly parallel OptiML applications achieve single-threaded performance comparable to C++ and outperform explicitly parallel MATLAB in nearly all cases.},
	Author = {Brown, K.J. and Sujeeth, A.K. and Hyouk Joong Lee and Rompf, T. and Chafi, H. and Odersky, M. and Olukotun, K.},
	Booktitle = {Parallel Architectures and Compilation Techniques (PACT), 2011 International Conference on},
	Date-Added = {2013-08-03 15:57:23 +0000},
	Date-Modified = {2013-08-03 15:57:24 +0000},
	Doi = {10.1109/PACT.2011.15},
	Issn = {1089-795X},
	Keywords = {C++ language;learning (artificial intelligence);parallel processing;program compilers;C++ language;Delite compiler framework;Matlab;OptiML;domain-specific language;execution graph;heterogeneous parallel framework;high performance parallel code;high-level abstraction;machine learning application;parallelism;programmer productivity;runtime application;single-threaded performance;DSL;Hardware;Optimization;Parallel processing;Performance evaluation;Programming;Runtime;computer languages;multicore processing;parallel programming},
	Pages = {89-100},
	Title = {A Heterogeneous Parallel Framework for Domain-Specific Languages},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/PACT.2011.15}}

@inproceedings{Odersky05,
	Acmid = {1094815},
	Address = {New York, NY, USA},
	Author = {Odersky, Martin and Zenger, Matthias},
	Booktitle = oopsla,
	Date-Added = {2013-08-03 15:46:57 +0000},
	Date-Modified = {2013-08-03 15:47:12 +0000},
	Doi = {10.1145/1094811.1094815},
	Isbn = {1-59593-031-0},
	Keywords = {Scala, abstract types, classes, components, mixins},
	Location = {San Diego, CA, USA},
	Numpages = {17},
	Pages = {41--57},
	Publisher = {ACM},
	Series = {OOPSLA '05},
	Title = {Scalable component abstractions},
	Url = {http://doi.acm.org/10.1145/1094811.1094815},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094811.1094815},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094811.1094815}}

@article{Guttag78,
	Abstract = {There have been many recent proposals for embedding abstract data types in programming languages. In order to reason about programs using abstract data types, it is desirable to specify their properties at an abstract level, independent of any particular implementation. This paper presents an algebraic technique for such specifications, develops some of the formal properties of the technique, and shows that these provide useful guidelines for the construction of adequate specifications.},
	Author = {Guttag, J.V. and Horning, J.J.},
	Date-Added = {2013-07-13 12:46:23 +0000},
	Date-Modified = {2013-07-13 12:46:23 +0000},
	Doi = {10.1007/BF00260922},
	Issn = {0001-5903},
	Journal = {Acta Informatica},
	Language = {English},
	Number = {1},
	Pages = {27-52},
	Publisher = {Springer-Verlag},
	Title = {The algebraic specification of abstract data types},
	Url = {http://dx.doi.org/10.1007/BF00260922},
	Volume = {10},
	Year = {1978},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BF00260922}}

@article{LiuSkalka11staged,
	Annote = {Staging is a powerful language construct that allows a program at one stage of evaluation to manipulate and specialize a program to be executed at a later stage. We propose a new staged language calculus, „ÄàML„Äâ, which extends the programmability of staged languages in two directions. First, „ÄàML„Äâ supports dynamic type specialization: types can be dynamically constructed, abstracted, and passed as arguments, while preserving decidable typechecking via a System F‚â§-style semantics combined with a restricted form of Œª œâ -style runtime type construction. With dynamic type specialization the data structure layout of a program can be optimized via staging. Second, „ÄàML„Äâ works in a context where different stages of computation are executed in different process spaces, a property we term staged process separation. Programs at different stages can directly communicate program data in „ÄàML„Äâ via a built-in serialization discipline. The language „ÄàML„Äâ is endowed with a metatheory including type preservation, type safety, and decidability as demonstrated constructively by a sound type checking algorithm. While our language design is general, we are particularly interested in future applications of staging in resource-constrained and embedded systems: these systems have limited space for code and data, as well as limited CPU time, and specializing code for the particular deployment at hand can improve efficiency in all of these dimensions. The combination of dynamic type specialization and staging across processes greatly increases the utility of staged programming in these domains. We illustrate this via wireless sensor network programming examples.},
	Author = {Liu, Yu David and Skalka, Christian and Smith, Scott F.},
	Date-Added = {2013-06-30 06:59:47 +0000},
	Date-Modified = {2013-06-30 07:00:45 +0000},
	Doi = {10.1007/s10990-012-9089-0},
	Issn = {1388-3690},
	Journal = hosc,
	Keywords = {Programming languages; Access control; Wireless sensor networks; Type safety; Program specialization},
	Language = {English},
	Number = {4},
	Pages = {341-385},
	Publisher = {Springer US},
	Title = {Type-specialized staged programming with process separation},
	Url = {http://dx.doi.org/10.1007/s10990-012-9089-0},
	Volume = {24},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-012-9089-0}}

@inproceedings{Salvaneschi13reactive,
	Abstract = {Reactive applications are difficult to implement. Traditional solutions based on event systems and the Observer pattern have a number of inconveniences, but programmers bear them in return for the benefits of OO design. On the other hand, reactive approaches based on automatic updates of dependencies - like functional reactive programming and dataflow languages - provide undoubted advantages but do not fit well with mutable objects. In this paper, we provide a research roadmap to overcome the limitations of the current approaches and to support reactive applications in the OO setting. To establish a solid background for our investigation, we propose a conceptual framework to model the design space of reactive applications and we study the flaws of the existing solutions. Then we highlight how reactive languages have the potential to address those issues and we formulate our research plan.},
	Acmid = {2451442},
	Address = acmaddr,
	Author = {Salvaneschi, Guido and Mezini, Mira},
	Booktitle = aosd,
	Date-Added = {2013-06-27 08:23:04 +0000},
	Date-Modified = {2013-06-27 19:17:18 +0000},
	Keywords = {functional-reactive programming, incremental computation, object-oriented programming, reactive programming},
	Location = {Fukuoka, Japan},
	Nodoi = {10.1145/2451436.2451442},
	Noisbn = {978-1-4503-1766-5},
	Noseries = {AOSD '13},
	Nourl = {http://doi.acm.org/10.1145/2451436.2451442},
	Numpages = {12},
	Pages = {37--48},
	Publisher = acm,
	Title = {Reactive behavior in object-oriented applications: an analysis and a research roadmap},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2451436.2451442},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2451436.2451442}}

@inproceedings{Scherer13GADTSub,
	Abstract = {While generalized algebraic datatypes (GADTs) are now considered well-understood, adding them to a language with a notion of subtyping comes with a few surprises. What does it mean for a GADT parameter to be covariant? The answer turns out to be quite subtle. It involves fine-grained properties of the subtyping relation that raise interesting design questions. We allow variance annotations in GADT definitions, study their soundness, and present a sound and complete algorithm to check them. Our work may be applied to real-world ML-like languages with explicit subtyping such as OCaml, or to languages with general subtyping constraints.},
	Acmid = {2450309},
	Author = {Scherer, Gabriel and R{\'e}my, Didier},
	Booktitle = {ESOP},
	Date-Added = {2013-06-26 19:10:57 +0000},
	Date-Modified = {2013-06-26 19:11:46 +0000},
	Location = {Rome, Italy},
	Noaddress = {Berlin, Heidelberg},
	Nobooktitle = {Proceedings of the 22nd European conference on Programming Languages and Systems},
	Nodoi = {10.1007/978-3-642-37036-6_30},
	Noisbn = {978-3-642-37035-9},
	Noseries = {ESOP'13},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-37036-6_30},
	Numpages = {20},
	Pages = {554--573},
	Publisher = {Springer-Verlag},
	Title = {{GADTs} meet subtyping},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-37036-6_30}}

@inproceedings{Reichenbach12PQL,
	Acmid = {2367169},
	Address = {Berlin, Heidelberg},
	Author = {Reichenbach, Christoph and Smaragdakis, Yannis and Immerman, Neil},
	Booktitle = ecoop,
	Date-Added = {2013-06-25 16:00:48 +0000},
	Date-Modified = {2013-06-25 16:01:10 +0000},
	Doi = {10.1007/978-3-642-31057-7_4},
	Isbn = {978-3-642-31056-0},
	Location = {Beijing, China},
	Numpages = {26},
	Pages = {53--78},
	Publisher = {Springer-Verlag},
	Series = {ECOOP'12},
	Title = {PQL: a purely-declarative {Java} extension for parallel programming},
	Url = {http://dx.doi.org/10.1007/978-3-642-31057-7_4},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-31057-7_4}}

@inproceedings{Altenkirch07OE,
	Acmid = {1292608},
	Author = {Altenkirch, Thorsten and McBride, Conor and Swierstra, Wouter},
	Booktitle = plpv,
	Date-Added = {2013-06-25 00:02:01 +0000},
	Date-Modified = {2013-06-25 00:02:20 +0000},
	Keywords = {equality, type theory},
	Location = {Freiburg, Germany},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1292597.1292608},
	Noisbn = {978-1-59593-677-6},
	Noseries = {PLPV '07},
	Nourl = {http://doi.acm.org/10.1145/1292597.1292608},
	Numpages = {12},
	Pages = {57--68},
	Publisher = {ACM},
	Title = {Observational equality, now!},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1292597.1292608},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1292597.1292608}}

@book{Mitchell1996foundations,
	Author = {Mitchell, John C.},
	Date-Added = {2013-06-20 23:23:51 +0000},
	Date-Modified = {2013-06-20 23:23:51 +0000},
	Publisher = {MIT Press},
	Title = {Foundations of programming languages},
	Year = {1996}}

@inproceedings{Jategaonkar88,
	Acmid = {62702},
	Address = {New York, NY, USA},
	Author = {Jategaonkar, Lalita and Mitchell, John},
	Booktitle = {Proceedings of the 1988 ACM conference on LISP and functional programming},
	Date-Added = {2013-06-20 16:24:48 +0000},
	Date-Modified = {2013-06-20 16:24:48 +0000},
	Doi = {10.1145/62678.62702},
	Isbn = {0-89791-273-X},
	Location = {Snowbird, Utah, USA},
	Numpages = {14},
	Pages = {198--211},
	Publisher = {ACM},
	Series = {LFP '88},
	Title = {ML with extended pattern matching and subtypes},
	Url = {http://doi.acm.org/10.1145/62678.62702},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62702},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62702}}

@article{Paige82FDC,
	Acmid = {357177},
	Address = acmaddr,
	Author = {Paige, Robert and Koenig, Shaye},
	Date-Added = {2013-06-20 16:24:35 +0000},
	Date-Modified = {2013-06-20 16:24:35 +0000},
	Issue_Date = {July 1982},
	Journal = toplas,
	Keywords = {incremental computation},
	Month = jul,
	Nodoi = {10.1145/357172.357177},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/357172.357177},
	Number = {3},
	Numpages = {53},
	Pages = {402--454},
	Publisher = {ACM},
	Title = {Finite Differencing of Computable Expressions},
	Volume = {4},
	Year = {1982},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/357172.357177},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/357172.357177}}

@article{Blass92,
	Abstract = {We present a game (or dialogue) semantics in the style of Lorenzen (1959) for Girard's linear logic (1987). Lorenzen suggested that the (constructive) meaning of a proposition œï should be specified by telling how to conduct a debate between a proponent P who asserts œï and an opponent O who denies œï. Thus propositions are interpreted as games, connectives (almost) as operations on games, and validity as existence of a winning strategy for P. (The qualifier `almost' will be discussed later when more details have been presented.) We propose that the connectives of linear logic can be naturally interpreted as the operations on games introduced for entirely different purposes by Blass (1972). We show that affine logic, i.e., linear logic plus the rule of weakening, is sound for this interpretation. We also obtain a completeness theorem for the additive fragment of affine logic, but we show that completeness fails for the multiplicative fragment. On the other hand, for the multiplicative fragment, we obtain a simple characterization of game-semantical validity in terms of classical tautologies. An analysis of the failure of completeness for the multiplicative fragment leads to the conclusion that the game interpretation of the connective ‚äó is weaker than the interpretation implicit in Girard's proof rules; we discuss the differences between the two interpretations and their relative advantages and disadvantages. Finally, we discuss how G{\"o}del's Dialectica interpretation (1958), which was connected to linear logic by de Paiva (1989), fits with game semantics. },
	Author = {Andreas Blass},
	Date-Added = {2013-06-13 10:07:37 +0000},
	Date-Modified = {2013-06-13 10:07:40 +0000},
	Doi = {10.1016/0168-0072(92)90073-9},
	Issn = {0168-0072},
	Journal = {Annals of Pure and Applied Logic},
	Number = {1--3},
	Pages = {183 - 220},
	Title = {A game semantics for linear logic},
	Url = {http://www.sciencedirect.com/science/article/pii/0168007292900739},
	Volume = {56},
	Year = {1992},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0168007292900739},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0168-0072(92)90073-9}}

@inproceedings{Liu99a,
	Acmid = {328700},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Stoller, Scott D.},
	Booktitle = {Proceedings of the 2000 ACM SIGPLAN workshop on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-10 20:44:33 +0000},
	Date-Modified = {2013-06-10 20:44:55 +0000},
	Doi = {10.1145/328690.328700},
	Isbn = {1-58113-201-8},
	Keywords = {incremental computation; optimization},
	Location = {Boston, Massachusetts, USA},
	Numpages = {10},
	Pages = {73--82},
	Publisher = {ACM},
	Series = {PEPM '00},
	Title = {From recursion to iteration: what are the optimizations?},
	Url = {http://doi.acm.org/10.1145/328690.328700},
	Year = {1999},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/328690.328700},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/328690.328700}}

@inproceedings{Emir07Correct,
	Abstract = {Pattern matching makes ML programs more concise and readable, and these qualities are also sought in object-oriented settings. However, objects and classes come with open class hierarchies, extensibility requirements and the need for data abstraction, which all conflict with matching on concrete data types. Extractor-based pattern matching has been proposed to address this conflict. Extractors are user-defined methods that perform the task of value discrimination and deconstruction during pattern matching. In this paper, we give the first formalization of extractor-based matching, using a first-order object-oriented calculus. We give a direct operational semantics and prove it sound. We then present an optimizing translation to a target language without matching, and prove a correctness result stating that an expression is equivalent to its translation.},
	Acmid = {1784782},
	Address = {Berlin, Heidelberg},
	Author = {Emir, Burak and Ma, Qin and Odersky, Martin},
	Booktitle = {Proceedings of the 5th Asian conference on Programming languages and systems},
	Date-Added = {2013-06-09 13:38:40 +0000},
	Date-Modified = {2013-06-09 13:39:51 +0000},
	Isbn = {3-540-76636-7, 978-3-540-76636-0},
	Location = {Singapore},
	Numpages = {17},
	Pages = {54--70},
	Publisher = {Springer-Verlag},
	Series = {APLAS'07},
	Title = {Translation Correctness for First-Order Object-Oriented Pattern Matching},
	Url = {http://dl.acm.org/citation.cfm?id=1784774.1784782},
	Year = {2007},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1784774.1784782}}

@incollection{wadler1993taste,
	Author = {Wadler, Philip},
	Booktitle = {Mathematical Foundations of Computer Science 1993},
	Date-Added = {2013-06-06 17:10:01 +0000},
	Date-Modified = {2013-06-06 17:10:01 +0000},
	Pages = {185--210},
	Publisher = {Springer},
	Title = {A taste of linear logic},
	Year = {1993}}

@book{girard1989proofs,
	Annote = {Wadler cites it in \cite{wadler1993taste} by saying "see the wonderful introduction by Girard, Lafont and Taylor \cite{girard1989proofs}". However, everybody keeps telling me that this book is horrible.},
	Author = {Girard, Jean-Yves and Taylor, Paul and Lafont, Yves},
	Date-Added = {2013-06-06 17:09:13 +0000},
	Date-Modified = {2013-06-06 17:11:20 +0000},
	Publisher = {Cambridge University Press Cambridge},
	Title = {Proofs and types},
	Volume = {7},
	Year = {1989}}

@incollection{Emir06Variance,
	Abstract = {Generic types in C ‚ôØ behave invariantly with respect to subtyping. We propose a system of type-safe variance for C ‚ôØ that supports the declaration of covariant and contravariant type parameters on generic types. To support more widespread application of variance we also generalize the existing constraint mechanism with arbitrary subtype assertions on classes and methods. This extension is useful even in the absence of variance, and subsumes equational constraints proposed for Generalized Algebraic Data Types (GADTs). We formalize the subtype relation in both declarative and syntax-directed style, and describe and prove the correctness of algorithms for constraint closure and subtyping. Finally, we formalize and prove a type safety theorem for a featherweight language with variant classes and generalized constraints.},
	Author = {Emir, Burak and Kennedy, Andrew and Russo, Claudio and Yu, Dachuan},
	Booktitle = ecoop,
	Date-Added = {2013-06-06 16:57:54 +0000},
	Date-Modified = {2013-06-06 16:58:39 +0000},
	Nobooktitle = {ECOOP 2006 -- Object-Oriented Programming},
	Nodoi = {10.1007/11785477_18},
	Noeditor = {Thomas, Dave},
	Noisbn = {978-3-540-35726-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/11785477_18},
	Novolume = {4067},
	Pages = {279-303},
	Publisher = springer,
	Title = {Variance and Generalized Constraints for {C}$^\sharp$ Generics},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11785477_18}}

@inproceedings{Liu95a,
	Abstract = {The paper describes the design and implementation of an interactive, incremental-attribution-based program transformation system, CACHET, that derives incremental programs from non-incremental programs written in a functional language. CACHET is designed as a programming environment and implemented using a language-based editor generator, the Synthesizer Generator, with extensions that support complex transformations. Transformations directly manipulate the program tree and take into consideration information obtained from program analyses. Program analyses are performed via attribute evaluation, which is done incrementally as transformations change the program tree. The overall approach also explores a general framework for describing dynamic program semantics using annotations, which allows interleaving transformations with external input, such as user input. Designing CACHET as a programming environment also facilitates the integration of program derivation and validation with interactive editing, compiling, debugging, and execution},
	Author = {Liu, Y.A.},
	Booktitle = {Proceedings 10th Knowledge-Based Software Engineering Conference.},
	Date-Added = {2013-06-05 13:01:04 +0000},
	Date-Modified = {2013-06-09 15:30:00 +0000},
	Doi = {10.1109/KBSE.1995.490115},
	Issn = {1068-3062},
	Keywords = {attribute grammars;functional programming;incremental compilers;interactive programming;knowledge based systems;program debugging;program verification;programming environments;software tools;system monitoring;CACHET programming environment;Synthesizer Generator;annotations;attribute evaluation;compiling;complex transformations;debugging;dynamic program semantics;execution;external input;functional language;incremental program derivation;interactive editing;interactive incremental-attribution-based program transformation system;interleaving transformations;language-based editor generator;nonincremental programs;program analyses;program derivation;program tree;program validation;user input;Computer science;Contracts;Databases;Information analysis;Interleaved codes;Performance analysis;Performance evaluation;Programming environments;Synthesizers;Usability; incremental computation},
	Pages = {19-26},
	Title = {CACHET: an interactive, incremental-attribution-based program transformation system for deriving incremental programs},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/KBSE.1995.490115}}

@incollection{Liu99,
	Abstract = {Dynamic programming is an important algorithm design technique. It is used for solving problems whose solutions involve recursively solving subproblems that share subsubproblems. While a straightforward recursive program solves common subsubproblems repeatedly and often takes exponential time, a dynamic programming algorithm solves every subsubproblem just once, saves the result, reuses it when the subsubproblem is encountered again, and takes polynomial time. This paper describes a systematic method for transforming programs written as straightforward recursions into programs that use dynamic programming. The method extends the original program to cache all possibly computed values, incrementalizes the extended program with respect to an input increment to use and maintain all cached results, prunes out cached results that are not used in the incremental computation, and uses the resulting incremental program to form an optimized new program. Incrementalization statically exploits semantics of both control structures and data structures and maintains as invariants equalities characterizing cached results. The principle underlying incrementalization is general for achieving drastic program speedups. Compared with previous methods that perform memoization or tabulation, the method based on incrementalization is more powerful and systematic. It has been implemented and applied to numerous problems and succeeded on all of them.},
	Author = {Liu, Yanhong A. and Stoller, Scott D.},
	Booktitle = {Programming Languages and Systems},
	Date-Added = {2013-06-05 12:58:35 +0000},
	Date-Modified = {2014-01-21 11:47:22 +0000},
	Doi = {10.1007/3-540-49099-X_19},
	Editor = {Swierstra, S.Doaitse},
	Isbn = {978-3-540-65699-9},
	Keywords = {incremental computation},
	Language = {English},
	Pages = {288-305},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Dynamic Programming via Static Incrementalization},
	Url = {http://dx.doi.org/10.1007/3-540-49099-X_19},
	Volume = {1576},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-49099-X_19}}

@article{Loader01,
	Abstract = {The question of the decidability of the observational ordering of finitary \{PCF\} was raised (Jung and Stoughton, in: M. Bezem, J.F. Groote (Eds.), Typed Lambda Calculi and Applications, Lecture Notes in Computer Science, vol. 664, Springer, Berlin, 1993, pp. 230--244) to give mathematical content to the full abstraction problem for \{PCF\} (Milner, Theoret. Comput. Sci. 4 (1977) 1--22). We show that the ordering is in fact undecidable. This result places limits on how explicit a representation of the fully abstract model can be. It also gives a slight strengthening of the author's earlier result on typed Œª-definability (Loader, in: A. Anderson, M. Zeleny (Eds.), Church Memorial Volume, Kluwer Academic Press, Dordrecht, to appear). },
	Author = {Ralph Loader},
	Date-Added = {2013-06-05 12:45:07 +0000},
	Date-Modified = {2013-06-05 12:57:07 +0000},
	Doi = {10.1016/S0304-3975(00)00194-8},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {Full abstraction},
	Number = {1--2},
	Pages = {341 - 364},
	Title = {Finitary {PCF} is not decidable},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304397500001948},
	Volume = {266},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304397500001948},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S0304-3975(00)00194-8}}

@article{Liu00,
	Abstract = {Incremental computation takes advantage of repeated computations on inputs that differ slightly from one another, computing each output efficiently by exploiting the previous output. This paper gives an overview of a general and systematic approach to incrementalization: given a program f and an operation ‚äï, the approach yields an incremental program that computes f(x ‚äï y) efficiently by using the result of f(x), the intermediate results of f(x), and auxiliary information of f(x) that can be inexpensively maintained.
Since every non-trivial computation proceeds by iteration or recursion, the approach can be used for achieving efficient computation by computing each iteration incrementally using an appropriate incremental program. This approach has applications in interactive systems, optimizing compilers, transformational programming, and many other areas, where problems were previously solved in less general and systematic ways. This paper also describes the design and implementation of CACHET, a prototype system for incrementalization.},
	Author = {Liu, Yanhong A.},
	Date-Added = {2013-06-04 21:38:00 +0000},
	Date-Modified = {2013-06-04 21:38:12 +0000},
	Journal = hosc,
	Keywords = {caching; incremental computation; incremental programs; incrementalization; program analysis; program optimization; program transformation; programming environments},
	Language = {English},
	Nodoi = {10.1023/A:1026547031739},
	Noissn = {1388-3690},
	Nourl = {http://dx.doi.org/10.1023/A%3A1026547031739},
	Number = {4},
	Pages = {289-313},
	Publisher = kluwer,
	Title = {Efficiency by Incrementalization: An Introduction},
	Volume = {13},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A%3A1026547031739},
	Bdsk-Url-2 = {http://dx.doi.org/10.1023/A:1026547031739}}

@inproceedings{Zhang98,
	Acmid = {289480},
	Address = {New York, NY, USA},
	Author = {Zhang, Yuchen and Lin, Yanhong A.},
	Booktitle = ICFP,
	Date-Added = {2013-06-04 18:00:17 +0000},
	Date-Modified = {2013-06-04 18:04:37 +0000},
	Doi = {10.1145/289423.289480},
	Isbn = {1-58113-024-4},
	Location = {Baltimore, Maryland, USA},
	Pages = {350},
	Publisher = {ACM},
	Series = {ICFP '98},
	Title = {Automating derivation of incremental programs},
	Url = {http://doi.acm.org/10.1145/289423.289480},
	Year = {1998},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/289423.289480},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/289423.289480}}

@inproceedings{Liu95,
	Acmid = {215590},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Teitelbaum, Tim},
	Booktitle = {Proceedings of the 1995 ACM SIGPLAN symposium on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-04 17:18:24 +0000},
	Date-Modified = {2013-06-09 15:30:00 +0000},
	Doi = {10.1145/215465.215590},
	Isbn = {0-89791-720-0},
	Keywords = {incremental computation},
	Location = {La Jolla, California, USA},
	Numpages = {12},
	Pages = {190--201},
	Publisher = {ACM},
	Series = {PEPM '95},
	Title = {Caching intermediate results for program improvement},
	Url = {http://doi.acm.org/10.1145/215465.215590},
	Year = {1995},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/215465.215590},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/215465.215590}}

@article{Liu98,
	Acmid = {291895},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Stoller, Scott D. and Teitelbaum, Tim},
	Date-Added = {2013-06-04 17:18:09 +0000},
	Date-Modified = {2013-06-04 17:18:11 +0000},
	Doi = {10.1145/291889.291895},
	Issn = {0164-0925},
	Issue_Date = {May 1998},
	Journal = toplas,
	Keywords = {caching, dependence analysis, incremental computation, incremental programs, intermediate results, memoization, optimization, program efficiency improvement, program transformation, static analysis},
	Month = may,
	Number = {3},
	Numpages = {40},
	Pages = {546--585},
	Publisher = {ACM},
	Title = {Static caching for incremental computation},
	Url = {http://doi.acm.org/10.1145/291889.291895},
	Volume = {20},
	Year = {1998},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/291889.291895},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/291889.291895}}

@inproceedings{Sundaresh91a,
	Acmid = {115875},
	Address = {New York, NY, USA},
	Author = {Sundaresh, R. S.},
	Booktitle = {Proceedings of the 1991 ACM SIGPLAN symposium on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-04 12:57:23 +0000},
	Date-Modified = {2014-02-08 19:58:00 +0000},
	Doi = {10.1145/115865.115875},
	Isbn = {0-89791-433-3},
	Keywords = {incremental computation},
	Location = {New Haven, Connecticut, USA},
	Numpages = {11},
	Pages = {83--93},
	Publisher = {ACM},
	Series = {PEPM '91},
	Title = {Building incremental programs using partial evaluation},
	Url = {http://doi.acm.org/10.1145/115865.115875},
	Year = {1991},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/115865.115875},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/115865.115875}}

@inproceedings{Sundaresh91,
	Acmid = {99587},
	Address = acmaddr,
	Annote = {Also titled:
Incremental Computation via Partial Evaluation},
	Author = {Sundaresh, R. S. and Hudak, Paul},
	Booktitle = popl,
	Date-Added = {2013-06-04 03:21:53 +0000},
	Date-Modified = {2014-02-08 19:59:08 +0000},
	Keywords = {incremental computation},
	Location = {Orlando, Florida, USA},
	Nodoi = {10.1145/99583.99587},
	Noisbn = {0-89791-419-8},
	Noseries = {POPL '91},
	Nourl = {http://doi.acm.org/10.1145/99583.99587},
	Numpages = {13},
	Pages = {1--13},
	Publisher = {ACM},
	Title = {A theory of incremental computation and its application},
	Year = {1991},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/99583.99587},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/99583.99587}}

@article{Acar09EAS,
	Abstract = {Recent work on adaptive functional programming (AFP) developed techniques for writing programs that can respond to modifications to their data by performing change propagation. To achieve this, executions of programs are represented with dynamic dependence graphs (DDGs) that record data dependences and control dependences in a way that a change-propagation algorithm can update the computation as if the program were from scratch, by re-executing only the parts of the computation affected by the changes. Since change-propagation only re-executes parts of the computation, it can respond to certain incremental modifications asymptotically faster than recomputing from scratch, potentially offering significant speedups. Such asymptotic speedups, however, are rare: for many computations and modifications, change propagation is no faster than recomputing from scratch.

In this article, we realize a duality between dynamic dependence graphs and memoization, and combine them to give a change-propagation algorithm that can dramatically increase computation reuse. The key idea is to use DDGs to identify and re-execute the parts of the computation that are affected by modifications, while using memoization to identify the parts of the computation that remain unaffected by the changes. We refer to this approach as self-adjusting computation. Since DDGs are imperative, but (traditional) memoization requires purely functional computation, reusing computation correctly via memoization becomes a challenge. We overcome this challenge with a technique for remembering and reusing not just the results of function calls (as in conventional memoization), but their executions represented with DDGs. We show that the proposed approach is realistic by describing a library for self-adjusting computation, presenting efficient algorithms for realizing the library, and describing and evaluating an implementation. Our experimental evaluation with a variety of applications, ranging from simple list primitives to more sophisticated computational geometry algorithms, shows that the approach is effective in practice: compared to recomputing from-scratch; self-adjusting programs respond to small modifications to their data orders of magnitude faster.},
	Acmid = {1596530},
	Address = acmaddr,
	Articleno = {3},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Blume, Matthias and Harper, Robert and Tangwongsan, Kanat},
	Date-Added = {2013-05-31 15:54:36 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Issue_Date = {October 2009},
	Journal = toplas,
	Keywords = {Computational geometry, dynamic algorithms, dynamic dependence graphs, memoization, performance, self-adjusting computation; incremental computation},
	Month = nov,
	Nodoi = {10.1145/1596527.1596530},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/1596527.1596530},
	Number = {1},
	Numpages = {53},
	Pages = {3:1--3:53},
	Publisher = {ACM},
	Title = {An experimental analysis of self-adjusting computation},
	Volume = {32},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596527.1596530},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596527.1596530}}

@inproceedings{Acar10TDT,
	Abstract = {Self-adjusting computation provides an evaluation model where computations can respond automatically to modifications to their data by using a mechanism for propagating modifications through the computation. Current approaches to self-adjusting computation guarantee correctness by recording dependencies in a trace at the granularity of individual memory operations. Tracing at the granularity of memory operations, however, has some limitations: it can be asymptotically inefficient (\eg, compared to optimal solutions) because it cannot take advantage of problem-specific structure, it requires keeping a large computation trace (often proportional to the runtime of the program on the current input), and it introduces moderately large constant factors in practice.

In this paper, we extend dependence-tracing to work at the granularity of the query and update operations of arbitrary (abstract) data types, instead of just reads and writes on memory cells. This can significantly reduce the number of dependencies that need to be kept in the trace and followed during an update. We define an interface for supporting a traceable version of a data type, which reports the earliest query that depends on (is changed by) revising operations back in time, and implement several such structures, including priority queues, queues, dictionaries, and counters. We develop a semantics for tracing, extend an existing self-adjusting language, ŒîML, and its implementation to support traceable data types, and present an experimental evaluation by considering a number of benchmarks. Our experiments show dramatic improvements on space and time, sometimes by as much as two orders of magnitude.},
	Acmid = {1806650},
	Address = acmaddr,
	Author = {Acar, Umut A. and Blelloch, Guy and Ley-Wild, Ruy and Tangwongsan, Kanat and Turkoglu, Duru},
	Booktitle = pldi,
	Date-Added = {2013-05-31 15:46:14 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation, traceable data types; incremental computation},
	Location = {Toronto, Ontario, Canada},
	Nodoi = {10.1145/1806596.1806650},
	Noisbn = {978-1-4503-0019-3},
	Noseries = {PLDI '10},
	Nourl = {http://doi.acm.org/10.1145/1806596.1806650},
	Numpages = {14},
	Pages = {483--496},
	Publisher = {ACM},
	Title = {Traceable data types for self-adjusting computation},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1806596.1806650},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1806596.1806650}}

@incollection{Acar07,
	Abstract = {This paper presents a semantics of self-adjusting computation and proves that the semantics is correct and consistent. The semantics integrates change propagation with the classic idea of memoization to enable reuse of computations under mutation to memory. During evaluation, reuse of a computation via memoization triggers a change propagation that adjusts the reused computation to reflect the mutated memory. Since the semantics combines memoization and change-propagation, it involves both non-determinism and mutation. Our consistency theorem states that the non-determinism is not harmful: any two evaluations of the same program starting at the same state yield the same result. Our correctness theorem states that mutation is not harmful: self-adjusting programs are consistent with purely functional programming. We formalized the semantics and its meta-theory in the LF logical framework and machine-checked the proofs in Twelf.},
	Author = {Acar, UmutA. and Blume, Matthias and Donham, Jacob},
	Booktitle = {Programming Languages and Systems},
	Date-Added = {2013-05-31 15:36:47 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1007/978-3-540-71316-6_31},
	Editor = {Nicola, Rocco},
	Isbn = {978-3-540-71314-2},
	Keywords = {self-adjusting computation; incremental computation},
	Pages = {458-474},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A Consistent Semantics of Self-adjusting Computation},
	Url = {http://dx.doi.org/10.1007/978-3-540-71316-6_31},
	Volume = {4421},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-71316-6_31}}

@inproceedings{Acar06experim,
	Abstract = {Dependence graphs and memoization can be used to efficiently update the output of a program as the input changes dynamically. Recent work has studied techniques for combining these approaches to effectively dynamize a wide range of applications. Toward this end various theoretical results were given. In this paper we describe the implementation of a library based on these ideas, and present experimental results on the efficiency of this library on a variety of applications. The results of the experiments indicate that the approach is effective in practice, often requiring orders of magnitude less time than recomputing the output from scratch. We believe this is the first experimental evidence that incremental computation of any type is effective in practice for a reasonably broad set of applications.},
	Acmid = {1133993},
	Address = {New York, NY, USA},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Blume, Matthias and Tangwongsan, Kanat},
	Booktitle = {Proceedings of the 2006 ACM SIGPLAN conference on Programming language design and implementation},
	Date-Added = {2013-05-31 13:43:14 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1133981.1133993},
	Isbn = {1-59593-320-4},
	Keywords = {computational geometry, dynamic algorithms, dynamic dependence graphs, memorization, performance, self-adjusting computation; incremental computation},
	Location = {Ottawa, Ontario, Canada},
	Numpages = {12},
	Pages = {96--107},
	Publisher = {ACM},
	Series = {PLDI '06},
	Title = {An experimental analysis of self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1133981.1133993},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1133981.1133993},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1133981.1133993}}

@article{Acar06Lib,
	Abstract = {We present a Standard ML library for writing programs that automatically adjust to changes to their data. The library combines modifiable references and memoization to achieve efficient updates. We describe an implementation of the library and apply it to the problem of maintaining the convex hull of a dynamically changing set of points. Our experiments show that the overhead of the library is small, and that self-adjusting programs can adjust to small changes three-orders of magnitude faster than recomputing from scratch. The implementation relies on invariants that could be enforced by a modal type system. We show, using an existing language, abstract interfaces for modifiable references and for memoization that ensure the same safety properties without the use of modal types. The interface for memoization, however, does not scale well, suggesting a language-based approach to be preferable after all. },
	Author = {Umut Acar and Guy Blelloch and Matthias Blume and Robert Harper and Kanat Tangwongsan},
	Date-Added = {2013-05-31 13:41:06 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1016/j.entcs.2005.11.043},
	Issn = {1571-0661},
	Journal = {Electronic Notes in Theoretical Computer Science},
	Keywords = {quickhull; self-adjusting computation; incremental computation},
	Note = {<ce:title>Proceedings of the ACM-SIGPLAN Workshop on \{ML\} (ML 2005)</ce:title> <xocs:full-name>ACM-SIGPLAN Workshop on \{ML\} 2005</xocs:full-name>},
	Number = {2},
	Pages = {127 - 154},
	Title = {A Library for Self-Adjusting Computation},
	Url = {http://www.sciencedirect.com/science/article/pii/S1571066106001290},
	Volume = {148},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1571066106001290},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.entcs.2005.11.043}}

@inproceedings{Acar09,
	Abstract = {Many applications need to respond to incremental modifications to data. Being incremental, such modification often require incremental modifications to the output, making it possible to respond to them asymptotically faster than recomputing from scratch. In many cases, taking advantage of incrementality therefore dramatically improves performance, especially as the input size increases. As a frame of reference, note that in parallel computing speedups are bounded by the number of processors, often a (small) constant.

Designing and developing applications that respond to incremental modifications, however, is challenging: it often involves developing highly specific, complex algorithms. Self-adjusting computation offers a linguistic approach to this problem. In self-adjusting computation, programs respond automatically and efficiently to modifications to their data by tracking the dynamic data dependences of the computation and incrementally updating their output as needed. In this invited talk, I present an overview of self-adjusting computation and briefly discuss the progress in developing the approach and present some recent advances.},
	Acmid = {1480946},
	Address = acmaddr,
	Author = {Acar, Umut A.},
	Booktitle = pepm,
	Date-Added = {2013-05-31 13:17:25 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {asymptotic complexity, change propagation, compilers, continuations, dependence graphs, incremental modification, language design, performance, self-adjusting computation; incremental computation},
	Location = {Savannah, GA, USA},
	Nodoi = {10.1145/1480945.1480946},
	Noisbn = {978-1-60558-327-3},
	Noseries = {PEPM '09},
	Nourl = {http://doi.acm.org/10.1145/1480945.1480946},
	Numpages = {6},
	Pages = {1--6},
	Publisher = {ACM},
	Read = {1},
	Title = {Self-adjusting computation: (an overview)},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480945.1480946},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480945.1480946}}

@inproceedings{Acar08,
	Abstract = {Self-adjusting computation enables writing programs that can automatically and efficiently respond to changes to their data (e.g., inputs). The idea behind the approach is to store all data that can change over time in modifiable references and to let computations construct traces that can drive change propagation. After changes have occurred, change propagation updates the result of the computation by re-evaluating only those expressions that depend on the changed data. Previous approaches to self-adjusting computation require that modifiable references be written at most once during execution---this makes the model applicable only in a purely functional setting.

In this paper, we present techniques for imperative self-adjusting computation where modifiable references can be written multiple times. We define a language SAIL (Self-Adjusting Imperative Language) and prove consistency, i.e., that change propagation and from-scratch execution are observationally equivalent. Since SAIL programs are imperative, they can create cyclic data structures. To prove equivalence in the presence of cycles in the store, we formulate and use an untyped, step-indexed logical relation, where step indices are used to ensure well-foundedness. We show that SAIL accepts an asymptotically efficient implementation by presenting algorithms and data structures for its implementation. When the number of operations (reads and writes) per modifiable is bounded by a constant, we show that change propagation becomes as efficient as in the non-imperative case. The general case incurs a slowdown that is logarithmic in the maximum number of such operations. We describe a prototype implementation of SAIL as a Standard ML library},
	Acmid = {1328476},
	Address = {New York, NY, USA},
	Author = {Acar, Umut A. and Ahmed, Amal and Blume, Matthias},
	Booktitle = {Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-31 13:16:36 +0000},
	Date-Modified = {2013-05-31 15:58:26 +0000},
	Doi = {10.1145/1328438.1328476},
	Isbn = {978-1-59593-689-9},
	Keywords = {change propagation, imperative programming, incremental computation, memoization, mutable state, self-adjusting computation, step-indexed logical relations},
	Location = {San Francisco, California, USA},
	Numpages = {14},
	Pages = {309--322},
	Publisher = {ACM},
	Series = {POPL '08},
	Title = {Imperative self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1328438.1328476},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1328438.1328476},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1328438.1328476}}

@inproceedings{Ley-Wild09,
	Abstract = {Self-adjusting computation is an evaluation model in which programs can respond efficiently to small changes to their input data by using a change-propagation mechanism that updates computation by re-building only the parts affected by changes. Previous work has proposed language techniques for self-adjusting computation and showed the approach to be effective in a number of application areas. However, due to the complex semantics of change propagation and the indirect nature of previously proposed language techniques, it remains difficult to reason about the efficiency of self-adjusting programs and change propagation.

In this paper, we propose a cost semantics for self-adjusting computation that enables reasoning about its effectiveness. As our source language, we consider a direct-style Œª-calculus with first-class mutable references and develop a notion of trace distance for source programs. To facilitate asymptotic analysis, we propose techniques for composing and generalizing concrete distances via trace contexts (traces with holes). We then show how to translate the source language into a self-adjusting target language such that the translation (1) preserves the extensional semantics of the source programs and the cost of from-scratch runs, and (2) ensures that change propagation between two evaluations takes time bounded by their relative distance. We consider several examples and analyze their effectiveness by considering upper and lower bounds.},
	Acmid = {1480907},
	Address = {New York, NY, USA},
	Author = {Ley-Wild, Ruy and Acar, Umut A. and Fluet, Matthew},
	Booktitle = {Proceedings of the 36th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-31 13:14:56 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1480881.1480907},
	Isbn = {978-1-60558-379-2},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Savannah, GA, USA},
	Numpages = {14},
	Pages = {186--199},
	Publisher = {ACM},
	Series = {POPL '09},
	Title = {A cost semantics for self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1480881.1480907},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480881.1480907},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480881.1480907}}

@inproceedings{Ley-Wild08,
	Abstract = {Self-adjusting programs respond automatically and efficiently to input changes by tracking the dynamic data dependences of the computation and incrementally updating the output as needed. In order to identify data dependences, previously proposed approaches require the user to make use of a set of monadic primitives. Rewriting an ordinary program into a self-adjusting program with these primitives, however, can be difficult and error-prone due to various monadic and proper-usage restrictions, some of which cannot be enforced statically. Previous work therefore suggests that self-adjusting computation would benefit from direct language and compiler support.

In this paper, we propose a language-based technique for writing and compiling self-adjusting programs from ordinary programs. To compile self-adjusting programs, we use a continuation-passing style (cps) transformation to automatically infer a conservative approximation of the dynamic data dependences. To prevent the inferred, approximate dependences from degrading the performance of change propagation, we generate memoized versions of cps functions that can reuse previous work even when they are invoked with different continuations. The approach offers a natural programming style that requires minimal changes to existing code, while statically enforcing the invariants required by self-adjusting computation.

We validate the feasibility of our proposal by extending Standard ML and by integrating the transformation into MLton, a whole-program optimizing compiler for Standard ML. Our experiments indicate that the proposed compilation technique can produce self-adjusting programs whose performance is consistent with the asymptotic bounds and experimental results obtained via manual rewriting (up to a constant factor).},
	Acmid = {1411249},
	Address = {New York, NY, USA},
	Author = {Ley-Wild, Ruy and Fluet, Matthew and Acar, Umut A.},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-05-31 13:04:48 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1411204.1411249},
	Isbn = {978-1-59593-919-7},
	Keywords = {continuation-passing style, memoization, self-adjusting computation; incremental computation},
	Location = {Victoria, BC, Canada},
	Numpages = {14},
	Pages = {321--334},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Compiling self-adjusting programs with continuations},
	Url = {http://doi.acm.org/10.1145/1411204.1411249},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411249},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411249}}

@inproceedings{Sansom95,
	Acmid = {199531},
	Address = {New York, NY, USA},
	Author = {Sansom, Patrick M. and Peyton Jones, Simon L.},
	Booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-30 09:06:14 +0000},
	Date-Modified = {2013-05-30 09:06:15 +0000},
	Doi = {10.1145/199448.199531},
	Isbn = {0-89791-692-1},
	Location = {San Francisco, California, USA},
	Numpages = {12},
	Pages = {355--366},
	Publisher = {ACM},
	Series = {POPL '95},
	Title = {Time and space profiling for non-strict, higher-order functional languages},
	Url = {http://doi.acm.org/10.1145/199448.199531},
	Year = {1995},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/199448.199531},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/199448.199531}}

@inproceedings{Field90,
	Abstract = {An incremental algorithm is one that takes advantage of the fact that the function it computes is to be evaluated repeatedly on inputs that differ only slightly from one another, avoiding unnecessary duplication of common computations. We define here a new notion of incrementality for reduction in the untyped Œª-calculus and describe an incremental reduction algorithm, Œõinc. We show that Œõinc has the desirable property of performing non-overlapping reductions on related terms, yet is simple enough to allow a practical implementation. The algorithm is based on a novel Œª-reduction strategy that may prove useful in a non-incremental setting as well. Incremental Œª-reduction can be used to advantage in any setting where an algorithm is specified in a functional or applicative manner.},
	Acmid = {91679},
	Address = {New York, NY, USA},
	Author = {Field, John and Teitelbaum, Tim},
	Booktitle = {Proceedings of the 1990 ACM conference on LISP and functional programming},
	Date-Added = {2013-05-30 08:55:17 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/91556.91679},
	Isbn = {0-89791-368-X},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Nice, France},
	Numpages = {16},
	Pages = {307--322},
	Publisher = {ACM},
	Series = {LFP '90},
	Title = {Incremental reduction in the lambda calculus},
	Url = {http://doi.acm.org/10.1145/91556.91679},
	Year = {1990},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/91556.91679},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/91556.91679}}

@inproceedings{Burckhardt11,
	Abstract = {Parallel or incremental versions of an algorithm can significantly outperform their counterparts, but are often difficult to develop. Programming models that provide appropriate abstractions to decompose data and tasks can simplify parallelization. We show in this work that the same abstractions can enable both parallel and incremental execution. We present a novel algorithm for parallel self-adjusting computation. This algorithm extends a deterministic parallel programming model (concurrent revisions) with support for recording and repeating computations. On record, we construct a dynamic dependence graph of the parallel computation. On repeat, we reexecute only parts whose dependencies have changed.

We implement and evaluate our idea by studying five example programs, including a realistic multi-pass CSS layout algorithm. We describe programming techniques that proved particularly useful to improve the performance of self-adjustment in practice. Our final results show significant speedups on all examples (up to 37x on an 8-core machine). These speedups are well beyond what can be achieved by parallelization alone, while requiring a comparable effort by the programmer.},
	Acmid = {2048101},
	Author = {Burckhardt, Sebastian and Leijen, Daan and Sadowski, Caitlin and Yi, Jaeheon and Ball, Thomas},
	Booktitle = oopsla,
	Date-Added = {2013-05-29 00:10:21 +0000},
	Date-Modified = {2013-06-09 15:30:35 +0000},
	Keywords = {incremental memoization, parallel programming, incremental computation},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/2048066.2048101},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048101},
	Numpages = {18},
	Pages = {427--444},
	Publisher = acm,
	Title = {Two for the price of one: a model for parallel and incremental computation},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048101}}

@inproceedings{Hammer11,
	Abstract = {Self-adjusting computation offers a language-based approach to writing programs that automatically respond to dynamically changing data. Recent work made significant progress in developing sound semantics and associated implementations of self-adjusting computation for high-level, functional languages. These techniques, however, do not address issues that arise for low-level languages, i.e., stack-based imperative languages that lack strong type systems and automatic memory management. In this paper, we describe techniques for self-adjusting computation which are suitable for low-level languages. Necessarily, we take a different approach than previous work: instead of starting with a high-level language with additional primitives to support self-adjusting computation, we start with a low-level intermediate language, whose semantics is given by a stack-based abstract machine. We prove that this semantics is sound: it always updates computations in a way that is consistent with full reevaluation. We give a compiler and runtime system for the intermediate language used by our abstract machine. We present an empirical evaluation that shows that our approach is efficient in practice, and performs favorably compared to prior proposals.},
	Acmid = {2048124},
	Author = {Hammer, Matthew A. and Neis, Georg and Chen, Yan and Acar, Umut A.},
	Booktitle = oopsla,
	Date-Added = {2013-05-29 00:09:57 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation; incremental computation},
	Noaddress = {New York, NY, USA},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048124},
	Numpages = {20},
	Pages = {753--772},
	Publisher = acm,
	Title = {Self-adjusting stack machines},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048124}}

@inproceedings{Chen11,
	Abstract = {Computational problems that involve dynamic data, such as physics simulations and program development environments, have been an important subject of study in programming languages. Building on this work, recent advances in self-adjusting computation have developed techniques that enable programs to respond automatically and efficiently to dynamic changes in their inputs. Self-adjusting programs have been shown to be efficient for a reasonably broad range of problems but the approach still requires an explicit programming style, where the programmer must use specific monadic types and primitives to identify, create and operate on data that can change over time.

We describe techniques for automatically translating purely functional programs into self-adjusting programs. In this implicit approach, the programmer need only annotate the (top-level) input types of the programs to be translated. Type inference finds all other types, and a type-directed translation rewrites the source program into an explicitly self-adjusting target program. The type system is related to information-flow type systems and enjoys decidable type inference via constraint solving. We prove that the translation outputs well-typed self-adjusting programs and preserves the source program's input-output behavior, guaranteeing that translated programs respond correctly to all changes to their data. Using a cost semantics, we also prove that the translation preserves the asymptotic complexity of the source program.},
	Acmid = {2034792},
	Author = {Chen, Yan and Dunfield, Joshua and Hammer, Matthew A. and Acar, Umut A.},
	Booktitle = ICFP,
	Date-Added = {2013-05-28 22:25:49 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Tokyo, Japan},
	Noaddress = acmaddr,
	Nodoi = {10.1145/2034773.2034792},
	Noisbn = {978-1-4503-0865-6},
	Noseries = {ICFP '11},
	Nourl = {http://doi.acm.org/10.1145/2034773.2034792},
	Numpages = {13},
	Pages = {129--141},
	Publisher = ACM,
	Title = {Implicit self-adjusting computation for purely functional programs},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034792},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034792}}

@inproceedings{deOliveira13DataMill,
	Acmid = {2479892},
	Address = {New York, NY, USA},
	Author = {de Oliveira, Augusto Born and Petkovich, Jean-Christophe and Reidemeister, Thomas and Fischmeister, Sebastian},
	Booktitle = {Proceedings of the ACM/SPEC International conference on performance engineering},
	Date-Added = {2013-05-10 12:27:41 +0000},
	Date-Modified = {2013-05-10 12:28:28 +0000},
	Doi = {10.1145/2479871.2479892},
	Isbn = {978-1-4503-1636-1},
	Keywords = {datamill, experimentation, infrastructure, performance, repeatability, reproducibility, robustness},
	Location = {Prague, Czech Republic},
	Numpages = {12},
	Pages = {137--148},
	Publisher = {ACM},
	Series = {ICPE '13},
	Title = {DataMill: rigorous performance evaluation made easy},
	Url = {http://doi.acm.org/10.1145/2479871.2479892},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2479871.2479892},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2479871.2479892}}

@inproceedings{Tardieu12,
	Acmid = {2384675},
	Author = {Tardieu, Olivier and Nystrom, Nathaniel and Peshansky, Igor and Saraswat, Vijay},
	Booktitle = oopsla,
	Date-Added = {2013-04-19 17:55:33 +0000},
	Date-Modified = {2013-04-19 17:55:48 +0000},
	Keywords = {X10, constraints, generics, types},
	Location = {Tucson, Arizona, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/2384616.2384675},
	Noisbn = {978-1-4503-1561-6},
	Noseries = {OOPSLA '12},
	Nourl = {http://doi.acm.org/10.1145/2384616.2384675},
	Numpages = {20},
	Pages = {811--830},
	Publisher = ACM,
	Title = {Constrained kinds},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2384616.2384675},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2384616.2384675}}

@inproceedings{ChenDunfieldAcar12,
	Abstract = {Application data often changes slowly or incrementally over time. Since incremental changes to input often result in only small changes in output, it is often feasible to respond to such changes asymptotically more efficiently than by re-running the whole computation. Traditionally, realizing such asymptotic efficiency improvements requires designing problem-specific algorithms known as dynamic or incremental algorithms, which are often significantly more complicated than conventional algorithms to design, analyze, implement, and use. A long-standing open problem is to develop techniques that automatically transform conventional programs so that they correctly and efficiently respond to incremental changes.

In this paper, we describe a significant step towards solving the problem of automatic incrementalization: a programming language and a compiler that can, given a few type annotations describing what can change over time, compile a conventional program that assumes its data to be static (unchanging over time) to an incremental program. Based on recent advances in self-adjusting computation, including a theoretical proposal for translating purely functional programs to self-adjusting programs, we develop techniques for translating conventional Standard ML programs to self-adjusting programs. By extending the Standard ML language, we design a fully featured programming language with higher-order features, a module system, and a powerful type system, and implement a compiler for this language. The resulting programming language, LML, enables translating conventional programs decorated with simple type annotations into incremental programs that can respond to changes in their data correctly and efficiently.

We evaluate the effectiveness of our approach by considering a range of benchmarks involving lists, vectors, and matrices, as well as a ray tracer. For these benchmarks, our compiler incrementalizes existing code with only trivial amounts of annotation. The resulting programs are often asymptotically more efficient, leading to orders of magnitude speedups in practice.},
	Acmid = {2254100},
	Address = {New York, NY, USA},
	Author = {Chen, Yan and Dunfield, Joshua and Acar, Umut A.},
	Booktitle = {Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation},
	Date-Added = {2013-04-18 16:33:55 +0000},
	Date-Modified = {2013-05-31 15:59:40 +0000},
	Doi = {10.1145/2254064.2254100},
	Isbn = {978-1-4503-1205-9},
	Keywords = {compiler optimization, incrementalization, performance, self-adjusting computation, type annotations; Incremental computation; adaptive computation},
	Location = {Beijing, China},
	Numpages = {12},
	Pages = {299--310},
	Publisher = {ACM},
	Series = {PLDI '12},
	Title = {Type-directed automatic incrementalization},
	Url = {http://doi.acm.org/10.1145/2254064.2254100},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2254064.2254100},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2254064.2254100}}

@inproceedings{Kennedy05gadtoo,
	Acmid = {1094814},
	Author = {Kennedy, Andrew and Russo, Claudio V.},
	Booktitle = oopsla,
	Date-Added = {2013-04-18 16:31:43 +0000},
	Date-Modified = {2013-04-18 16:32:21 +0000},
	Keywords = {constraints, generalized algebraic data types, generics},
	Location = {San Diego, CA, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1094811.1094814},
	Noisbn = {1-59593-031-0},
	Noseries = {OOPSLA '05},
	Nourl = {http://doi.acm.org/10.1145/1094811.1094814},
	Numpages = {20},
	Pages = {21--40},
	Publisher = {ACM},
	Title = {Generalized algebraic data types and object-oriented programming},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094811.1094814},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094811.1094814}}

@inproceedings{MacQueen88,
	Acmid = {62704},
	Address = {New York, NY, USA},
	Author = {MacQueen, David},
	Booktitle = {Proceedings of the 1988 ACM conference on LISP and functional programming},
	Date-Added = {2013-04-12 19:31:53 +0000},
	Date-Modified = {2013-04-12 19:32:38 +0000},
	Doi = {10.1145/62678.62704},
	Isbn = {0-89791-273-X},
	Location = {Snowbird, Utah, USA},
	Numpages = {12},
	Pages = {212--223},
	Publisher = {ACM},
	Series = {LFP '88},
	Title = {An implementation of standard ML modules},
	Url = {http://doi.acm.org/10.1145/62678.62704},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62704},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62704}}

@article{Huet97,
	Abstract = {Almost every programmer has faced the problem of representing a tree together with a subtree that is the focus of attention, where that focus may move left, right, up or down the tree. The Zipper is Huet's nifty name for a nifty data structure which fulfills this need. I wish I had known of it when I faced this task, because the solution I came up with was not quite so efficient or elegant as the Zipper.},
	Author = {G{\'e}rard Huet},
	Date-Added = {2013-04-12 13:39:01 +0000},
	Date-Modified = {2013-04-12 16:46:22 +0000},
	Issn = {1469-7653},
	Journal = JFP,
	Month = {8},
	Number = {05},
	Numpages = {6},
	Pages = {549--554},
	Title = {The Zipper},
	Url = {http://journals.cambridge.org/article_S0956796897002864},
	Volume = {7},
	Year = {1997},
	Bdsk-Url-1 = {http://journals.cambridge.org/article_S0956796897002864},
	Bdsk-Url-2 = {http://dx.doi.org/null}}

@inproceedings{Nakamura01,
	Acmid = {504294},
	Address = {New York, NY, USA},
	Author = {Nakamura, Hiroaki},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2013-03-18 16:15:50 +0000},
	Date-Modified = {2013-05-13 09:14:42 +0000},
	Doi = {10.1145/504282.504294},
	Isbn = {1-58113-335-9},
	Keywords = {Incremental computation},
	Location = {Tampa Bay, FL, USA},
	Numpages = {10},
	Pages = {156--165},
	Publisher = {ACM},
	Series = {OOPSLA '01},
	Title = {Incremental computation of complex object queries},
	Url = {http://doi.acm.org/10.1145/504282.504294},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/504282.504294},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/504282.504294}}

@article{Acar06,
	Abstract = {We present techniques for incremental computing by introducing adaptive functional programming. As an adaptive program executes, the underlying system represents the data and control dependences in the execution in the form of a dynamic dependence graph. When the input to the program changes, a change propagation algorithm updates the output and the dynamic dependence graph by propagating changes through the graph and re-executing code where necessary. Adaptive programs adapt their output to any change in the input, small or large.We show that adaptivity techniques are practical by giving an efficient implementation as a small ML library. The library consists of three operations for making a program adaptive, plus two operations for making changes to the input and adapting the output to these changes. We give a general bound on the time it takes to adapt the output, and based on this, show that an adaptive Quicksort adapts its output in logarithmic time when its input is extended by one key.To show the safety and correctness of the mechanism we give a formal definition of AFL, a call-by-value functional language extended with adaptivity primitives. The modal type system of AFL enforces correct usage of the adaptivity mechanism, which can only be checked at run time in the ML library. Based on the AFL dynamic semantics, we formalize thechange-propagation algorithm and prove its correctness.},
	Acmid = {1186634},
	Address = acmaddr,
	Author = {Acar, Umut A. and Blelloch, Guy E. and Harper, Robert},
	Date-Added = {2013-02-15 14:04:59 +0000},
	Date-Modified = {2013-05-31 15:57:21 +0000},
	Issue_Date = {November 2006},
	Journal = toplas,
	Keywords = {Incremental computation, adaptive computation, dynamic algorithms; self-adjusting computation},
	Month = nov,
	Nodoi = {10.1145/1186632.1186634},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/1186632.1186634},
	Number = {6},
	Numpages = {45},
	Pages = {990--1034},
	Publisher = {ACM},
	Title = {Adaptive functional programming},
	Volume = {28},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1186632.1186634},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1186632.1186634}}

@inproceedings{Acar02,
	Abstract = {An adaptive computation maintains the relationship between its input and output as the input changes. Although various techniques for adaptive computing have been proposed, they remain limited in their scope of applicability. We propose a general mechanism for adaptive computing that enables one to make any purely-functional program adaptive.We show that the mechanism is practical by giving an efficient implementation as a small ML library. The library consists of three operations for making a program adaptive, plus two operations for making changes to the input and adapting the output to these changes. We give a general bound on the time it takes to adapt the output, and based on this, show that an adaptive Quicksort adapts its output in logarithmic time when its input is extended by one key.To show the safety and correctness of the mechanism we give a formal definition of AFL, a call-by-value functional language extended with adaptivity primitives. The modal type system of AFL enforces correct usage of the adaptivity mechanism, which can only be checked at run time in the ML library. Based on the AFL dynamic semantics, we formalize the change-propagation algorithm and prove its correctness.},
	Acmid = {503296},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Harper, Robert},
	Booktitle = popl,
	Date-Added = {2013-02-15 14:02:01 +0000},
	Date-Modified = {2013-05-31 15:56:55 +0000},
	Keywords = {adaptive computation; Incremental computation; self-adjusting computation},
	Location = {Portland, Oregon},
	Noaddress = {New York, NY, USA},
	Nobooktitle = {Proceedings of the 29th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Nodoi = {10.1145/503272.503296},
	Noisbn = {1-58113-450-9},
	Noseries = {POPL '02},
	Nourl = {http://doi.acm.org/10.1145/503272.503296},
	Numpages = {13},
	Pages = {247--259},
	Publisher = {ACM},
	Title = {Adaptive functional programming},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/503272.503296},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/503272.503296}}

@inproceedings{Wang11IUE,
	Acmid = {2034825},
	Address = {New York, NY, USA},
	Author = {Wang, Meng and Gibbons, Jeremy and Wu, Nicolas},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-28 16:09:26 +0000},
	Date-Modified = {2013-05-13 09:13:17 +0000},
	Doi = {10.1145/2034773.2034825},
	Isbn = {978-1-4503-0865-6},
	Keywords = {bidirectional programming, functional programming, program transformation, view-update problem; Incremental computation},
	Location = {Tokyo, Japan},
	Numpages = {12},
	Pages = {392--403},
	Publisher = {ACM},
	Series = {ICFP '11},
	Title = {Incremental updates for efficient bidirectional transformations},
	Url = {http://doi.acm.org/10.1145/2034773.2034825},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034825},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034825}}

@inproceedings{Perera05,
	Acmid = {1094871},
	Address = {New York, NY, USA},
	Author = {Perera, Roly and Foster, Jeff and Koch, Gy{\"o}rgy},
	Booktitle = {Companion to the 20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2013-01-28 16:08:30 +0000},
	Date-Modified = {2013-05-31 15:50:37 +0000},
	Doi = {10.1145/1094855.1094871},
	Isbn = {1-59593-193-7},
	Keywords = {adaptive functions, delta-driven execution, incremental computation, lazy memoization, relational programming},
	Location = {San Diego, CA, USA},
	Numpages = {9},
	Pages = {63--71},
	Publisher = {ACM},
	Series = {OOPSLA '05},
	Title = {A delta-driven execution model for semantic computing},
	Url = {http://doi.acm.org/10.1145/1094855.1094871},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094855.1094871},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094855.1094871}}

@inproceedings{Mainland08FSF,
	Acmid = {1411251},
	Address = {New York, NY, USA},
	Author = {Mainland, Geoffrey and Morrisett, Greg and Welsh, Matt},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-28 16:04:55 +0000},
	Date-Modified = {2013-01-28 16:05:22 +0000},
	Doi = {10.1145/1411204.1411251},
	Isbn = {978-1-59593-919-7},
	Keywords = {meta programming},
	Location = {Victoria, BC, Canada},
	Numpages = {12},
	Pages = {335--346},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Flask: staged functional programming for sensor networks},
	Url = {http://doi.acm.org/10.1145/1411204.1411251},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411251},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411251}}

@inproceedings{Amin12,
	Abstract = {We propose a new type-theoretic foundation of Scala and
                 languages like it: the Dependent Object Types (DOT)
                 calculus. DOT models Scala's path-dependent types,
                 abstract type members and its mixture of nominal and
                 structural typing through the use of refinement types. The
                 core formalism makes no attempt to model inheritance and
                 mixin composition. DOT normalizes Scala's type system by
                 unifying the constructs for type members and by providing
                 classical intersection and union types which simplify
                 greatest lower bound and least upper bound computations.
                 In this paper, we present the DOT calculus, both formally
                 and informally. We also discuss our work-in-progress to
                 prove typesafety of the calculus.},
	Affiliation = {EPFL},
	Author = {Amin, Nada and Moors, Adriaan and Odersky, Martin},
	Booktitle = {19{t}h {I}nternational {W}orkshop on {F}oundations of {O}bject-{O}riented {L}anguages},
	Date-Added = {2013-01-23 18:13:15 +0000},
	Date-Modified = {2013-01-23 18:13:17 +0000},
	Details = {http://infoscience.epfl.ch/record/183030},
	Documenturl = {http://infoscience.epfl.ch/record/183030/files/fool.pdf},
	Keywords = {calculus; objects; dependent types},
	Location = {Tucson, Arizona, USA},
	Oai-Id = {oai:infoscience.epfl.ch:183030},
	Oai-Set = {conf},
	Review = {REVIEWED},
	Status = {PUBLISHED},
	Submitter = {164625},
	Title = {Dependent {O}bject {T}ypes},
	Unit = {LAMP},
	Url = {https://github.com/namin/dot},
	Year = 2012,
	Bdsk-Url-1 = {https://github.com/namin/dot}}

@inproceedings{Demetrescu11,
	Acmid = {2048100},
	Author = {Demetrescu, Camil and Finocchi, Irene and Ribichini, Andrea},
	Booktitle = oopsla,
	Date-Added = {2013-01-23 17:48:24 +0000},
	Date-Modified = {2013-01-23 17:48:24 +0000},
	Keywords = {constraint solving, data structure repair, dataflow programming, imperative programming, incremental computation, observer design pattern, reactive programming},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/2048066.2048100},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048100},
	Numpages = {20},
	Pages = {407--426},
	Publisher = acm,
	Title = {Reactive imperative programming with dataflow constraints},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048100}}

@inproceedings{Rompf13,
	Acmid = {2429128},
	Author = {Rompf, Tiark and Sujeeth, Arvind K. and Amin, Nada and Brown, Kevin J. and Jovanovic, Vojin and Lee, HyoukJoong and Jonnalagedda, Manohar and Olukotun, Kunle and Odersky, Martin},
	Booktitle = popl,
	Date-Added = {2013-01-23 16:49:06 +0000},
	Date-Modified = {2013-01-23 17:49:05 +0000},
	Keywords = {code generation, data structures, extensible compilers, staging},
	Location = {Rome, Italy},
	Noaddress = newyork,
	Nodoi = {10.1145/2429069.2429128},
	Noisbn = {978-1-4503-1832-7},
	Noseries = {POPL '13},
	Nourl = {http://doi.acm.org/10.1145/2429069.2429128},
	Numpages = {14},
	Pages = {497--510},
	Publisher = {ACM},
	Title = {Optimizing data structures in high-level programs: new directions for extensible compilers based on staging},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2429069.2429128},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2429069.2429128}}

@incollection{Iu06Queryll,
	Affiliation = {School of Computer and Communication Sciences, EPFL, Lausanne, Switzerland},
	Author = {Iu, Ming-Yee and Zwaenepoel, Willy},
	Booktitle = {Middleware 2006},
	Date-Added = {2013-01-17 15:24:23 +0000},
	Date-Modified = {2013-01-17 15:24:35 +0000},
	Editor = {van Steen, Maarten and Henning, Michi},
	Isbn = {978-3-540-49023-4},
	Keyword = {Computer Science},
	Note = {10.1007/11925071_11},
	Pages = {201-218},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Queryll: Java Database Queries Through Bytecode Rewriting},
	Url = {http://dx.doi.org/10.1007/11925071_11},
	Volume = {4290},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11925071_11}}

@inproceedings{Chafi11,
	Acmid = {1941561},
	Address = {New York, NY, USA},
	Author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
	Booktitle = {Proceedings of the 16th ACM symposium on Principles and practice of parallel programming},
	Date-Added = {2013-01-16 15:08:52 +0000},
	Date-Modified = {2013-01-16 15:08:53 +0000},
	Doi = {10.1145/1941553.1941561},
	Isbn = {978-1-4503-0119-0},
	Keywords = {domain-specific languages, dynamic optimizations, parallel programming, runtimes},
	Location = {San Antonio, TX, USA},
	Numpages = {12},
	Pages = {35--46},
	Publisher = {ACM},
	Series = {PPoPP '11},
	Title = {A domain-specific approach to heterogeneous parallelism},
	Url = {http://doi.acm.org/10.1145/1941553.1941561},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1941553.1941561},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1941553.1941561}}

@article{gibbons2009essence,
	Author = {Gibbons, J. and Oliveira, B.C.S.},
	Date-Added = {2013-01-04 20:04:25 +0000},
	Date-Modified = {2013-01-04 20:04:25 +0000},
	Journal = {Journal of Functional Programming},
	Number = {3-4},
	Pages = {377--402},
	Publisher = {Cambridge Univ Press},
	Title = {The essence of the iterator pattern},
	Volume = {19},
	Year = {2009}}

@article{hinze2006finger,
	Author = {Hinze, R. and Paterson, R.},
	Date-Added = {2013-01-04 17:36:38 +0000},
	Date-Modified = {2013-01-04 17:36:38 +0000},
	Journal = {Journal of Functional Programming},
	Number = {2},
	Pages = {197--218},
	Publisher = {Cambridge Univ Press},
	Title = {Finger trees: a simple general-purpose data structure},
	Volume = {16},
	Year = {2006}}

@inproceedings{Baars02TDT,
	Acmid = {581494},
	Address = {New York, NY, USA},
	Author = {Baars, Arthur I. and Swierstra, S. Doaitse},
	Booktitle = {Proceedings of the seventh ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-02 02:52:37 +0000},
	Date-Modified = {2013-01-02 02:52:52 +0000},
	Doi = {10.1145/581478.581494},
	Isbn = {1-58113-487-8},
	Keywords = {Haskell, Leibnitz' rule, coercions, dynamic typing, quantified types, static typing, type equality, typed interpreters},
	Location = {Pittsburgh, PA, USA},
	Numpages = {10},
	Pages = {157--166},
	Publisher = {ACM},
	Series = {ICFP '02},
	Title = {Typing dynamic typing},
	Url = {http://doi.acm.org/10.1145/581478.581494},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/581478.581494},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/581478.581494}}

@incollection{Coquand94,
	Affiliation = {Chalmers University of Technology and University of G{\"o}teborg Department of Computer Sciences S-412 96 G{\"o}teborg Sweden S-412 96 G{\"o}teborg Sweden},
	Author = {Coquand, Catarina},
	Booktitle = {Computer Science Logic},
	Date-Added = {2013-01-01 16:27:45 +0000},
	Date-Modified = {2013-01-01 16:27:46 +0000},
	Editor = {B{\"o}rger, Egon and Gurevich, Yuri and Meinke, Karl},
	Isbn = {978-3-540-58277-9},
	Keyword = {Computer Science},
	Note = {10.1007/BFb0049326},
	Pages = {91-105},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {From semantics to rules: A machine assisted analysis},
	Url = {http://dx.doi.org/10.1007/BFb0049326},
	Volume = {832},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0049326}}

@article{Berger06,
	Abstract = {This paper describes formalizations of Tait's normalization proof for the simply typed Œª-calculus in the proof assistants Minlog, Coq and Isabelle/HOL. From the formal proofs programs are machine-extracted that implement variants of the well-known normalization-by-evaluation algorithm. The case study is used to test and compare the program extraction machineries of the three proof assistants in a non-trivial setting.},
	Affiliation = {University of Wales Swansea Department of Computer Science Singleton Park Swansea SA2 8PP UK Singleton Park Swansea SA2 8PP UK},
	Author = {Berger, Ulrich and Berghofer, Stefan and Letouzey, Pierre and Schwichtenberg, Helmut},
	Date-Added = {2013-01-01 16:20:55 +0000},
	Date-Modified = {2013-01-01 16:20:55 +0000},
	Issn = {0039-3215},
	Issue = {1},
	Journal = {Studia Logica},
	Keyword = {Humanities, Social Sciences and Law},
	Note = {10.1007/s11225-006-6604-5},
	Pages = {25-49},
	Publisher = {Springer Netherlands},
	Title = {Program Extraction from Normalization Proofs},
	Url = {http://dx.doi.org/10.1007/s11225-006-6604-5},
	Volume = {82},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s11225-006-6604-5}}

@incollection{Berger93,
	Affiliation = {Mathematisches Institut der Ludwig-Maximilians-Universit{\"a}t M{\"u}nchen Theresienstra{\ss}e 39 8000 M{\"u}nchen 2 Germany Theresienstra{\ss}e 39 8000 M{\"u}nchen 2 Germany},
	Author = {Berger, Ulrich},
	Booktitle = {Typed Lambda Calculi and Applications},
	Date-Added = {2013-01-01 16:18:31 +0000},
	Date-Modified = {2013-01-01 16:18:32 +0000},
	Editor = {Bezem, Marc and Groote, Jan},
	Isbn = {978-3-540-56517-8},
	Keyword = {Computer Science},
	Note = {10.1007/BFb0037100},
	Pages = {91-106},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Program extraction from normalization proofs},
	Url = {http://dx.doi.org/10.1007/BFb0037100},
	Volume = {664},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0037100}}

@article{Elgueta99,
	Abstract = {Given a structure for a first-order language L, two objects of its domain can be indiscernible relative to the properties expressible in L, without using the equality symbol, and without actually being the same. It is this relation that interests us in this paper. It is called Leibniz equality. In the paper we study systematically the problem of its definibility mainly for classes of structures that are the models of some equality-free universal Horn class in an infinitary language L Œ∫Œ∫ , where Œ∫ is an infinite regular cardinal.},
	Affiliation = {Universitat Polit{\`e}cnica de Catalunya Department of Applied Mathematics II Spain Spain},
	Author = {Elgueta, R. and Jansana, R.},
	Date-Added = {2013-01-01 16:16:47 +0000},
	Date-Modified = {2013-01-01 16:16:49 +0000},
	Issn = {0039-3215},
	Issue = {2},
	Journal = {Studia Logica},
	Keyword = {Humanities, Social Sciences and Law},
	Note = {10.1023/A:1005214714620},
	Pages = {223-243},
	Publisher = {Springer Netherlands},
	Title = {Definability of Leibniz Equality},
	Url = {http://dx.doi.org/10.1023/A:1005214714620},
	Volume = {63},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1005214714620}}

@inproceedings{Atkey09,
	Acmid = {1596644},
	Address = {New York, NY, USA},
	Author = {Atkey, Robert and Lindley, Sam and Yallop, Jeremy},
	Booktitle = {Proceedings of the 2nd ACM SIGPLAN symposium on Haskell},
	Date-Added = {2012-12-31 04:06:15 +0000},
	Date-Modified = {2012-12-31 04:06:16 +0000},
	Doi = {10.1145/1596638.1596644},
	Isbn = {978-1-60558-508-6},
	Keywords = {domain-specific languages, higher-order abstract syntax, type classes, unembedding},
	Location = {Edinburgh, Scotland},
	Numpages = {12},
	Pages = {37--48},
	Publisher = {ACM},
	Series = {Haskell '09},
	Title = {Unembedding domain-specific languages},
	Url = {http://doi.acm.org/10.1145/1596638.1596644},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596638.1596644},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596638.1596644}}

@inproceedings{Chlipala08,
	Acmid = {1411226},
	Address = {New York, NY, USA},
	Author = {Chlipala, Adam},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-12-31 04:05:51 +0000},
	Date-Modified = {2012-12-31 04:05:53 +0000},
	Doi = {10.1145/1411204.1411226},
	Isbn = {978-1-59593-919-7},
	Keywords = {compiler verification, dependent types, interactive proof assistants, type-theoretic semantics},
	Location = {Victoria, BC, Canada},
	Numpages = {14},
	Pages = {143--156},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Parametric higher-order abstract syntax for mechanized semantics},
	Url = {http://doi.acm.org/10.1145/1411204.1411226},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411226},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411226}}

@inproceedings{odersky-zenger:fool05,
	Author = {Martin Odersky and Matthias Zenger},
	Booktitle = {FOOL},
	Date-Added = {2012-12-12 13:27:50 +0000},
	Date-Modified = {2012-12-12 23:10:06 +0000},
	Nomonth = jan,
	Nonote = {\url{http://homepages.inf.ed.ac.uk/wadler/fool}},
	Nourl = {http://lampwww.epfl.ch/~odersky/papers/ExpressionProblem.html},
	Read = {1},
	Title = {Independently Extensible Solutions to the Expression Problem},
	Year = 2005,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QiC4uLy4uLy4uL0Ryb3Bib3gvUGFwZXJzL1Byb2dyYW1taW5nIExhbmd1YWdlcy9TY2FsYS9JbmRlcGVuZGVudGx5IEV4dGVuc2libGUgU29sdXRpb25zIHRvIHRoZSBFeHByZXNzaW9uIFByb2JsZW0gLSBleHByZXNzaW9uUHJvYmxlbS5wZGbSFwsYGVdOUy5kYXRhTxECtgAAAAACtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpe500grAAAAFi24H0luZGVwZW5kZW50bHkgRXh0ZW5zIzE2MkRDNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWLcTM7kSdAAAAAAAAAAAAAwAFAAAJIAAAAAAAAAAAAAAAAAAAAAVTY2FsYQAAEAAIAADOl6vDAAAAEQAIAADM7jaNAAAAAQAYABYtuAAWJ4gAFiZ7ABYh+wANl58AAmSOAAIAbk1hY2ludG9zaCBIRDpVc2VyczoAcGdpYXJydXNzbzoARHJvcGJveDoAUGFwZXJzOgBQcm9ncmFtbWluZyBMYW5ndWFnZXM6AFNjYWxhOgBJbmRlcGVuZGVudGx5IEV4dGVucyMxNjJEQzQucGRmAA4AqgBUAEkAbgBkAGUAcABlAG4AZABlAG4AdABsAHkAIABFAHgAdABlAG4AcwBpAGIAbABlACAAUwBvAGwAdQB0AGkAbwBuAHMAIAB0AG8AIAB0AGgAZQAgAEUAeABwAHIAZQBzAHMAaQBvAG4AIABQAHIAbwBiAGwAZQBtACAALQAgAGUAeABwAHIAZQBzAHMAaQBvAG4AUAByAG8AYgBsAGUAbQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAkFVzZXJzL3BnaWFycnVzc28vRHJvcGJveC9QYXBlcnMvUHJvZ3JhbW1pbmcgTGFuZ3VhZ2VzL1NjYWxhL0luZGVwZW5kZW50bHkgRXh0ZW5zaWJsZSBTb2x1dGlvbnMgdG8gdGhlIEV4cHJlc3Npb24gUHJvYmxlbSAtIGV4cHJlc3Npb25Qcm9ibGVtLnBkZgATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOARkBHgEmA+AD4gPnA/ID+wQJBA0EFAQdBCIELwQyBEQERwRMAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABE4=}}

@inproceedings{Lindley12EmbeddingF,
	Acmid = {2364402},
	Address = {New York, NY, USA},
	Author = {Lindley, Sam},
	Booktitle = {Proceedings of the 8th ACM SIGPLAN workshop on Generic programming},
	Date-Added = {2012-12-10 19:31:29 +0000},
	Date-Modified = {2012-12-10 19:31:38 +0000},
	Doi = {10.1145/2364394.2364402},
	Isbn = {978-1-4503-1576-0},
	Keywords = {domain specific languages, haskell, higher-order abstract syntax, ocaml, polymorphism},
	Location = {Copenhagen, Denmark},
	Numpages = {12},
	Pages = {45--56},
	Publisher = {ACM},
	Series = {WGP '12},
	Title = {Embedding F},
	Url = {http://doi.acm.org/10.1145/2364394.2364402},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2364394.2364402},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2364394.2364402}}

@incollection{Coquand85,
	Affiliation = {Domaine de Voluceau INRIA 78150 Rocquencourt France 78150 Rocquencourt France},
	Author = {Coquand, Thierry and Huet, G{\'e}rard},
	Booktitle = {EUROCAL '85},
	Date-Added = {2012-10-18 19:41:48 +0200},
	Date-Modified = {2012-10-18 19:41:50 +0200},
	Editor = {Buchberger, Bruno},
	Isbn = {978-3-540-15983-4},
	Keyword = {Computer Science},
	Note = {10.1007/3-540-15983-5_13},
	Pages = {151-184},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Constructions: A higher order proof system for mechanizing mathematics},
	Url = {http://dx.doi.org/10.1007/3-540-15983-5_13},
	Volume = {203},
	Year = {1985},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-15983-5_13}}

@inproceedings{Smaragdakis:1997:DTL,
	Acmid = {1267970},
	Author = {Smaragdakis, Yannis and Batory, Don},
	Booktitle = {Proceedings of the Conference on Domain-Specific Languages on Conference on Domain-Specific Languages (DSL), 1997},
	Date-Added = {2012-08-01 22:08:11 +0200},
	Date-Modified = {2013-05-13 09:15:09 +0000},
	Keywords = {data structures},
	Location = {Santa Barbara, California},
	Noaddress = {Berkeley, CA, USA},
	Numpages = {1},
	Pages = {20--20},
	Publisher = {USENIX Association},
	Series = {DSL'97},
	Title = {DiSTiL: a transformation library for data structures},
	Url = {http://dl.acm.org/citation.cfm?id=1267950.1267970},
	Year = {1997},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1267950.1267970}}

@inproceedings{Chambers10,
	Acmid = {1806638},
	Author = {Chambers, Craig and Raniwala, Ashish and Perry, Frances and Adams, Stephen and Henry, Robert R. and Bradshaw, Robert and Weizenbaum, Nathan},
	Booktitle = pldi,
	Date-Added = {2012-07-30 14:49:22 +0200},
	Date-Modified = {2012-08-07 16:44:46 +0200},
	Keywords = {data-parallel programming, java, mapreduce},
	Location = {Toronto, Ontario, Canada},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1806596.1806638},
	Noisbn = {978-1-4503-0019-3},
	Noseries = {PLDI '10},
	Nourl = {http://doi.acm.org/10.1145/1806596.1806638},
	Numpages = {13},
	Pages = {363--375},
	Publisher = acm,
	Title = {{FlumeJava}: easy, efficient data-parallel pipelines},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1806596.1806638},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1806596.1806638}}

@inproceedings{Yu08,
	Acmid = {1855742},
	Author = {Yu, Yuan and Isard, Michael and Fetterly, Dennis and Budiu, Mihai and Erlingsson, \'{U}lfar and Gunda, Pradeep Kumar and Currey, Jon},
	Booktitle = {Proc. Conf. Operating systems design and implementation},
	Date-Added = {2012-07-09 15:17:25 +0200},
	Date-Modified = {2012-07-09 15:21:47 +0200},
	Location = {San Diego, California},
	Noaddress = {Berkeley, CA, USA},
	Nourl = {http://dl.acm.org/citation.cfm?id=1855741.1855742},
	Numpages = {14},
	Pages = {1--14},
	Publisher = {USENIX Association},
	Series = {OSDI'08},
	Title = {{DryadLINQ}: a system for general-purpose distributed data-parallel computing using a high-level language},
	Year = {2008},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1855741.1855742}}

@inproceedings{AOP,
	Author = {Gregor Kiczales and John Lamping and Anurag Menhdhekar and Chris Maeda and Cristina Lopes and Jean-Marc Loingtier and John Irwin},
	Authorshort = {Gregor Kiczales and others},
	Booktitle = ECOOP,
	Date-Added = {2012-07-06 16:02:53 +0200},
	Date-Modified = {2012-07-09 15:20:52 +0200},
	Noaddress = SpringerAddr,
	Noeditor = {Mehmet Aksit and Satoshi Matsuoka},
	Noisbn = {3-540-63089-9},
	Nomonth = jul,
	Nopublisher = Springer,
	Noseries = LNCS,
	Novolume = {1241},
	Pages = {220--242},
	Title = {Aspect-Oriented Programming},
	Year = 1997}

@incollection{Sorensen94,
	Abstract = {We study four transformation methodologies which are automatic instances of Burstall and Darlington's fold/unfold framework: partial evaluation, deforestation, supercompilation , and generalized partial computation (GPC) . One can classify these and other fold/unfold based transformers by how much information they maintain during transformation.},
	Affiliation = {University of Copenhagen DIKU, Department of Computer Science Universitetsparken 1 DK-2100 Copenhagen {\O} Denmark Universitetsparken 1 DK-2100 Copenhagen {\O} Denmark},
	Author = {S{\o}rensen, Morten and Gl{\"u}ck, Robert and Jones, Neil},
	Booktitle = {Programming Languages and Systems --- ESOP '94},
	Date-Added = {2012-07-03 14:58:26 +0200},
	Date-Modified = {2014-02-08 19:57:31 +0000},
	Editor = {Sannella, Donald},
	Isbn = {978-3-540-57880-2},
	Keyword = {Computer Science},
	Keywords = {partial evaluation},
	Note = {10.1007/3-540-57880-3_32},
	Pages = {485-500},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Towards unifying partial evaluation, deforestation, supercompilation, and GPC},
	Url = {http://dx.doi.org/10.1007/3-540-57880-3_32},
	Volume = {788},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-57880-3_32}}

@inproceedings{danvy99type-directed,
	Author = {Danvy, Olivier},
	Booktitle = {Partial Evaluation - Practice and Theory, DIKU 1998 International Summer School},
	Date-Added = {2012-06-29 16:17:18 +0200},
	Date-Modified = {2012-06-29 16:17:18 +0200},
	Noaddress = London,
	Pages = {367--411},
	Publisher = Springer,
	Title = {Type-Directed Partial Evaluation},
	Url = {http://cs.au.dk/~danvy/tdpe-ln.pdf},
	Year = {1999},
	Bdsk-Url-1 = {http://cs.au.dk/~danvy/tdpe-ln.pdf}}

@inproceedings{Chapman10,
	Acmid = {1863547},
	Author = {Chapman, James and Dagand, Pierre-\'{E}variste and McBride, Conor and Morris, Peter},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-27 14:52:40 +0200},
	Date-Modified = {2013-05-13 09:15:20 +0000},
	Doi = {10.1145/1863543.1863547},
	Isbn = {978-1-60558-794-3},
	Keywords = {data structures, metaprogramming, monads, proof assistants, type systems},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Numpages = {12},
	Pages = {3--14},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {The gentle art of levitation},
	Url = {http://doi.acm.org/10.1145/1863543.1863547},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863547},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863547}}

@inproceedings{Blelloch:2010:FPA:1863543.1863579,
	Acmid = {1863579},
	Author = {Blelloch, Guy E.},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-27 14:23:38 +0200},
	Date-Modified = {2012-06-27 14:23:38 +0200},
	Doi = {10.1145/1863543.1863579},
	Isbn = {978-1-60558-794-3},
	Keywords = {functional programming, parallel algorithms},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Numpages = {1},
	Pages = {247--247},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {Functional parallel algorithms},
	Url = {http://doi.acm.org/10.1145/1863543.1863579},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863579},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863579}}

@inproceedings{Blelloch96a,
	Acmid = {232650},
	Author = {Blelloch, Guy E. and Greiner, John},
	Booktitle = {Proceedings of the first ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-23 14:32:17 +0200},
	Date-Modified = {2012-06-23 14:32:20 +0200},
	Doi = {10.1145/232627.232650},
	Isbn = {0-89791-770-7},
	Location = {Philadelphia, Pennsylvania, United States},
	Noaddress = {New York, NY, USA},
	Numpages = {13},
	Pages = {213--225},
	Publisher = acm,
	Series = {ICFP '96},
	Title = {A provable time and space efficient implementation of NESL},
	Url = {http://doi.acm.org/10.1145/232627.232650},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/232627.232650},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/232627.232650}}

@incollection{Chakravarty01Nepal,
	Abstract = {This paper discusses an extension of Haskell by support for nested data-parallel programming in the style of the special-purpose language Nesl . The extension consists of a parallel array type, array comprehensions, and primitive parallel array operations. This extension brings a hitherto unsupported style of parallel programming to Haskell. Moreover, nested data parallelism should receive wider attention when available in a standardised language like Haskell.},
	Affiliation = {University of New South Wales Australia},
	Author = {Chakravarty, Manuel and Keller, Gabriele and Lechtchinsky, Roman and Pfannenstiel, Wolf},
	Booktitle = {Euro-Par 2001 Parallel Processing},
	Date-Added = {2012-06-23 14:19:28 +0200},
	Date-Modified = {2012-06-23 14:20:04 +0200},
	Editor = {Sakellariou, Rizos and Gurd, John and Freeman, Len and Keane, John},
	Isbn = {978-3-540-42495-6},
	Keyword = {Computer Science},
	Keywords = {nested data parallelism, Haskell},
	Note = {10.1007/3-540-44681-8_76},
	Pages = {524-534},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Nepal --- Nested Data Parallelism in Haskell},
	Url = {http://dx.doi.org/10.1007/3-540-44681-8_76},
	Volume = {2150},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-44681-8_76}}

@article{Blelloch90,
	Abstract = {This paper introduces techniques for compiling the nested parallelism of collection-oriented languages onto existing parallel hardware. Programmers of parallel machines encounter nested parallelism whenever they write a routine that performs parallel operations, and then want to call that routine itself in parallel. This occurs naturally in many applications. Most parallel systems, however, do not permit the expression of nested parallelism. This forces the programmer to exploit only one level of parallelism or to implement nested parallelism themselves. Both of these alternatives tend to produce code that is harder to maintain and less modular than code described at a higher level with nested parallel constructs. Not permitting the expression of nested parallelism is analogous to not permitting nested loops in serial languages. This paper describes issues and techniques for taking high-level descriptions of parallelism in the form of operations on nested collections and automatically translating them into flat, single-level parallelism. A compiler that translates a subset of a collection-oriented language,Paralation Lisp, into the instruction set of a flat virtual machine is presented. The instructions of the virtual machine are simple instructions on vectors of atomic values, and can be implemented on a broad class of target architectures, including vector machines, single-instruction parallel machines, and multiple-instruction parallel machines. We have implemented the instructions on the Connection Machine computer (CM-2), a massively parallel, single-instruction computer. As an illustration of the compiler techniques, the paper presents a quicksort example. The example has been tested on the CM-2. The speed of the compiled sort is only a factor of 3 slower than that of the fastest CM-2 sort.},
	Author = {Guy E. Blelloch and Gary W. Sabot},
	Date-Added = {2012-06-23 14:14:27 +0200},
	Date-Modified = {2012-06-23 14:21:33 +0200},
	Doi = {10.1016/0743-7315(90)90087-6},
	Issn = {0743-7315},
	Journal = {Journal of Parallel and Distributed Computing},
	Keywords = {nested data parallelism; parallel programming},
	Number = {2},
	Pages = {119 - 134},
	Title = {Compiling collection-oriented languages onto massively parallel computers},
	Url = {http://www.sciencedirect.com/science/article/pii/0743731590900876},
	Volume = {8},
	Year = {1990},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0743731590900876},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0743-7315(90)90087-6}}

@inproceedings{Kienzle06AopMakesSense,
	Author = {Kienzle, J{\"o}rg and Guerraoui, Rachid},
	Booktitle = ecoop,
	Date-Added = {2012-06-23 14:13:25 +0200},
	Date-Modified = {2012-06-23 14:13:25 +0200},
	Editor = {Magnusson, Boris},
	Pages = {113-121},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {AOP: Does It Make Sense? The Case of Concurrency and Failures},
	Url = {http://dx.doi.org/10.1007/3-540-47993-7_2},
	Volume = {2374},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-47993-7_2}}

@article{Blelloch96,
	Acmid = {227246},
	Author = {Blelloch, Guy E.},
	Date-Added = {2012-06-22 07:08:26 +0200},
	Date-Modified = {2012-06-23 14:21:33 +0200},
	Doi = {10.1145/227234.227246},
	Issn = {0001-0782},
	Issue_Date = {March 1996},
	Journal = {Commun. ACM},
	Keywords = {nested data parallelism; parallel programming},
	Noaddress = {New York, NY, USA},
	Nomonth = mar,
	Number = {3},
	Numpages = {13},
	Pages = {85--97},
	Publisher = acm,
	Title = {Programming parallel algorithms},
	Url = {http://doi.acm.org/10.1145/227234.227246},
	Volume = {39},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/227234.227246},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/227234.227246}}

@incollection{Keller96FlatteningNesl,
	Affiliation = {Technische Universit{\"a}t Berlin Forschungsgruppe Softwaretechnik (FR5-6) Franklinstr. 28/29 D-10587 Berlin Franklinstr. 28/29 D-10587 Berlin},
	Author = {Keller, Gabriele and Simons, Martin},
	Booktitle = {Concurrency and Parallelism, Programming, Networking, and Security},
	Date-Added = {2012-06-22 06:56:59 +0200},
	Date-Modified = {2012-06-23 14:24:26 +0200},
	Editor = {Jaffar, Joxan and Yap, Roland},
	Isbn = {978-3-540-62031-0},
	Keyword = {Computer Science},
	Keywords = {nested data parallelism},
	Note = {10.1007/BFb0027796},
	Pages = {234-243},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A calculational approach to flattening nested data parallelism in functional languages},
	Url = {http://dx.doi.org/10.1007/BFb0027796},
	Volume = {1179},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0027796}}

@inproceedings{Odersky01coloredLocal,
	Author = {Martin Odersky and Matthias Zenger and Christoph Zenger},
	Booktitle = {Proc. ACM Symposium on Principles of Programming Languages},
	Date-Added = {2012-04-20 17:27:39 +0200},
	Date-Modified = {2012-04-20 17:28:07 +0200},
	Pages = {41-53},
	Title = {Colored Local Type Inference},
	Year = 2001}

@inproceedings{hofer08polymorphic,
	Author = {Christian Hofer and Klaus Ostermann and Tillmann Rendel and Adriaan Moors},
	Booktitle = gpce,
	Date-Added = {2012-04-14 09:25:19 +0200},
	Date-Modified = {2012-06-23 14:26:16 +0200},
	Keywords = {DSEL},
	Noseries = {GPCE'08},
	Nourl = {http://www.daimi.au.dk/~ko/papers/gpce50_hofer.pdf},
	Pages = {137--148},
	Publisher = acm,
	Title = {Polymorphic Embedding of {DSLs}},
	Year = {2008},
	Bdsk-Url-1 = {http://www.daimi.au.dk/~ko/papers/gpce50_hofer.pdf}}

@book{Pierce02TAPL,
	Abstract = {{A type system is a syntactic method for automatically checking the absence of certain erroneous behaviors by classifying program phrases according to the kinds of values they compute. The study of type systems--and of programming languages from a type-theoretic perspective-has important applications in software engineering, language design, high-performance compilers, and security.<br /> <br /> This text provides a comprehensive introduction both to type systems in computer science and to the basic theory of programming languages. The approach is pragmatic and operational; each new concept is motivated by programming examples and the more theoretical sections are driven by the needs of implementations. Each chapter is accompanied by numerous exercises and solutions, as well as a running implementation, available via the Web. Dependencies between chapters are explicitly identified, allowing readers to choose a variety of paths through the material.<br /> <br /> The core topics include the untyped lambda-calculus, simple type systems, type reconstruction, universal and existential polymorphism, subtyping, bounded quantification, recursive types, kinds, and type operators. Extended case studies develop a variety of approaches to modeling the features of object-oriented languages.}},
	Author = {Pierce, Benjamin C.},
	Citeulike-Article-Id = {105547},
	Citeulike-Linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0262162091},
	Citeulike-Linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0262162091},
	Citeulike-Linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0262162091},
	Citeulike-Linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262162091},
	Citeulike-Linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262162091/citeulike00-21},
	Citeulike-Linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262162091},
	Citeulike-Linkout-6 = {http://www.worldcat.org/isbn/0262162091},
	Citeulike-Linkout-7 = {http://books.google.com/books?vid=ISBN0262162091},
	Citeulike-Linkout-8 = {http://www.amazon.com/gp/search?keywords=0262162091&index=books&linkCode=qs},
	Citeulike-Linkout-9 = {http://www.librarything.com/isbn/0262162091},
	Date-Added = {2012-04-14 05:21:23 +0200},
	Date-Modified = {2012-04-14 05:24:09 +0200},
	Day = {01},
	Edition = {1st},
	Howpublished = {Hardcover},
	Keywords = {getting-started, type-theory},
	Noisbn = {0262162091},
	Nomonth = feb,
	Posted-At = {2008-02-26 22:26:29},
	Priority = {0},
	Publisher = {MIT Press},
	Title = {{Types and Programming Languages}},
	Year = {2002},
	Bdsk-Url-1 = {http://www.worldcat.org/isbn/0262162091}}

@article{carette09finally,
	Author = {Carette, Jacques and Kiselyov, Oleg and Shan, Chung-chieh},
	Date-Added = {2012-04-14 00:18:13 +0200},
	Date-Modified = {2012-06-23 14:23:18 +0200},
	Issue = {5},
	Journal = JFP,
	Keywords = {DSEL},
	Noaddress = NewYork,
	Nomonth = {September},
	Nopublisher = Cambridge,
	Pages = {509--543},
	Title = {Finally Tagless, Partially Evaluated: Tagless Staged Interpreters for Simpler Typed Languages},
	Volume = {19},
	Year = {2009},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?id=1630623.1630626}}

@inproceedings{Peyton-Jones01playingby,
	Author = {Peyton Jones, Simon L. and Andrew Tolmach and Tony Hoare},
	Booktitle = {Proc. Haskell Workshop},
	Date-Added = {2012-04-13 12:22:53 +0200},
	Date-Modified = {2014-02-09 22:53:59 +0000},
	Editor = {Ralf Hinze},
	Keywords = {optimization},
	Pages = {203-233},
	Title = {Playing by the rules: rewriting as a practical optimisation technique in {GHC}},
	Year = {2001}}

@inproceedings{Gill93shortcut,
	Acmid = {165214},
	Author = {Gill, Andrew and Launchbury, John and Peyton Jones, Simon L.},
	Booktitle = fpca,
	Date-Added = {2012-04-11 23:10:44 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {optimization},
	Location = {Copenhagen, Denmark},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/165180.165214},
	Noisbn = {0-89791-595-X},
	Noseries = {FPCA '93},
	Nourl = {http://doi.acm.org/10.1145/165180.165214},
	Numpages = {10},
	Pages = {223--232},
	Publisher = acm,
	Title = {A short cut to deforestation},
	Year = {1993},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/165180.165214},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/165180.165214}}

@article{Wadler90deforest,
	Author = {Wadler, Philip},
	Date-Added = {2012-04-11 23:06:54 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Issue_Date = {June 22, 1990},
	Journal = tcs,
	Keywords = {optimization},
	Noaddress = elsevieraddr,
	Nodoi = {10.1016/0304-3975(90)90147-A},
	Noissn = {0304-3975},
	Nomonth = jun,
	Nourl = {http://dx.doi.org/10.1016/0304-3975(90)90147-A},
	Number = {2},
	Numpages = {18},
	Pages = {231--248},
	Publisher = elsevier,
	Title = {Deforestation: transforming programs to eliminate trees},
	Volume = {73},
	Year = {1990},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/0304-3975(90)90147-A}}

@inproceedings{Coutts07stream,
	Acmid = {1291199},
	Author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
	Booktitle = icfp,
	Date-Added = {2012-04-11 23:01:07 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {deforestation, functional programming, program fusion, program transformation; optimization},
	Location = {Freiburg, Germany},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1291151.1291199},
	Noisbn = {978-1-59593-815-2},
	Nourl = {http://doi.acm.org/10.1145/1291151.1291199},
	Numpages = {12},
	Pages = {315--326},
	Publisher = acm,
	Series = {ICFP '07},
	Title = {Stream fusion: from lists to streams to nothing at all},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1291151.1291199},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1291151.1291199}}

@inproceedings{mitchell10rethinking,
	Acmid = {1863588},
	Author = {Mitchell, Neil},
	Booktitle = icfp,
	Date-Added = {2012-04-11 14:40:35 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {haskell, optimization, supercompilation},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/1863543.1863588},
	Noisbn = {978-1-60558-794-3},
	Nourl = {http://doi.acm.org/10.1145/1863543.1863588},
	Numpages = {12},
	Pages = {309--320},
	Prg = {2011-02-09, Paolo},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {Rethinking Supercompilation},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863588}}

@misc{OderskyPimpLib,
	Author = {Martin Odersky},
	Date-Added = {2012-04-10 19:04:50 +0200},
	Date-Modified = {2012-04-10 19:14:33 +0200},
	Note = {Last accessed on 10 April 2012},
	Title = {Pimp my Library},
	Url = {http://www.artima.com/weblogs/viewpost.jsp?thread=179766},
	Urldate = {9 October, 2006},
	Year = {2006},
	Bdsk-Url-1 = {http://www.artima.com/weblogs/viewpost.jsp?thread=179766}}

@article{Steele99Growing,
	Author = {Steele, Guy L.},
	Date-Added = {2012-04-03 07:32:20 +0200},
	Date-Modified = {2012-06-23 14:23:39 +0200},
	Issue = {3},
	Journal = hosc,
	Keyword = {Computer Science},
	Keywords = {DSEL},
	Noissn = {1388-3690},
	Nonote = {10.1023/A:1010085415024},
	Nourl = {http://dx.doi.org/10.1023/A:1010085415024},
	Pages = {221-236},
	Publisher = {Springer Netherlands},
	Title = {Growing a Language},
	Volume = {12},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1010085415024}}

@inproceedings{Pfenning88,
	Acmid = {62697},
	Author = {Pfenning, Frank},
	Booktitle = lfp,
	Date-Added = {2012-04-03 07:23:20 +0200},
	Date-Modified = {2012-04-03 07:23:23 +0200},
	Location = {Snowbird, Utah, United States},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/62678.62697},
	Noisbn = {0-89791-273-X},
	Nourl = {http://doi.acm.org/10.1145/62678.62697},
	Numpages = {11},
	Pages = {153--163},
	Publisher = acm,
	Series = {LFP '88},
	Title = {Partial polymorphic type inference and higher-order unification},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62697},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62697}}

@incollection{Filinski01NormByEval,
	Abstract = {We show how a simple semantic characterization of normalization by evaluation for the Œª Œ≤Œ∑ -calculus can be extended to a similar construction for normalization of terms in the computational Œª-calculus. Specifically, we show that a suitable residualizing interpretation of base types, constants, and computational effects allows us to extract a syntactic normal form from a term's denotation. The required interpretation can itself be constructed as the meaning of a suitable functional program in an ML-like language, leading directly to a practical normalization algorithm. The results extend easily to product and sum types, and can be seen as a formal basis for call-by-value type-directed partial evaluation.},
	Affiliation = {University of Aarhus BRICS, Department of Computer Science Aarhus},
	Author = {Filinski, Andrzej},
	Booktitle = {Typed Lambda Calculi and Applications},
	Date-Added = {2012-04-01 23:07:33 +0200},
	Date-Modified = {2012-04-01 23:08:32 +0200},
	Editor = {Abramsky, Samson},
	Keyword = {Computer Science},
	Noisbn = {978-3-540-41960-0},
	Nonote = {10.1007/3-540-45413-6\_15},
	Nourl = {http://dx.doi.org/10.1007/3-540-45413-6_15},
	Pages = {151-165},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Normalization by Evaluation for the Computational Lambda-Calculus},
	Volume = {2044},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-45413-6_15}}

@inproceedings{Berger91NormByEval,
	Abstract = {A functional p rarr;e (procedure rarr;expression) that inverts the evaluation functional for typed lambda;-terms in any model of typed lambda;-calculus containing some basic arithmetic is defined. Combined with the evaluation functional, p rarr;e yields an efficient normalization algorithm. The method is extended to lambda;-calculi with constants and is used to normalize (the lambda;-representations of) natural deduction proofs of (higher order) arithmetic. A consequence of theoretical interest is a strong completeness theorem for beta; eta;-reduction. If two lambda;-terms have the same value in some model containing representations of the primitive recursive functions (of level 1) then they are probably equal in the beta; eta;-calculus },
	Author = {Berger, U. and Schwichtenberg, H.},
	Booktitle = {Proc. Symposium on Logic in Computer Science, 1991. LICS '91., Proceedings of Sixth Annual IEEE Symposium on},
	Date-Added = {2012-03-29 13:04:39 +0200},
	Date-Modified = {2012-06-23 14:20:23 +0200},
	Keywords = {lambda-calculi;completeness theorem;constants;evaluation functional;inverse;natural deduction proofs;normalization algorithm;recursive functions;typed lambda-calculus;typed lambda-terms;formal logic;},
	Nodoi = {10.1109/LICS.1991.151645},
	Nomonth = {july},
	Pages = {203 -211},
	Series = {LICS '91},
	Title = {An inverse of the evaluation functional for typed $\lambda$-calculus},
	Year = {1991},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LICS.1991.151645}}

@incollection{Berger98NormByEval,
	Abstract = {We extend normalization by evaluation (first presented in [ 4 ]) from the pure typed Œª-calculus to general higher type term rewrite systems. This work also gives a theoretical explanation of the normalization algorithm implemented in the Minlog system},
	Affiliation = {Mathematisches Institut der Universit{\"a}t M{\"u}nchen Germany},
	Author = {Berger, Ulrich and Eberl, Matthias and Schwichtenberg, Helmut},
	Booktitle = {Prospects for Hardware Foundations},
	Date-Added = {2012-03-29 09:52:55 +0200},
	Date-Modified = {2012-03-29 09:53:26 +0200},
	Editor = {M{\"o}ller, Bernhard and Tucker, John},
	Keyword = {Computer Science},
	Noisbn = {978-3-540-65461-2},
	Nonote = {10.1007/3-540-49254-2\_4},
	Nourl = {http://dx.doi.org/10.1007/3-540-49254-2_4},
	Pages = {624-624},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Normalization by Evaluation},
	Volume = {1546},
	Year = {1998},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-49254-2_4}}

@inproceedings{Rompf11BBlocks,
	Author = {Rompf, Tiark and Sujeeth, Arvind K. and Lee, HyoukJoong and Brown, Kevin J. and Chafi, Hassan and Odersky, Martin and Olukotun, Kunle},
	Booktitle = dsl,
	Date-Added = {2012-03-28 15:11:14 +0200},
	Date-Modified = {2012-06-23 14:28:22 +0200},
	Keywords = {DSEL; optimization; multi-stage programming},
	Nodoi = {10.4204/EPTCS.66.5},
	Noeditor = {Danvy, Olivier and Shan, Chung-chieh},
	Nopublisher = {Open Publishing Association},
	Noseries = {EPTCS},
	Novolume = {66},
	Pages = {93-117},
	Title = {Building-Blocks for Performance Oriented {DSLs}},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.4204/EPTCS.66.5}}

@incollection{Emir07Patterns,
	Abstract = {Data in object-oriented programming is organized in a hierarchy of classes. The problem of object-oriented pattern matching is how to explore this hierarchy from the outside. This usually involves classifying objects by their run-time type, accessing their members, or determining some other characteristic of a group of objects. In this paper we compare six different pattern matching techniques: object-oriented decomposition, visitors, type-tests/type-casts, typecase, case classes, and extractors. The techniques are compared on nine criteria related to conciseness, maintainability and performance. The paper introduces case classes and extractors as two new pattern-matching methods and shows that their combination works well for all of the established criteria.},
	Address = springeraddr,
	Affiliation = {EPFL, 1015 Lausanne Switzerland},
	Author = {Emir, Burak and Odersky, Martin and Williams, John},
	Booktitle = ecoop,
	Date-Added = {2012-03-27 11:24:20 +0200},
	Date-Modified = {2012-03-27 11:25:17 +0200},
	Keyword = {Computer Science},
	Noeditor = {Ernst, Erik},
	Noisbn = {978-3-540-73588-5},
	Nonote = {10.1007/978-3-540-73589-2\_14},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-540-73589-2_14},
	Novolume = {4609},
	Pages = {273-298},
	Publisher = springer,
	Read = {1},
	Title = {Matching Objects with Patterns},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-73589-2_14}}

@incollection{Hajiyev06CodeQuest,
	Abstract = {Source code querying tools allow programmers to explore relations between different parts of the code base. This paper describes such a tool, named codeQuest. It combines two previous proposals, namely the use of logic programming and database systems. As the query language we use safe Datalog , which was originally introduced in the theory of databases. That provides just the right level of expressiveness; in particular recursion is indispensable for source code queries. Safe Datalog is like Prolog, but all queries are guaranteed to terminate, and there is no need for extra-logical annotations. Our implementation of Datalog maps queries to a relational database system. We are thus able to capitalise on the query optimiser provided by such a system. For recursive queries we implement our own optimisations in the translation from Datalog to SQL. Experiments confirm that this strategy yields an efficient, scalable code querying system.},
	Address = springeraddr,
	Affiliation = {Programming Tools Group, Oxford University Computing Laboratory, Wolfson Building, Parks Road, Oxford, OX1 3QD UK},
	Author = {Hajiyev, Elnar and Verbaere, Mathieu and de Moor, Oege},
	Booktitle = ecoop,
	Date-Added = {2012-03-26 20:20:46 +0200},
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Keyword = {Computer Science},
	Keywords = {query constructs},
	Noeditor = {Thomas, Dave},
	Noisbn = {978-3-540-35726-1},
	Nonote = {10.1007/11785477\_2},
	Noseries = lncs,
	Nourl = {http://dx.doi.org/10.1007/11785477_2},
	Novolume = {4067},
	Pages = {2-27},
	Publisher = springerbase,
	Title = {\emph{CodeQuest}: Scalable Source Code Queries with {Datalog}},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11785477_2}}

@inproceedings{Chafi10LangVirt,
	Acmid = {1869527},
	Author = {Chafi, Hassan and DeVito, Zach and Moors, Adriaan and Rompf, Tiark and Sujeeth, Arvind K. and Hanrahan, Pat and Odersky, Martin and Olukotun, Kunle},
	Booktitle = oopslacomp,
	Date-Added = {2012-03-26 02:48:39 +0200},
	Date-Modified = {2012-03-30 21:34:13 +0200},
	Keywords = {domain specific languages, dynamic optimizations, parallel programming},
	Location = {Reno/Tahoe, Nevada, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1869459.1869527},
	Noisbn = {978-1-4503-0203-6},
	Nourl = {http://doi.acm.org/10.1145/1869459.1869527},
	Numpages = {13},
	Pages = {835--847},
	Publisher = acm,
	Series = {OOPSLA '10},
	Title = {Language virtualization for heterogeneous parallel computing},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1869459.1869527},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1869459.1869527}}

@misc{Moors10TCP,
	Author = {Adriaan Moors},
	Date-Added = {2012-03-25 21:10:39 +0200},
	Date-Modified = {2012-04-11 22:19:53 +0200},
	Note = {Last accessed on 2012-04-11},
	Title = {Type Constructor Polymorphism},
	Url = {http://adriaanm.github.com/research/2010/10/06/new-in-scala-2.8-type-constructor-inference/},
	Year = {2010},
	Bdsk-Url-1 = {http://adriaanm.github.com/research/2010/10/06/new-in-scala-2.8-type-constructor-inference/}}

@misc{ScalaRef,
	Author = {Martin Odersky},
	Date-Added = {2012-03-24 03:02:58 +0100},
	Date-Modified = {2012-03-25 21:16:03 +0200},
	Nomonth = {August},
	Read = {1},
	Title = {The {Scala} Language Specification Version 2.9},
	Year = {2011}}

@inproceedings{Siek10gplml,
	Acmid = {1706358},
	Author = {Siek, Jeremy G.},
	Booktitle = pepm,
	Date-Added = {2012-03-21 17:12:35 +0100},
	Date-Modified = {2012-03-21 17:12:53 +0100},
	Keywords = {domain-specific embedded languages, metaprogramming, multi-stage programming, reflection},
	Location = {Madrid, Spain},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1706356.1706358},
	Noisbn = {978-1-60558-727-1},
	Nourl = {http://doi.acm.org/10.1145/1706356.1706358},
	Numpages = {2},
	Pages = {3},
	Publisher = acm,
	Series = {PEPM '10},
	Title = {General purpose languages should be metalanguages},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1706356.1706358},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1706356.1706358}}

@inproceedings{Pfenning88hoas,
	Acmid = {54010},
	Author = {Pfenning, F. and Elliot, C.},
	Booktitle = pldi,
	Date-Added = {2012-03-21 11:56:39 +0100},
	Date-Modified = {2012-03-21 17:35:06 +0100},
	Location = {Atlanta, Georgia, United States},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/53990.54010},
	Noisbn = {0-89791-269-1},
	Noseries = {PLDI '88},
	Nourl = {http://doi.acm.org/10.1145/53990.54010},
	Numpages = {10},
	Pages = {199--208},
	Publisher = acm,
	Title = {Higher-order abstract syntax},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/53990.54010},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/53990.54010}}

@inproceedings{Oliveira10TCOI,
	Acmid = {1869489},
	Author = {Oliveira, Bruno C.d.S. and Moors, Adriaan and Odersky, Martin},
	Booktitle = oopsla,
	Date-Added = {2012-03-20 15:42:48 +0100},
	Date-Modified = {2012-03-20 15:43:20 +0100},
	Keywords = {abstract datatypes, c++ concepts, scala, type classes},
	Location = {Reno/Tahoe, Nevada, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1869459.1869489},
	Noisbn = {978-1-4503-0203-6},
	Nourl = {http://doi.acm.org/10.1145/1869459.1869489},
	Numpages = {20},
	Pages = {341--360},
	Publisher = acm,
	Series = {OOPSLA '10},
	Title = {Type classes as objects and implicits},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1869459.1869489},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1869459.1869489}}

@inproceedings{Moors12Virtualized,
	Acmid = {2103769},
	Author = {Moors, Adriaan and Rompf, Tiark and Haller, Philipp and Odersky, Martin},
	Booktitle = {Proc.\ Workshop on Partial Evaluation and Semantics-Based Program Manipulation},
	Date-Added = {2012-03-20 14:54:14 +0100},
	Date-Modified = {2012-03-20 14:55:07 +0100},
	Keywords = {code generation, domain-specific languages, language virtualization, multi-stage programming},
	Location = {Philadelphia, Pennsylvania, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/2103746.2103769},
	Noisbn = {978-1-4503-1118-2},
	Nourl = {http://doi.acm.org/10.1145/2103746.2103769},
	Numpages = {4},
	Pages = {117--120},
	Publisher = acm,
	Series = {PEPM '12},
	Title = {Scala-virtualized},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2103746.2103769},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2103746.2103769}}

@book{Odersky11book,
	Author = {Odersky, Martin and Spoon, Lex and Venners, Bill},
	Date-Added = {2012-03-20 09:36:00 +0100},
	Date-Modified = {2012-03-20 10:02:24 +0100},
	Edition = {2nd},
	Howpublished = {Paperback},
	Keywords = {Scala},
	Noisbn = {0981531644},
	Nomonth = jan,
	Nourl = {http://www.worldcat.org/isbn/0981531644},
	Publisher = {Artima Inc},
	Title = {{Programming in Scala}},
	Year = {2011},
	Bdsk-Url-1 = {http://www.worldcat.org/isbn/0981531644}}

@inproceedings{Rothamel08generating,
	Acmid = {1449923},
	Author = {Rothamel, Tom and Liu, Yanhong A.},
	Booktitle = gpce,
	Date-Added = {2012-03-17 12:22:17 +0100},
	Date-Modified = {2013-05-13 09:14:00 +0000},
	Keywords = {automatic incrementalization, optimization, query constructs; Incremental computation},
	Location = {Nashville, TN, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1449913.1449923},
	Noisbn = {978-1-60558-267-2},
	Nourl = {http://doi.acm.org/10.1145/1449913.1449923},
	Numpages = {12},
	Pages = {55--66},
	Publisher = acm,
	Series = {GPCE '08},
	Title = {Generating incremental implementations of object-set queries},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1449913.1449923},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1449913.1449923}}

@inproceedings{rompf2010lightweight,
	Acmid = {1868314},
	Author = {Rompf, Tiark and Odersky, Martin},
	Booktitle = gpce,
	Conference = {GPCE},
	Date-Added = {2012-03-17 11:20:08 +0100},
	Date-Modified = {2012-03-19 02:20:36 +0100},
	Keywords = {code generation, domain-specific languages, language virtualization, multi-stage programming},
	Location = {Eindhoven, The Netherlands},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/1868294.1868314},
	Noisbn = {978-1-4503-0154-1},
	Noseries = {GPCE '10},
	Nourl = {http://doi.acm.org/10.1145/1868294.1868314},
	Numpages = {10},
	Pages = {127--136},
	Publisher = acm,
	Title = {Lightweight modular staging: a pragmatic approach to runtime code generation and compiled {DSLs}},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1868294.1868314}}

@article{Eini11Pain,
	Acmid = {1978556},
	Author = {Eini, Oren},
	Date-Added = {2012-03-16 17:33:47 +0100},
	Date-Modified = {2012-06-23 14:27:21 +0200},
	Issue_Date = {August 2011},
	Journal = cacm,
	Keywords = {LINQ},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1978542.1978556},
	Noissn = {0001-0782},
	Nomonth = aug,
	Nourl = {http://doi.acm.org/10.1145/1978542.1978556},
	Number = {8},
	Numpages = {7},
	Pages = {55--61},
	Publisher = acm,
	Title = {The pain of implementing {LINQ} providers},
	Volume = {54},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1978542.1978556},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1978542.1978556}}

@inproceedings{odersky2009fighting,
	Author = {Odersky, M. and Moors, A.},
	Booktitle = {IARCS Conf. Foundations of Software Technology and Theoretical Computer Science},
	Date-Added = {2012-03-16 17:10:11 +0100},
	Date-Modified = {2012-03-16 17:10:49 +0100},
	Pages = {427--451},
	Title = {Fighting Bit Rot with Types (Experience Report: {{Scala}} Collections)},
	Volume = {4},
	Year = {2009}}

@article{Peyton-Jones02,
	Abstract = { ABSTRACT Higher-order languages such as Haskell encourage the programmer to build abstractions by composing functions. A good compiler must inline many of these calls to recover an efficiently executable program. In principle, inlining is dead simple: just replace the call of a function by an instance of its body. But any compiler-writer will tell you that inlining is a black art, full of delicate compromises that work together to give good performance without unnecessary code bloat. The purpose of this paper is, therefore, to articulate the key lessons we learned from a full-scale ``production'' inliner, the one used in the Glasgow Haskell compiler. We focus mainly on the algorithmic aspects, but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner. },
	Author = {Peyton Jones, Simon L. and Marlow, Simon},
	Date-Added = {2012-03-16 16:14:52 +0100},
	Date-Modified = {2014-02-09 22:54:25 +0000},
	Eprint = {http://journals.cambridge.org/article_S0956796802004331},
	Journal = jfp,
	Keywords = {optimization},
	Nodoi = {10.1017/S0956796802004331},
	Nourl = {http://dx.doi.org/10.1017/S0956796802004331},
	Number = {4-5},
	Pages = {393-434},
	Title = {Secrets of the {Glasgow Haskell Compiler} inliner},
	Volume = {12},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/S0956796802004331}}

@phdthesis{chambers1992design,
	Author = {Chambers, C.},
	Date-Added = {2012-03-16 16:07:06 +0100},
	Date-Modified = {2012-03-16 16:07:25 +0100},
	School = {Stanford University},
	Title = {The design and implementation of the {Self} compiler, an optimizing compiler for object-oriented programming languages},
	Year = {1992}}

@article{kuehne06matters,
	Author = {Thomas Kuehne},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Date-Added = {2012-03-16 16:00:58 +0100},
	Date-Modified = {2012-03-16 16:00:58 +0100},
	Ee = {http://dx.doi.org/10.1007/s10270-006-0017-9},
	Journal = {Software and System Modeling},
	Nourl = {http://homepages.mcs.vuw.ac.nz/~tk/publications/papers/kuehne-matters.pdf},
	Number = {4},
	Pages = {369--385},
	Prg = {2011-08-31, Sebastian},
	Title = {Matters of (Meta-)Modeling},
	Volume = {5},
	Year = {2006},
	Bdsk-Url-1 = {http://homepages.mcs.vuw.ac.nz/~tk/publications/papers/kuehne-matters.pdf}}

@article{elliott03compiling,
	Author = {Elliott, Conal and Finne, Sigbjorn and de Moor, Oege},
	Date-Added = {2012-03-16 15:59:10 +0100},
	Date-Modified = {2012-06-23 14:23:06 +0200},
	Journal = jfp,
	Keywords = {DSEL; deep embedding},
	Nourl = {http://conal.net/papers/jfp-saig/compile-dsel.pdf},
	Number = 2,
	Pages = {455--481},
	Prg = {2011-08-24, Matteo},
	Title = {Compiling Embedded Languages},
	Volume = 13,
	Year = 2003,
	Bdsk-Url-1 = {http://conal.net/papers/jfp-saig/compile-dsel.pdf}}

@proceedings{DBLP:conf/oopsla/2003p,
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {OOPSLA},
	Editor = {Ron Crocker and Guy L. Steele Jr.},
	Noisbn = {1-58113-712-5},
	Publisher = acm,
	Title = {Proceedings of the 2003 ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications, OOPSLA 2003, October 26-30, 2003, Anaheim, CA, USA},
	Year = {2003}}

@inproceedings{DBLP:conf/oopsla/Cook92,
	Author = {William R. Cook},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {OOPSLA},
	Pages = {1-15},
	Title = {Interfaces and Specifications for the Smalltalk-80 Collection Classes},
	Year = {1992}}

@inproceedings{Bierman:2007:LTF:1297027.1297063,
	Author = {Bierman, Gavin M. and Meijer, Erik and Torgersen, Mads},
	Booktitle = oopsla,
	Date-Modified = {2012-03-29 10:40:24 +0200},
	Keywords = {C\#, LINQ},
	Noaddress = {New York, NY, USA},
	Noseries = {OOPSLA '07},
	Numpages = {20},
	Pages = {479--498},
	Publisher = acm,
	Title = {Lost in translation: formalizing proposed extensions to {C\#}},
	Year = {2007}}

@inproceedings{Meijer:2006:LRO:1142473.1142552,
	Author = {Meijer, Erik and Beckman, Brian and Bierman, Gavin},
	Booktitle = sigmod,
	Date-Modified = {2012-06-23 14:27:31 +0200},
	Keywords = {LINQ},
	Noaddress = {New York, NY, USA},
	Noseries = {SIGMOD '06},
	Numpages = {1},
	Pages = {706},
	Publisher = acm,
	Title = {{LINQ}: reconciling objects, relations and {XML} in the {.NET} framework},
	Year = {2006}}

@inproceedings{Leijen99DSEC,
	Acmid = {331977},
	Author = {Leijen, Daan and Meijer, Erik},
	Booktitle = dsl,
	Date-Added = {2012-03-26 02:43:28 +0200},
	Date-Modified = {2012-06-23 14:24:16 +0200},
	Keywords = {DSEL},
	Location = {Austin, Texas, United States},
	Noaddress = {Berkeley, CA, USA},
	Nodoi = {10.1145/331960.331977},
	Noisbn = {1-58113-255-7},
	Nopublisher = {USENIX Association},
	Noseries = {DSL '99},
	Nourl = {http://doi.acm.org/10.1145/331960.331977},
	Numpages = {14},
	Pages = {109--122},
	Publisher = acm,
	Title = {Domain specific embedded compilers},
	Year = {1999},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/331960.331977},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/331960.331977}}

@inproceedings{Grust:2009:FDP:1559845.1559982,
	Author = {Grust, Torsten and Mayr, Manuel and Rittinger, Jan and Schreiber, Tom},
	Booktitle = sigmod,
	Date-Modified = {2012-06-23 14:20:36 +0200},
	Keywords = {ferry, linq, pathfinder, sql1999},
	Noaddress = {New York, NY, USA},
	Noseries = {SIGMOD '09},
	Pages = {1063--1066},
	Publisher = acm,
	Title = {{FERRY}: database-supported program execution},
	Year = {2009}}

@article{JOT:issue_2010_07/article3,
	Author = {Miguel Garcia and Anastasia Izmaylova and Sibylle Schupp},
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Journal = {Journal of Object Technology},
	Keywords = {query constructs},
	Nomonth = jul,
	Number = {4},
	Pages = {45-68},
	Title = {Extending {Scala} with Database Query Capability},
	Volume = {9},
	Year = {2010}}

@inproceedings{Spiewak09scalaql:language-integrated,
	Author = {Daniel Spiewak and Tian Zhao},
	Booktitle = sle,
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Keywords = {query constructs},
	Title = {{ScalaQL}: Language-integrated database queries for {Scala}},
	Year = {2009}}

@inproceedings{Wegrzynowicz:2009:GBU:1639950.1640032,
	Author = {W\c{e}grzynowicz, Patrycja and Stencel, Krzysztof},
	Booktitle = oopsla,
	Date-Modified = {2012-04-11 15:09:04 +0200},
	Location = {Orlando, Florida, USA},
	Noaddress = {New York, NY, USA},
	Noseries = {OOPSLA '09},
	Numpages = {2},
	Pages = {821--822},
	Publisher = acm,
	Title = {The good, the bad, and the ugly: three ways to use a semantic code query system},
	Year = {2009}}

@book{DBLP:books/mk/Muchnick1997,
	Author = {Steven S. Muchnick},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Isbn = {1-55860-320-4},
	Publisher = {Morgan Kaufmann},
	Title = {Advanced Compiler Design and Implementation},
	Year = {1997}}

@techreport{Amadio94,
	Author = {Amadio, Roberto M. and Curien, Pierre-Lous},
	Institution = {Institut national de recherche en informatique et en automatique},
	Month = {March},
	Number = {161},
	Title = {Selected Domains and Lambda Calculi},
	Year = {1994}}

@inproceedings{Maier2013,
	Author = {Maier, Ingo and Odersky, Martin},
	Booktitle = ecoop,
	Nobooktitle = {ECOOP 2013 -- Object-Oriented Programming},
	Nodoi = {10.1007/978-3-642-39038-8_29},
	Noeditor = {Castagna, Giuseppe},
	Noisbn = {978-3-642-39037-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-39038-8_29},
	Novolume = {7920},
	Pages = {707-731},
	Publisher = Springer,
	Title = {Higher-Order Reactive Programming with Incremental Lists},
	Year = {2013}}

@inproceedings{Arvind13,
	Abstract = {Programmers who need high performance currently rely on low-level, architecture-specific programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Performance optimization with these frameworks usually requires expertise in the specific programming model and a deep understanding of the target architecture. Domain-specific languages (DSLs) are a promising alternative, allowing compilers to map problem-specific abstractions directly to low-level architecture-specific programming models. However, developing DSLs is difficult, and using multiple DSLs together in a single application is even harder because existing compiled solutions do not compose together. In this paper, we present four new performance-oriented DSLs developed with Delite, an extensible DSL compilation framework. We demonstrate new techniques to compose compiled DSLs embedded in a common backend together in a single program and show that generic optimizations can be applied across the different DSL sections. Our new DSLs are implemented with a small number of reusable components (less than 9 parallel operators total) and still achieve performance up to 125x better than library implementations and at worst within 30\% of optimized stand-alone DSLs. The DSLs retain good performance when composed together, and applying cross-DSL optimizations results in up to an additional 1.82x improvement.},
	Author = {Sujeeth, Arvind K. and Rompf, Tiark and Brown, Kevin J. and Lee, HyoukJoong and Chafi, Hassan and Popic, Victoria and Wu, Michael and Prokopec, Aleksandar and Jovanovic, Vojin and Odersky, Martin and Olukotun, Kunle},
	Booktitle = ecoop,
	Nobooktitle = {ECOOP 2013 -- Object-Oriented Programming},
	Nodoi = {10.1007/978-3-642-39038-8_3},
	Noeditor = {Castagna, Giuseppe},
	Noisbn = {978-3-642-39037-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-39038-8_3},
	Novolume = {7920},
	Pages = {52-78},
	Publisher = Springer,
	Title = {Composition and Reuse with Compiled Domain-Specific Languages},
	Year = {2013}}

@book{Hott,
	Address = {Princeton},
	Author = {{The Univalent Foundations Program}},
	Publisher = {Institute for Advanced Study},
	Title = {Homotopy Type Theory: Univalent Foundations of Mathematics},
	Year = 2013}

@incollection{Hofmann96,
	Author = {Hofmann, Martin},
	Booktitle = {Types for Proofs and Programs},
	Nodoi = {10.1007/3-540-61780-9_68},
	Noeditor = {Berardi, Stefano and Coppo, Mario},
	Noisbn = {978-3-540-61780-8},
	Nopublisher = {Springer Berlin Heidelberg},
	Nourl = {http://dx.doi.org/10.1007/3-540-61780-9_68},
	Pages = {153-164},
	Publisher = Springer,
	Series = lncs,
	Title = {Conservativity of equality reflection over intensional type theory},
	Volume = {1158},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-61780-9_68}}

@article{Lammel07,
	Author = {L\"{a}mmel, Ralf},
	Date-Modified = {2013-10-09 09:39:56 +0000},
	Issue_Date = {October, 2007},
	Journal = {Sci. Comput. Program.},
	Month = oct,
	Number = {3},
	Numpages = {30},
	Pages = {208--237},
	Publisher = {Elsevier North-Holland, Inc.},
	Title = {Google's {MapReduce} programming model --- Revisited},
	Volume = {68},
	Year = {2007}}

@inproceedings{Elliott:1997:FRA:258948.258973,
	Author = {Elliott, Conal and Hudak, Paul},
	Booktitle = icfp,
	Noaddress = {New York, NY, USA},
	Nobooktitle = {Proceedings of the second ACM SIGPLAN international conference on Functional programming},
	Noseries = {ICFP '97},
	Numpages = {11},
	Pages = {263--273},
	Publisher = acm,
	Title = {Functional reactive animation},
	Year = {1997}}

@misc{agda-head,
	Author = {{Agda Development Team}},
	Howpublished = {\url{http://wiki.portal.chalmers.se/agda/}},
	Note = {Accessed on 2013-10-30.},
	Title = {{The Agda Wiki}},
	Year = {2013}}

@inproceedings{Rendel:2009:TS:1542476.1542509,
	Acmid = {1542509},
	Address = {New York, NY, USA},
	Author = {Rendel, Tillmann and Ostermann, Klaus and Hofer, Christian},
	Booktitle = {Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation},
	Doi = {10.1145/1542476.1542509},
	Isbn = {978-1-60558-392-1},
	Keywords = {lambda calculus, language design, reflection, self interpretation, types},
	Location = {Dublin, Ireland},
	Numpages = {11},
	Pages = {293--303},
	Publisher = {ACM},
	Series = {PLDI '09},
	Title = {Typed Self-representation},
	Url = {http://doi.acm.org/10.1145/1542476.1542509},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1542476.1542509},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1542476.1542509}}

@inproceedings{Hofer:2010:MDL:1868294.1868307,
	Acmid = {1868307},
	Address = {New York, NY, USA},
	Author = {Hofer, Christian and Ostermann, Klaus},
	Booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
	Doi = {10.1145/1868294.1868307},
	Isbn = {978-1-4503-0154-1},
	Keywords = {domain-specific languages, embedded languages, scala, term representation, visitor pattern},
	Location = {Eindhoven, The Netherlands},
	Numpages = {10},
	Pages = {83--92},
	Publisher = {ACM},
	Series = {GPCE '10},
	Title = {Modular Domain-specific Language Components in Scala},
	Url = {http://doi.acm.org/10.1145/1868294.1868307},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1868294.1868307},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1868294.1868307}}

@inproceedings{Cook_w.r.:remote,
	Author = {William R. Cook and Ben Wiedermann},
	Booktitle = {In: The 13th International Symposium on Database Programming Languages (DBPL)},
	Title = {Remote batch invocation for SQL databases},
	Year = {2011}}

@inproceedings{fan2012incremental,
	Author = {Fan, Wenfei and Li, Jianzhong and Tang, Nan and Yu, Wenyuan},
	Booktitle = {Data Engineering (ICDE), 2012 IEEE 28th International Conference on},
	Organization = {IEEE},
	Pages = {318--329},
	Title = {Incremental detection of inconsistencies in distributed data},
	Year = {2012}}
