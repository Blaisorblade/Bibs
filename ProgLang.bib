%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Paolo Giosué Giarrusso at 2017-09-06 02:31:07 +0200 


%% Saved with string encoding Unicode (UTF-8) 


@string{acm = {ACM}}

@string{acmaddr = {}}

@string{acp4is = {Proc.\ AOSD Workshop on Aspects, Components, and Patterns for Infrastructure Software (ACP4IS)}}

@string{addisonwesleylongman = {Addison-Wesley}}

@string{aosd = {AOSD}}

@string{apsec = {Proc.\ Asia-Pacific Software Engineering Conf.\ (APSEC)}}

@string{ase = {Proc.\ Int'l Conf.\ Automated Software Engineering (ASE)}}

@string{btw = {Proc.\ GI-Fachtagung Datenbanksysteme f{\"u}r Business, Technologie und Web (BTW)}}

@string{cacm = {Commun.\ ACM}}

@string{cambridge = {Cambridge University Press}}

@string{cc = {Proc.\ Int'l Conf.\ Compiler Construction (CC)}}

@string{ccpe = {Concurrency and Computation: Practice and Experience}}

@string{chi = {Proc.\ Conf.\ Human Factors in Computing Systems (CHI)}}

@string{cpe = {Biennal Conf. Innovative Data Systems Research}}

@string{csmr = {Proc.\ European Conf.\ on Software Maintenance and Reengineering (CSMR)}}

@string{csur = {ACM Computing Surveys (CSUR)}}

@string{diplomarbeit = {Master's Thesis ({Diplomarbeit})}}

@string{dsl = {DSL}}

@string{ecoop = {ECOOP}}

@string{elsevier = {Elsevier}}

@string{elsevieraddr = {Amsterdam}}

@string{esecfse = {Proc.\ Europ.\ Software Engineering Conf./Foundations of Software Engineering (ESEC/FSE)}}

@string{etx = {Proc.\ OOPSLA Workshop on Eclipse Technology eXchange (ETX)}}

@string{etxe = {Proc.\ ECOOP Workshop on Eclipse Technology eXchange (ETX)}}

@string{eurosys = {Proc.\ European Conference on Computer Systems (EuroSys)}}

@string{fase = {Proc.\ Int'l Conf.\ Fundamental Approaches to Software Engineering}}

@string{fosd = {Proc.\ GPCE Workshop on Feature-Oriented Software Development (FOSD)}}

@string{fpca = {FPCA}}

@string{fse = {Proc.\ Int'l Symposium Foundations of Software Engineering (FSE)}}

@string{gcse = {Proc.\ Int'l Conf.\ Generative and Component-Based Software Engineering (GCSE)}}

@string{gi = {Gesellschaft f{\"u}r Informatik (GI)}}

@string{giaddr = {Bonn}}

@string{gpce = {GPCE}}

@string{hosc = {HOSC}}

@string{icdcs = {Proc.\ Int'l Conf.\ Distributed Computing Systems (ICDCS)}}

@string{icfp = {ICFP}}

@string{icmt = {Proc.\ Int'l Conf.\ Theory and Practice of Model Transformations (ICMT)}}

@string{icpc = {Proc.\ Int'l Conf.\ Program Comprehension (ICPC)}}

@string{icre = {Proc.\ Int'l Conf.\ Requirements Engineering (ICRE)}}

@string{icse = {Proc.\ Int'l Conf.\ Software Engineering (ICSE)}}

@string{icsecomp = {Comp.\ Int'l Conf.\ Software Engineering (ICSE)}}

@string{icsm = {Proc.\ Int'l Conf.\ Software Maintenance (ICSM)}}

@string{icsr = {Proc.\ Int'l Conf.\ Software Reuse (ICSR)}}

@string{ieee = {IEEE Computer Society}}

@string{ieeeaddr = {Los Alamitos, CA}}

@string{ieeeaddrp = {Piscataway, NJ}}

@string{ieeeaddrw = {Washington, DC}}

@string{ieeesoftware = {IEEE Software}}

@string{infcomput = {Information and Computation}}

@string{ipdps = {Proc. Int'l. Parallel and Distributed Processing Symp.}}

@string{iwpc = {Proc.\ Int'l Workshop on Program Comprehension (IWPC)}}

@string{jase = {Automated Software Engineering}}

@string{jfp = {JFP}}

@string{jot = {Journal of Object Technology (JOT)}}

@string{kde = {IEEE Trans. Knowledge and Data Engineering}}

@string{kluwer = {Kluwer}}

@string{ldta = {Proc.\ Workshop on Language Descriptions, Tools and Applications (LDTA)}}

@string{lfp = {Proc.\ ACM Conf.\ on LISP and Functional Programming}}

@string{lnbip = {Lecture Notes in Business Information Processing}}

@string{lncs = {LNCS}}

@string{lzi = {Leibniz-Zentrum f{\"u}r Informatik (LZI)}}

@string{lziaddr = {Wadern}}

@string{macs = {Proc.\ ICSE Workshop on Modeling and Analysis of Concerns in Software (MACS)}}

@string{mdtech = {School of Computer Science, University of Magdeburg}}

@string{models = {Proc.\ Int'l Conf.\ Model Driven Engineering Languages and Systems (MoDELS)}}

@string{netobjectdays = {Proc. Int'l Conf.\ Object-Oriented and Internet-based Technologies, Concepts, and Applications for a Networked World (Net.ObjectDays)}}

@string{newyork = {New York}}

@string{oopsla = {OOPSLA}}

@string{oopslacomp = {Companion Int'l Conf.\ Object-Oriented Programming, Systems, Languages and Applications}}

@string{patech = {Department of Informatics and Mathematics, University of Passau}}

@string{pepm = {PEPM}}

@string{pldi = {PLDI}}

@string{plpv = {Programming Languages meets Program Verification}}

@string{popl = {POPL}}

@string{re = {Proc.\ Int'l Requirements Engineering Conf. (RE)}}

@string{sac = {Proc.\ Symp.\ Applied Computing (SAC)}}

@string{sc = {Proc.\ Int'l Conf.\ Software Composition (SC)}}

@string{scam = {Proc.\ Int'l Workshop Source Code Analysis and Manipulation (SCAM)}}

@string{scp = {Sci. Comput. Program.}}

@string{setmdm = {Proc.\ EDBT Workshop on Software Engineering for Tailor-made Data Management}}

@string{sigmod = {Proc.\ Int'l SIGMOD Conf.\ on Management of Data (SIGMOD)}}

@string{sigplannot = {SIGPLAN Notices}}

@string{sigsoftnotice = {SIGSOFT Softw. Eng. Notes}}

@string{sle = {Proc.\ Conf.\ Software Language Engineering (SLE)}}

@string{spe = {Software: Practice and Experience}}

@string{splc = {Proc.\ Int'l Software Product Line Conference (SPLC)}}

@string{split = {Proc.\ SPLC Workshop on Software Product Line Testing (SPLiT)}}

@string{springer = {Springer-Verlag}}

@string{springeraddr = {}}

@string{springeraddr-not = {Berlin/Heidelberg}}

@string{springeraddrbhn = {Berlin/Heidelberg/New York}}

@string{springeraddrl = {London}}

@string{springeraddrnj = {Secaucus, NJ}}

@string{springeraddrnl = {Dordrecht}}

@string{springeraddrny = {New York}}

@string{springerbase = {Springer}}

@string{springernl = {Springer Netherlands}}

@string{tcs = {Theoretical Computer Science}}

@string{tocs = {ACM Trans. Comp. Syst. (TOCS)}}

@string{tods = {ACM Trans. Database Systems (TODS)}}

@string{tools = {Proc.\ Int'l Conf.\ Objects, Models, Components, Patterns (TOOLS EUROPE)}}

@string{toplas = {TOPLAS}}

@string{tosem = {ACM Trans. Softw. Eng. Methodol. (TOSEM)}}

@string{tpds = {IEEE Trans.\ Parallel Distr.\ Systems (TPDS)}}

@string{tse = {IEEE Trans.\ Softw.\ Eng. (TSE)}}

@string{vamos = {Proc.\ Int'l Workshop on Variability Modelling of Software-intensive Systems (VaMoS)}}

@string{visple = {Proc.\ SPLC Workshop on Visualization in Software Product Line Engineering (ViSPLE)}}

@string{wcre = {Proc.\ Working Conf.\ Reverse Engineering (WCRE)}}

@string{wgp = {Proc.\ SIGPLAN Workshop on Generic Programming}}

@string{wiley = {John Wiley \& Sons, Inc.}}

@string{wileyaddr = {New York, NY}}

@string{wrt = {Proc.\ ECOOP Workshop on Refactoring Tools (WRT)}}


@inproceedings{Casinghino2012step,
	Author = {Chris Casinghino and Vilhelm Sj{\"{o}}berg and Stephanie Weirich},
	Bibsource = {dblp computer science bibliography, http://dblp.org},
	Biburl = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1202-2918},
	Booktitle = {Proceedings Fourth Workshop on Mathematically Structured Functional Programming, MSFP@ETAPS 2012, Tallinn, Estonia, 25 March 2012.},
	Crossref = {DBLP:journals/corr/abs-1202-2407},
	Date-Added = {2017-09-06 00:30:58 +0000},
	Date-Modified = {2017-09-06 00:31:07 +0000},
	Doi = {10.4204/EPTCS.76.4},
	Pages = {25--39},
	Timestamp = {Wed, 03 May 2017 14:47:54 +0200},
	Title = {Step-Indexed Normalization for a Language with General Recursion},
	Url = {https://doi.org/10.4204/EPTCS.76.4},
	Year = {2012},
	Bdsk-Url-1 = {https://doi.org/10.4204/EPTCS.76.4},
	Bdsk-Url-2 = {http://dx.doi.org/10.4204/EPTCS.76.4}}

@article{Amadio1993subtyping,
	Abstract = {We investigate the interactions of subtyping and recursive types, in a simply typed \&lgr;-calculus. The two fundamental questions here are whether two (recursive)types are in the subtype relation and whether a term has a type. To address the first question, we relate various definitions of type equivalence and subtyping that are induced by a model, an ordering on infinite trees, an algorithm, and a set of type rules. We show soundness and completeness among the rules, the algorithm, and the tree semantics. We also prove soundness and a restricted form of completeness for the model. To address the second question, we show that to every pair of types in the subtype relation we can associate a term whose denotation is the uniquely determined coercion map between the two types. Moreover, we derive an algorithm that, when given a term with implicit coercions, can infer its least type whenever possible.},
	Author = {Amadio, Roberto M. and Cardelli, Luca},
	Date-Added = {2017-09-01 23:15:38 +0000},
	Date-Modified = {2017-09-01 23:15:38 +0000},
	Doi = {10.1145/155183.155231},
	Issn = {0164-0925},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Keywords = {coercions,Lambda-calculus,partial-equivalence relations,recursive types,regular trees,subtyping,tree orderings,typechecking algorithm,type equivalence},
	Month = sep,
	Number = {4},
	Pages = {575--631},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Subtyping {{Recursive Types}}},
	Urldate = {2015-05-26},
	Volume = {15},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/155183.155231}}

@article{Schwinghammer2009stepindexed,
	Abstract = {Step-indexed semantic interpretations of types were proposed as an alternative to purely syntactic proofs of type safety using subject reduction. The types are interpreted as sets of values indexed by the number of computation steps for which these values are guaranteed to behave like proper elements of the type. Building on work by Ahmed, Appel and others, we introduce a step-indexed semantics for the imperative object calculus of Abadi and Cardelli. Providing a semantic account of this calculus using more `traditional', domain-theoretic approaches has proved challenging due to the combination of dynamically allocated objects, higher-order store, and an expressive type system. Here we show that, using step-indexing, one can interpret a rich type discipline with object types, subtyping, recursive and bounded quantified types in the presence of state.},
	Author = {Schwinghammer, Jan and Hritcu, Catalin},
	Date-Added = {2017-08-29 14:34:17 +0000},
	Date-Modified = {2017-08-29 14:34:17 +0000},
	File = {Schwinghammer_Hritcu - 2009 - A Step-indexed Semantics of Imperative Objects.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/MBKT7DT6/Schwinghammer_Hritcu - 2009 - A Step-indexed Semantics of Imperative Objects.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/JNVJF5RH/744.html:text/html},
	Journal = {Logical Methods in Computer Science},
	Keywords = {_tablet},
	Language = {en},
	Month = dec,
	Timestamp = {2017-07-18T19:51:08Z},
	Title = {A {{Step}}-Indexed {{Semantics}} of {{Imperative Objects}}},
	Urldate = {2017-07-18},
	Volume = {Volume 5, Issue 4},
	Year = {2009}}

@unpublished{McBride2001derivative,
	Author = {McBride, Conor},
	Date-Added = {2017-07-29 03:36:42 +0000},
	Date-Modified = {2017-07-29 03:38:26 +0000},
	Note = {Last accessed on 29 June 2017},
	Title = {The derivative of a regular type is its type of one-hole contexts},
	Url = {http://www.strictlypositive.org/diff.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://www.strictlypositive.org/diff.pdf}}

@inproceedings{Cheney2013practical,
	Abstract = {Language-integrated query is receiving renewed attention, in part because of its support through Microsoft's LINQ framework. We present a practical theory of language-integrated query based on quotation and normalisation of quoted terms. Our technique supports join queries, abstraction over values and predicates, composition of queries, dynamic generation of queries, and queries with nested intermediate data. Higher-order features prove useful even for constructing first-order queries. We prove a theorem characterising when a host query is guaranteed to generate a single SQL query. We present experimental results confirming our technique works, even in situations where Microsoft's LINQ framework either fails to produce an SQL query or, in one case, produces an avalanche of SQL queries.},
	Address = {New York, NY, USA},
	Author = {Cheney, James and Lindley, Sam and Wadler, Philip},
	Booktitle = {Proceedings of the 18th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2017-07-28 11:59:23 +0000},
	Date-Modified = {2017-07-28 11:59:23 +0000},
	Doi = {10.1145/2500365.2500586},
	File = {Cheney et al - 2013 - A Practical Theory of Language-integrated Query.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/BRG3AF8D/Cheney et al - 2013 - A Practical Theory of Language-integrated Query.pdf:application/pdf},
	Isbn = {978-1-4503-2326-0},
	Keywords = {antiquotation,f\#,lambda calculus,LINQ,quotation,sql},
	Pages = {403--416},
	Publisher = {{ACM}},
	Series = {ICFP '13},
	Timestamp = {2017-07-28T11:47:12Z},
	Title = {A {{Practical Theory}} of {{Language}}-Integrated {{Query}}},
	Urldate = {2017-07-28},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2500365.2500586}}

@book{Barendregt1984lambda,
	Author = {H. P. Barendregt},
	Date-Added = {2017-07-22 16:08:41 +0000},
	Date-Modified = {2017-07-22 16:08:55 +0000},
	Publisher = {Elsevier},
	Title = {The Lambda Calculus: Its Syntax and Semantics},
	Year = {1984}}

@book{Harper2016PFPL,
	Author = {Robert Harper},
	Date-Added = {2017-07-17 18:24:45 +0000},
	Date-Modified = {2017-07-17 18:28:05 +0000},
	Edition = {2nd},
	Isbn = {9781107150300},
	Publisher = {Cambridge University Press},
	Title = {Practical Foundations for Programming Languages},
	Year = {2016}}

@inproceedings{Adams2014optimizing,
	Abstract = {The most widely used generic-programming system in the Haskell community, Scrap Your Boilerplate (SYB), also happens to be one of the slowest. Generic traversals in SYB are often an order of magnitude slower than equivalent handwritten, non-generic traversals. Thus while SYB allows the concise expression of many traversals, its use incurs a significant runtime cost. Existing techniques for optimizing other generic-programming systems are not able to eliminate this overhead. This paper presents an optimization that completely eliminates this cost. Essentially, it is a partial evaluation that takes advantage of domain-specific knowledge about the structure of SYB. It optimizes SYB-style traversals to be as fast as handwritten, non-generic code, and benchmarks show that this optimization improves the speed of SYB-style code by an order of magnitude or more.},
	Address = {New York, NY, USA},
	Author = {Adams, Michael D. and Farmer, Andrew and Magalh{\~a}es, Jos{\'e} Pedro},
	Booktitle = {Proceedings of the {{ACM SIGPLAN}} 2014 {{Workshop}} on {{Partial Evaluation}} and {{Program Manipulation}}},
	Date-Added = {2017-07-17 04:54:19 +0000},
	Date-Modified = {2017-07-17 04:54:19 +0000},
	Doi = {10.1145/2543728.2543730},
	File = {Adams et al - 2014 - Optimizing SYB is Easy!.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/D8MEIQ7C/Adams et al - 2014 - Optimizing SYB is Easy!.pdf:application/pdf},
	Isbn = {978-1-4503-2619-3},
	Keywords = {datatype-generic programming,Haskell,keywords: optimization,partial evaluation,performance,scrap your boilerplate (syb)},
	Pages = {71--82},
	Publisher = {{ACM}},
	Series = {PEPM '14},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Optimizing {{SYB}} Is {{Easy}}!},
	Urldate = {2014-07-31},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2543728.2543730}}

@inproceedings{Farmer2012hermit,
	Abstract = {The importance of reasoning about and refactoring programs is a central tenet of functional programming. Yet our compilers and development toolchains only provide rudimentary support for these tasks. This paper introduces a programmatic and compiler-centric interface that facilitates refactoring and equational reasoning. To develop our ideas, we have implemented HERMIT, a toolkit enabling informal but systematic transformation of Haskell programs from inside the Glasgow Haskell Compiler's optimization pipeline. With HERMIT, users can experiment with optimizations and equational reasoning, while the tedious heavy lifting of performing the actual transformations is done for them. HERMIT provides a transformation API that can be used to build higher-level rewrite tools. One use-case is prototyping new optimizations as clients of this API before being committed to the GHC toolchain. We describe a HERMIT application - a read-eval-print shell for performing transformations using HERMIT. We also demonstrate using this shell to prototype an optimization on a specific example, and report our initial experiences and remaining challenges.},
	Address = {New York, NY, USA},
	Author = {Farmer, Andrew and Gill, Andy and Komp, Ed and Sculthorpe, Neil},
	Booktitle = {Proceedings of the 2012 {{Haskell Symposium}}},
	Date-Added = {2017-07-17 04:54:19 +0000},
	Date-Modified = {2017-07-17 04:54:19 +0000},
	Doi = {10.1145/2364506.2364508},
	File = {Farmer et al - 2012 - The HERMIT in the Machine - A Plugin for the Interactive Transformation of GHC Core Language Programs.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/58DCMIQB/Farmer et al - 2012 - The HERMIT in the Machine - A Plugin for the Interactive Transformation of GHC Core Language Programs.pdf:application/pdf},
	Isbn = {978-1-4503-1574-6},
	Keywords = {dsls,equational reasoning,ghc,optimization,strategic programming},
	Pages = {1--12},
	Publisher = {{ACM}},
	Series = {Haskell '12},
	Shorttitle = {The {{HERMIT}} in the {{Machine}}},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {The {{HERMIT}} in the {{Machine}}: {{A Plugin}} for the {{Interactive Transformation}} of {{GHC Core Language Programs}}},
	Urldate = {2014-07-31},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2364506.2364508}}

@inproceedings{Farmer2014hermit,
	Abstract = {Stream Fusion, a popular deforestation technique in the Haskell community, cannot fuse the concatMap combinator. This is a serious limitation, as concatMap represents computations on nested streams. The original implementation of Stream Fusion used the Glasgow Haskell Compiler's user-directed rewriting system. A transformation which allows the compiler to fuse many uses of concatMap has previously been proposed, but never implemented, because the host rewrite system was not expressive enough to implement the proposed transformation. In this paper, we develop a custom optimization plugin which implements the proposed concatMap transformation, and study the effectiveness of the transformation in practice. We also provide a new translation scheme for list comprehensions which enables them to be optimized. Within this framework, we extend the transformation to monadic streams. Code featuring uses of concatMap experiences significant speedup when compiled with this optimization. This allows Stream Fusion to outperform its rival, foldr/build, on many list computations, and enables performance-sensitive code to be expressed at a higher level of abstraction.},
	Address = {New York, NY, USA},
	Author = {Farmer, Andrew and {Hoener zu Siederdissen}, Christian and Gill, Andy},
	Booktitle = {Proceedings of the {{ACM SIGPLAN}} 2014 {{Workshop}} on {{Partial Evaluation}} and {{Program Manipulation}}},
	Date-Added = {2017-07-17 04:54:19 +0000},
	Date-Modified = {2017-07-17 04:54:19 +0000},
	Doi = {10.1145/2543728.2543736},
	File = {ACM Full Text PDF:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/5V9CNA4T/Farmer et al. - 2014 - The HERMIT in the Stream Fusing Stream Fusion's c.pdf:application/pdf},
	Isbn = {978-1-4503-2619-3},
	Keywords = {_tablet,deforestation,functional programming,ghc,Haskell,optimization,program fusion,program transformation,stream fusion},
	Pages = {97--108},
	Publisher = {{ACM}},
	Series = {PEPM '14},
	Shorttitle = {The {{HERMIT}} in the {{Stream}}},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {The {{HERMIT}} in the {{Stream}}: {{Fusing Stream Fusion}}'s {{concatMap}}},
	Urldate = {2014-04-23},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2543728.2543736}}

@incollection{Sculthorpe2013hermit,
	Abstract = {This paper describes our experience using the HERMIT toolkit to apply well-known transformations to the internal core language of the Glasgow Haskell Compiler. HERMIT provides several mechanisms to support writing general-purpose transformations: a domain-specific language for strategic programming specialized to GHC's core language, a library of primitive rewrites, and a shell-style\textendash{}based scripting language for interactive and batch usage. There are many program transformation techniques that have been described in the literature but have not been mechanized and made available inside GHC \textemdash{} either because they are too specialized to include in a general-purpose compiler, or because the developers' interest is in theory rather than implementation. The mechanization process can often reveal pragmatic obstacles that are glossed over in pen-and-paper proofs; understanding and removing these obstacles is our concern. Using HERMIT, we implement eleven examples of three program transformations, report on our experience, and describe improvements made in the process.},
	Author = {Sculthorpe, Neil and Farmer, Andrew and Gill, Andy},
	Booktitle = {Implementation and {{Application}} of {{Functional Languages}}},
	Copyright = {\textcopyright{}2013 Springer-Verlag Berlin Heidelberg},
	Date-Added = {2017-07-17 04:54:19 +0000},
	Date-Modified = {2017-07-17 04:54:19 +0000},
	Editor = {Hinze, Ralf},
	File = {Sculthorpe et al - 2013 - The HERMIT in the Tree.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6Z3DTI5A/Sculthorpe et al - 2013 - The HERMIT in the Tree.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/QH4QPAZT/10.html:text/html},
	Isbn = {978-3-642-41581-4 978-3-642-41582-1},
	Keywords = {ghc,Information Systems Applications (incl. Internet),Logics and Meanings of Programs,Mathematical Logic and Formal Languages,Mechanization,Programming Languages; Compilers; Interpreters,Programming Techniques,Software Engineering,Transformation,Worker/wrapper},
	Language = {en},
	Month = jan,
	Pages = {86--103},
	Publisher = {{Springer Berlin Heidelberg}},
	Series = {Lecture Notes in Computer Science},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {The {{HERMIT}} in the {{Tree}}},
	Urldate = {2014-07-31},
	Year = {2013}}

@article{Headley2016random,
	Abstract = {We introduce the Random Access Zipper (RAZ), a simple, purely-functional data structure for editable sequences. A RAZ combines the structure of a zipper with that of a tree: like a zipper, edits at the cursor require constant time; by leveraging tree structure, relocating the edit cursor in the sequence requires logarithmic time. While existing data structures provide these time bounds, none do so with the same simplicity and brevity of code as the RAZ. The simplicity of the RAZ provides the opportunity for more programmers to extend the structure to their own needs, and we provide some suggestions for how to do so.},
	Archiveprefix = {arXiv},
	Author = {Headley, Kyle and Hammer, Matthew A.},
	Date-Added = {2017-07-16 17:04:14 +0000},
	Date-Modified = {2017-07-16 17:04:14 +0000},
	Eprint = {1608.06009},
	Eprinttype = {arxiv},
	File = {Headley_Hammer - 2016 - The Random Access Zipper - Simple, Purely-Functional Sequences.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/Q3WTTVTF/Headley_Hammer - 2016 - The Random Access Zipper - Simple, Purely-Functional Sequences.pdf:application/pdf;arXiv.org Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/74E92W5B/1608.html:text/html},
	Journal = {arXiv:1608.06009 [cs]},
	Keywords = {_tablet,Computer Science - Data Structures and Algorithms,Computer Science - Programming Languages},
	Month = aug,
	Primaryclass = {cs},
	Shorttitle = {The {{Random Access Zipper}}},
	Timestamp = {2016-10-06T11:35:38Z},
	Title = {The {{Random Access Zipper}}: {{Simple}}, {{Purely}}-{{Functional Sequences}}},
	Urldate = {2016-10-06},
	Year = {2016}}

@inproceedings{Rossberg2010fing,
	Abstract = {ML modules are a powerful language mechanism for decomposing programs into reusable components. Unfortunately, they also have a reputation for being "complex" and requiring fancy type theory that is mostly opaque to non-experts. While this reputation is certainly understandable, given the many non-standard methodologies that have been developed in the process of studying modules, we aim here to demonstrate that it is undeserved. To do so, we give a very simple elaboration semantics for a full-featured, higher-order ML-like module language. Our elaboration defines the meaning of module expressions by a straightforward, compositional translation into vanilla System F-$\omega$ (the higher-order polymorphic $\lambda$-calculus), under plain F-$\omega$ typing environments. We thereby show that ML modules are merely a particular mode of use of System F-$\omega$. Our module language supports the usual second-class modules with Standard ML-style generative functors and local module definitions. To demonstrate the versatility of our approach, we further extend the language with the ability to package modules as first-class values---a very simple extension, as it turns out. Our approach also scales to handle OCaml-style applicative functor semantics, but the details are significantly more subtle, so we leave their presentation to a future, expanded version of this paper. Lastly, we report on our experience using the "locally nameless" approach in order to mechanize the soundness of our elaboration semantics in Coq.},
	Address = {New York, NY, USA},
	Author = {Rossberg, Andreas and Russo, Claudio V. and Dreyer, Derek},
	Booktitle = {Proceedings of the 5th {{ACM SIGPLAN Workshop}} on {{Types}} in {{Language Design}} and {{Implementation}}},
	Date-Added = {2017-07-08 10:54:50 +0000},
	Date-Modified = {2017-07-08 10:54:50 +0000},
	Doi = {10.1145/1708016.1708028},
	File = {Rossberg et al - 2010 - F-ing Modules.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/XEC62NMC/Rossberg et al - 2010 - F-ing Modules.pdf:application/pdf},
	Isbn = {978-1-60558-891-9},
	Keywords = {abstract data types,elaboration,existential types,first-class modules,ML modules,system f,type systems},
	Pages = {89--102},
	Publisher = {{ACM}},
	Series = {TLDI '10},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {F-Ing {{Modules}}},
	Urldate = {2014-06-12},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1708016.1708028}}

@article{Hammer2016typeda,
	Abstract = {Over the past decade, programming language techniques for incremental computation have demonstrated that incremental programs with precise, carefully chosen dynamic names for data and sub-computations can dramatically outperform non-incremental programs, as well as those using traditional memoization (without such names). However, prior work lacks a verification mechanism to solve the ambiguous name problem, the problem of statically enforcing precise names. We say that an allocated pointer name is precise for an evaluation derivation when it identifies at most one value or subcomputation, and ambiguous otherwise. In this work, we define a refinement type system that gives practical static approximations to enforce precise, deterministic allocation names in otherwise functional programs. We show that this type system permits expressing familiar functional programs, and generic, composable library components. We prove that our type system enforces that well-typed programs name their values and sub-computations precisely, without ambiguity. Drawing closer to an implementation, we derive a bidirectional version of the type system, and prove that it corresponds to our declarative type system. A key challenge in implementing the bidirectional system is handling constraints over names, name terms and name sets; toward this goal, we give decidable, syntactic rules to guide these checks.},
	Archiveprefix = {arXiv},
	Author = {Hammer, Matthew A. and Dunfield, Joshua and Economou, Dimitrios J. and Narasimhamurthy, Monal},
	Date-Added = {2017-07-07 18:42:08 +0000},
	Date-Modified = {2017-07-07 18:42:08 +0000},
	Eprint = {1610.00097},
	Eprinttype = {arxiv},
	File = {Hammer et al - 2016 - Typed Adapton - Refinement types for incremental computations with precise names.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/PG36VUVG/Hammer et al - 2016 - Typed Adapton - Refinement types for incremental computations with precise names.pdf:application/pdf;arXiv.org Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/JA8NMP26/1610.html:text/html},
	Journal = {arXiv:1610.00097 [cs]},
	Keywords = {Computer Science - Programming Languages},
	Month = oct,
	Primaryclass = {cs},
	Shorttitle = {Typed {{Adapton}}},
	Timestamp = {2017-07-07T17:06:59Z},
	Title = {Typed {{Adapton}}: {{Refinement}} Types for Incremental Computations with Precise Names},
	Year = {2016}}

@inproceedings{Hammer2014adapton,
	Abstract = {Many researchers have proposed programming languages that support incremental computation (IC), which allows programs to be efficiently re-executed after a small change to the input. However, existing implementations of such languages have two important drawbacks. First, recomputation is oblivious to specific demands on the program output; that is, if a program input changes, all dependencies will be recomputed, even if an observer no longer requires certain outputs. Second, programs are made incremental as a unit, with little or no support for reusing results outside of their original context, e.g., when reordered. To address these problems, we present $\lambda$iccdd, a core calculus that applies a demand-driven semantics to incremental computation, tracking changes in a hierarchical fashion in a novel demanded computation graph. $\lambda$iccdd also formalizes an explicit separation between inner, incremental computations and outer observers. This combination ensures $\lambda$iccdd programs only recompute computations as demanded by observers, and allows inner computations to be reused more liberally. We present Adapton, an OCaml library implementing $\lambda$iccdd. We evaluated Adapton on a range of benchmarks, and found that it provides reliable speedups, and in many cases dramatically outperforms state-of-the-art IC approaches.},
	Address = {New York, NY, USA},
	Author = {Hammer, Matthew A. and Phang, Khoo Yit and Hicks, Michael and Foster, Jeffrey S.},
	Booktitle = {Proceedings of the 35th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
	Date-Added = {2017-07-07 18:41:50 +0000},
	Date-Modified = {2017-07-07 18:41:50 +0000},
	Doi = {10.1145/2594291.2594324},
	File = {Hammer et al. - 2014 - Adapton Composable, Demand-driven Incremental Com.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/KW5ITCRT/Hammer et al. - 2014 - Adapton Composable, Demand-driven Incremental Com.pdf:application/pdf},
	Isbn = {978-1-4503-2784-8},
	Keywords = {_tablet,call-by-push-value (CBPV),demanded computation graph (DCG) incremental computation,laziness,self-adjusting computation,thunks},
	Pages = {156--166},
	Publisher = {{ACM}},
	Series = {PLDI '14},
	Shorttitle = {Adapton},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Adapton: {{Composable}}, {{Demand}}-Driven {{Incremental Computation}}},
	Urldate = {2014-09-01},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2594291.2594324}}

@unpublished{Shah2017synthesis,
	Abstract = {Many domains require fast, efficient incremental algorithms with no runtime overhead, such as in approximate inference algorithms for machine learning. Currently, such algorithms must be produced manually. We propose the use of program synthesis to automate this work, since it is easily extensible, the generated programs are fast, and there is no runtime overhead. We explain the algorithm on a simple example and provide a comparison of synthesis to other techniques that automate incrementalization.},
	Author = {Rohin Shah and Rastislav Bodik},
	Date-Added = {2017-07-07 12:53:41 +0000},
	Date-Modified = {2017-07-07 14:24:30 +0000},
	Note = {Presented at \emph{IC 2017, First Workshop on Incremental Computing}; 2-page abstract available},
	Title = {Automated Incrementalization through Synthesis},
	Url = {http://pldi17.sigplan.org/event/ic-2017-papers-automated-incrementalization-through-synthesis},
	Year = {2017},
	Bdsk-Url-1 = {http://pldi17.sigplan.org/event/ic-2017-papers-automated-incrementalization-through-synthesis}}

@incollection{vanBenthemJutting1994checking,
	Abstract = {We have presented efficient syntax directed presentations of two subclasses of PTS: the semi-full systems, via the $\vdash$ sdsf relation the functional systems, via the $\vdash$f relation The only remaining defect in these presentations lies in the possible failure of tests for conversion in the application rule. Thus for normalizing functional and semi-full systems, everything has been said. For non-functional systems the situation is less clear. We know of no a priori bound on the amount of reduction necessary to correctly type $\lambda$-abstractions, so we must be content with the collective completeness of the family of syntax directed systems $\vdash$sd-n. We have made little impact on the Expansion Postponement problem, which we leave as future work. We can however bask in the relative peace of mind gained from the machine-checked presentation of most (i.e. those not concerning schematic judgments) of the above results.},
	Author = {{van Benthem Jutting}, L. S. and McKinna, J. and Pollack, R.},
	Booktitle = {Types for {{Proofs}} and {{Programs}}},
	Copyright = {\textcopyright{}1994 Springer-Verlag},
	Date-Added = {2017-07-03 00:01:01 +0000},
	Date-Modified = {2017-07-03 00:01:01 +0000},
	Editor = {Barendregt, Henk and Nipkow, Tobias},
	File = {Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/XVNUFWRM/3-540-58085-9_71.html:text/html},
	Isbn = {978-3-540-58085-0 978-3-540-48440-0},
	Keywords = {Artificial Intelligence (incl. Robotics),Logics and Meanings of Programs,Mathematical Logic and Formal Languages},
	Language = {en},
	Month = jan,
	Number = {806},
	Pages = {19--61},
	Publisher = {{Springer Berlin Heidelberg}},
	Series = {Lecture Notes in Computer Science},
	Timestamp = {2017-07-02T21:26:16Z},
	Title = {Checking Algorithms for {{Pure Type Systems}}},
	Urldate = {2014-07-29},
	Year = {1994}}

@article{Wadler2007girardreynolds,
	Abstract = {Jean-Yves Girard and John Reynolds independently discovered the second-order polymorphic lambda calculus, F2. Girard additionally proved a Representation Theorem: every function on natural numbers that can be proved total in second-order intuitionistic predicate logic, P2, can be represented in F2. Reynolds additionally proved an Abstraction Theorem: every term in F2 satisfies a suitable notion of logical relation; and formulated a notion of parametricity satisfied by well-behaved models.

We observe that the essence of Girard's result is a projection from P2 into F2, and that the essence of Reynolds's result is an embedding of F2 into P2, and that the Reynolds embedding followed by the Girard projection is the identity. We show that the inductive naturals are exactly those values of type natural that satisfy Reynolds's notion of parametricity, and as a consequence characterize situations in which the Girard projection followed by the Reynolds embedding is also the identity.

An earlier version of this paper used a logic over untyped terms. This version uses a logic over typed term, similar to ones considered by Abadi and Plotkin and by Takeuti, which better clarifies the relationship between F2 and P2.

This paper uses colour to enhance its presentation. If the link below is not blue, follow it for the colour version.

http://homepages.inf.ed.ac.uk/wadler},
	Author = {Wadler, Philip},
	Date-Added = {2017-06-30 14:58:04 +0000},
	Date-Modified = {2017-06-30 14:58:04 +0000},
	Doi = {10.1016/j.tcs.2006.12.042},
	File = {ScienceDirect Full Text PDF:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/IGZTECHJ/Wadler - 2007 - The Girard--Reynolds isomorphism (second edition).pdf:application/pdf;ScienceDirect Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/D5SF9E2N/S0304397506009236.html:text/html},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {Abstraction Theorem,Curry--Howard,Girard--Reynolds type system,Polymorphic lambda calculus,Representation Theorem,system f},
	Month = may,
	Number = {1\textendash{}3},
	Pages = {201--226},
	Series = {Festschrift for John C. Reynolds's 70th birthday},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {The {{Girard}}\textendash{}{{Reynolds}} Isomorphism (Second Edition)},
	Urldate = {2015-03-08},
	Volume = {375},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/j.tcs.2006.12.042}}

@unpublished{Kmett2012mirrored,
	Author = {Edward Kmett},
	Date-Added = {2017-06-29 02:16:34 +0000},
	Date-Modified = {2017-07-08 23:54:11 +0000},
	Lastchecked = {2017-06-29},
	Note = {Last accessed on 29 June 2017},
	Title = {Mirrored Lenses},
	Url = {http://comonad.com/reader/2012/mirrored-lenses/},
	Urldate = {2012-06-24},
	Year = {2012},
	Bdsk-Url-1 = {http://comonad.com/reader/2012/mirrored-lenses/}}

@unpublished{OConnor2012polymorphic,
	Author = {Russell O'Connor},
	Date-Added = {2017-06-29 01:58:29 +0000},
	Date-Modified = {2017-07-08 23:54:19 +0000},
	Lastchecked = {2017-06-29},
	Note = {Last accessed on 29 June 2017},
	Title = {Polymorphic Update with van {Laarhoven} Lenses},
	Url = {http://r6.ca/blog/20120623T104901Z.html},
	Urldate = {2012-06-23},
	Year = {2012},
	Bdsk-Url-1 = {http://r6.ca/blog/20120623T104901Z.html}}

@inbook{Barendregt1992lambda,
	Address = NewYork,
	Author = {Barendregt, Henk P.},
	Booktitle = {Handbook of Logic in Computer Science (vol. 2): Background: Computational Structures},
	Date-Added = {2017-06-28 17:02:15 +0000},
	Date-Modified = {2017-06-28 17:04:03 +0000},
	Pages = {117--309},
	Publisher = {Oxford University Press},
	Title = {Lambda Calculi with Types},
	Year = {1992}}

@inproceedings{Krishnaswami2013internalizing,
	Address = {Dagstuhl, Germany},
	Author = {Krishnaswami, Neelakantan R. and Dreyer, Derek},
	Booktitle = {Computer {{Science Logic}} 2013 ({{CSL}} 2013)},
	Date-Added = {2017-06-28 02:47:25 +0000},
	Date-Modified = {2017-06-28 02:47:25 +0000},
	Doi = {http://dx.doi.org/10.4230/LIPIcs.CSL.2013.432},
	Editor = {Rocca, Simona Ronchi Della},
	File = {Krishnaswami_Dreyer - 2013 - Internalizing Relational Parametricity in the Extensional Calculus of Constructions.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/V75RRRSA/Krishnaswami_Dreyer - 2013 - Internalizing Relational Parametricity in the Extensional Calculus of Constructions.pdf:application/pdf},
	Isbn = {978-3-939897-60-6},
	Pages = {432--451},
	Publisher = {{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik}},
	Series = {Leibniz International Proceedings in Informatics (LIPIcs)},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Internalizing {{Relational Parametricity}} in the {{Extensional Calculus}} of {{Constructions}}},
	Urn = {urn:nbn:de:0030-drops-42125},
	Volume = {23},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.4230/LIPIcs.CSL.2013.432}}

@inproceedings{Keller2010hereditary,
	Abstract = {We analyze a normalization function for the simply typed $\lambda$-calculus based on hereditary substitutions, a technique developed by Pfenning et al. The normalizer is implemented in Agda, a total language where all programs terminate. It requires no termination proof since it is structurally recursive which is recognized by Agda's termination checker. Using Agda as an interactive theorem prover we establish that our normalization function precisely identifies $B\eta$-equivalent terms and hence can be used to decide $B\eta$-equality. An interesting feature of this approach is that it is clear from the construction that $B\eta$-equality is primitive recursive.},
	Address = {New York, NY, USA},
	Author = {Keller, Chantal and Altenkirch, Thorsten},
	Booktitle = {Proceedings of the {{Third ACM SIGPLAN Workshop}} on {{Mathematically Structured Functional Programming}}},
	Date-Added = {2017-06-27 23:08:15 +0000},
	Date-Modified = {2017-06-27 23:08:15 +0000},
	Doi = {10.1145/1863597.1863601},
	File = {Keller_Altenkirch - 2010 - Hereditary Substitutions for Simple Types, Formalized.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/588I6JQ7/Keller_Altenkirch - 2010 - Hereditary Substitutions for Simple Types, Formalized.pdf:application/pdf},
	Isbn = {978-1-4503-0255-5},
	Keywords = {decidability of $\\beta$η-equality,hereditary substitutions,normalizer,type theory},
	Pages = {3--10},
	Publisher = {{ACM}},
	Series = {MSFP '10},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Hereditary {{Substitutions}} for {{Simple Types}}, {{Formalized}}},
	Urldate = {2015-07-06},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1863597.1863601}}

@incollection{Allais2017typeandscope,
	Abstract = {We abstract the common type-and-scope safe structure fromcomputations on lambda-terms that deliver, e.g., renaming, substitution, evaluation, CPS-transformation, and printing witha name supply. By exposing this structure, we can prove generic simulation and fusion lemmas relating operations built this way. This work has been fully formalised in Agda.},
	Address = {New York},
	Author = {Allais, Guillaume and Chapman, James and McBride, Conor and McKinna, James},
	Booktitle = {{{CPP}} 2017},
	Date-Added = {2017-06-24 02:07:42 +0000},
	Date-Modified = {2017-06-24 02:07:42 +0000},
	Editor = {Bertot, Yves and Vafeiadis, Viktor},
	File = {Allais et al - 2017 - Type-and-scope safe programs and their proofs.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/2N5WCWKR/Allais et al - 2017 - Type-and-scope safe programs and their proofs.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/H2GF769P/59447.html:text/html},
	Isbn = {978-1-4503-4705-1},
	Language = {en},
	Month = jan,
	Publisher = {{ACM, New York, NY}},
	Timestamp = {2017-06-24T01:48:23Z},
	Title = {Type-and-Scope Safe Programs and Their Proofs},
	Urldate = {2017-06-24},
	Year = {2017}}

@article{Benton2012strongly,
	Abstract = {There are two approaches to formalizing the syntax of typed object languages in a proof assistant or programming language. The extrinsic approach is to first define a type that encodes untyped object expressions and then make a separate definition of typing judgements over the untyped terms. The intrinsic approach is to make a single definition that captures well-typed object expressions, so ill-typed expressions cannot even be expressed. Intrinsic encodings are attractive and naturally enforce the requirement that metalanguage operations on object expressions, such as substitution, respect object types. The price is that the metalanguage types of intrinsic encodings and operations involve non-trivial dependency, adding significant complexity. This paper describes intrinsic-style formalizations of both simply-typed and polymorphic languages, and basic syntactic operations thereon, in the Coq proof assistant. The Coq types encoding object-level variables (de Bruijn indices) and terms are indexed by both type and typing environment. One key construction is the boot-strapping of definitions and lemmas about the action of substitutions in terms of similar ones for a simpler notion of renamings. In the simply-typed case, this yields definitions that are free of any use of type equality coercions. In the polymorphic case, some substitution operations do still require type coercions, which we at least partially tame by uniform use of heterogeneous equality.},
	Author = {Benton, Nick and Hur, Chung-Kil and Kennedy, Andrew J. and McBride, Conor},
	Date-Added = {2017-06-23 23:23:08 +0000},
	Date-Modified = {2017-06-23 23:23:08 +0000},
	Doi = {10.1007/s10817-011-9219-0},
	File = {Benton et al - 2012 - Strongly Typed Term Representations in Coq.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/HHCVBAAM/Benton et al - 2012 - Strongly Typed Term Representations in Coq.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/KZJCKU56/s10817-011-9219-0.html:text/html},
	Issn = {0168-7433, 1573-0670},
	Journal = {Journal of Automated Reasoning},
	Keywords = {Artificial Intelligence (incl. Robotics),de Bruijn indices,Mathematical Logic and Formal Languages,Mathematical Logic and Foundations,Symbolic and Algebraic Manipulation,The Coq proof assistant,Typed object languages},
	Language = {en},
	Month = aug,
	Number = {2},
	Pages = {141--159},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Strongly {{Typed Term Representations}} in {{Coq}}},
	Urldate = {2014-09-02},
	Volume = {49},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10817-011-9219-0}}

@inproceedings{Steele2009organizing,
	Abstract = {Alan Perlis, inverting OscarWilde's famous quip about cynics, once suggested, decades ago, that a Lisp programmer is one who knows the value of everything and the cost of nothing. Now that the conference on Lisp and Functional Programming has become ICFP, some may think that OCaml and Haskell programmers have inherited this (now undeserved) epigram. I do believe that as multicore processors are becoming prominent, and soon ubiquitous, it behooves all programmers to rethink their programming style, strategies, and tactics, so that their code may have excellent performance. For the last six years I have been part of a team working on a programming language, Fortress, that has borrowed ideas not only from Fortran, not only from Java, not only from Algol and Alphard and CLU, not only from MADCAP and MODCAP and MIRFAC and the Klerer-May system-but also from Haskell, and I would like to repay the favor. In this talk I will discuss three ideas (none original with me) that I have found to be especially powerful in organizing Fortress programs so that they may be executed equally effectively either sequentially or in parallel: user-defined associative operators (and, more generally, user-defined monoids); conjugate transforms of data; and monoid-caching trees (as described, for example, by Hinze and Paterson). I will exhibit pleasant little code examples (some original with me) that make use of these ideas.},
	Address = {New York, NY, USA},
	Author = {Steele, Jr., Guy L.},
	Booktitle = {Proceedings of the 14th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2017-06-04 20:24:39 +0000},
	Date-Modified = {2017-06-04 20:24:39 +0000},
	Doi = {10.1145/1596550.1596551},
	Isbn = {978-1-60558-332-7},
	Keywords = {associative operator,conjugate transform,monoid,reduction,tree},
	Pages = {1--2},
	Publisher = {{ACM}},
	Series = {ICFP '09},
	Timestamp = {2017-02-07T18:38:36Z},
	Title = {Organizing {{Functional Code}} for {{Parallel Execution}} or, {{Foldl}} and {{Foldr Considered Slightly Harmful}}},
	Urldate = {2017-02-07},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1596550.1596551}}

@article{Harper1992constructing,
	Abstract = {Type theories in the sense of Martin-L{\"o}f and the NuPRL system are based on taking as primitive a type-free programming language given by an operational semantics, and defining types as partial equivalence relations on the set of closed terms. The construction of a type system is based on a general form of inductive definition that may either be taken as acceptable in its own right, or further explicated in terms of other patterns of induction. One such account, based on a general theory of inductively-defined relations, was given by Allen. An alternative account, based on an essentially set-theoretic argument, is presented.},
	Author = {Harper, Robert},
	Date-Added = {2017-06-02 17:56:55 +0000},
	Date-Modified = {2017-06-02 17:56:55 +0000},
	Doi = {10.1016/0747-7171(92)90026-Z},
	File = {Harper - 1992 - Constructing type systems over an operational semantics.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/SSFAJZBH/Harper - 1992 - Constructing type systems over an operational semantics.pdf:application/pdf;ScienceDirect Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/7SEG9ZDU/074771719290026Z.html:text/html},
	Issn = {0747-7171},
	Journal = {Journal of Symbolic Computation},
	Month = jul,
	Number = {1},
	Pages = {71--84},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Constructing Type Systems over an Operational Semantics},
	Urldate = {2014-07-16},
	Volume = {14},
	Year = {1992},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/0747-7171(92)90026-Z}}

@inproceedings{Ahmed2006stepindexed,
	Abstract = {We present a sound and complete proof technique, based on syntactic logical relations, for showing contextual equivalence of expressions in a $\lambda$-calculus with recursive types and impredicative universal and existential types. Our development builds on the step-indexed PER model of recursive types presented by Appel and McAllester. We have discovered that a direct proof of transitivity of that model does not go through, leaving the ``PER'' status of the model in question. We show how to extend the Appel-McAllester model to obtain a logical relation that we can prove is transitive, as well as sound and complete with respect to contextual equivalence. We then augment this model to support relational reasoning in the presence of quantified types.Step-indexed relations are indexed not just by types, but also by the number of steps available for future evaluation. This stratification is essential for handling various circularities, from recursive functions, to recursive types, to impredicative polymorphism. The resulting construction is more elementary than existing logical relations which require complex machinery such as domain theory, admissibility, syntactic minimal invariance, and $\top$ $\top$-closure.},
	Author = {Ahmed, Amal},
	Booktitle = {Programming {{Languages}} and {{Systems}}},
	Date-Added = {2017-06-01 04:49:56 +0000},
	Date-Modified = {2017-06-01 04:49:56 +0000},
	Doi = {10.1007/11693024_6},
	File = {Ahmed - 2006 - Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/RZBITID3/Ahmed - 2006 - Step-Indexed Syntactic Logical Relations for Recursive and Quantified Types.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/SB5H46Q8/11693024_6.html:text/html},
	Language = {en},
	Month = mar,
	Pages = {69--83},
	Publisher = {{Springer, Berlin, Heidelberg}},
	Timestamp = {2017-01-13T00:19:01Z},
	Title = {Step-{{Indexed Syntactic Logical Relations}} for {{Recursive}} and {{Quantified Types}}},
	Urldate = {2017-01-13},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11693024_6}}

@inproceedings{Nikolic2014linview,
	Abstract = {Many analytics tasks and machine learning problems can be naturally expressed by iterative linear algebra programs. In this paper, we study the incremental view maintenance problem for such complex analytical queries. We develop a framework, called LINVIEW, for capturing deltas of linear algebra programs and understanding their computational cost. Linear algebra operations tend to cause an avalanche effect where even very local changes to the input matrices spread out and infect all of the intermediate results and the final view, causing incremental view maintenance to lose its performance benefit over re-evaluation. We develop techniques based on matrix factorizations to contain such epidemics of change. As a consequence, our techniques make incremental view maintenance of linear algebra practical and usually substantially cheaper than re-evaluation. We show, both analytically and experimentally, the usefulness of these techniques when applied to standard analytics tasks. Our evaluation demonstrates the efficiency of LINVIEW in generating parallel incremental programs that outperform re-evaluation techniques by more than an order of magnitude.},
	Address = {New York, NY, USA},
	Author = {Nikolic, Milos and ElSeidy, Mohammed and Koch, Christoph},
	Booktitle = {Proceedings of the 2014 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
	Date-Added = {2017-05-25 19:32:45 +0000},
	Date-Modified = {2017-05-25 19:32:45 +0000},
	Doi = {10.1145/2588555.2610519},
	File = {Nikolic et al - 2014 - LINVIEW - Incremental View Maintenance for Complex Analytical Queries.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6D9KEZSD/Nikolic et al - 2014 - LINVIEW - Incremental View Maintenance for Complex Analytical Queries.pdf:application/pdf},
	Isbn = {978-1-4503-2376-5},
	Keywords = {Compilation,Incremental view maintenance,linear algebra,machine learning,spark},
	Pages = {253--264},
	Publisher = {{ACM}},
	Series = {SIGMOD '14},
	Shorttitle = {{{LINVIEW}}},
	Timestamp = {2017-05-25T19:30:34Z},
	Title = {{{LINVIEW}}: {{Incremental View Maintenance}} for {{Complex Analytical Queries}}},
	Urldate = {2017-05-25},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2588555.2610519}}

@inproceedings{Flanagan1993essence,
	Abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style (CPS) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the ``continuation''). Since the nai\textasciidieresis{}ve CPS transformation considerably increases the size of programs, CPS compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the CPS transformation, this step is conceptually a second phase. Finally, code generators for typical CPS compilers treat continuations specially in order to optimize the interpretation of continuation parameters.
A thorough analysis of the abstract machine for CPS terms show that the actions of the code generator invert the nai\textasciidieresis{}ve CPS translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed CPS compilers do not need to employ the CPS transformation but can achieve the same results with a simple source-level transformation.},
	Address = {New York, NY, USA},
	Author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
	Booktitle = {Proceedings of the {{ACM SIGPLAN}} 1993 {{Conference}} on {{Programming Language Design}} and {{Implementation}}},
	Date-Added = {2017-05-25 19:17:26 +0000},
	Date-Modified = {2017-05-25 19:17:26 +0000},
	Doi = {10.1145/155090.155113},
	File = {Flanagan et al - 1993 - The Essence of Compiling with Continuations.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/RQGWXXKZ/Flanagan et al - 1993 - The Essence of Compiling with Continuations.pdf:application/pdf},
	Isbn = {0-89791-598-4},
	Pages = {237--247},
	Publisher = {{ACM}},
	Series = {PLDI '93},
	Timestamp = {2017-05-25T18:51:45Z},
	Title = {The {{Essence}} of {{Compiling}} with {{Continuations}}},
	Urldate = {2017-05-25},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/155090.155113}}

@misc{Atkey2015ILC,
	Author = {Robert Atkey},
	Date-Added = {2017-05-10 14:24:21 +0000},
	Date-Modified = {2017-06-29 02:19:00 +0000},
	Lastchecked = {2017-06-29},
	Note = {Last accessed on 29 June 2017},
	Read = {1},
	Title = {The Incremental λ-Calculus and Relational Parametricity},
	Url = {http://bentnib.org/posts/2015-04-23-incremental-lambda-calculus-and-parametricity.html},
	Urldate = {2015-04-23},
	Year = {2015},
	Bdsk-Url-1 = {http://bentnib.org/posts/2015-04-23-incremental-lambda-calculus-and-parametricity.html}}

@article{Statman1985logical,
	Author = {Statman, R.},
	Date-Added = {2017-04-28 19:18:16 +0000},
	Date-Modified = {2017-04-28 19:18:16 +0000},
	Doi = {10.1016/S0019-9958(85)80001-2},
	File = {Statman - 1985 - Logical relations and the typed λ-calculus.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/KGGQ5WMP/Statman - 1985 - Logical relations and the typed λ-calculus.pdf:application/pdf;ScienceDirect Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/WJBBIGUA/S0019995885800012.html:text/html},
	Issn = {0019-9958},
	Journal = {Information and Control},
	Month = may,
	Number = {2},
	Pages = {85--97},
	Timestamp = {2017-04-28T16:20:20Z},
	Title = {Logical Relations and the Typed $\lambda$-Calculus},
	Urldate = {2017-04-28},
	Volume = {65},
	Year = {1985},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0019-9958(85)80001-2}}

@inproceedings{Bernardy2011realizability,
	Abstract = {We describe a systematic method to build a logic from any programming language described as a Pure Type System (PTS). The formulas of this logic express properties about programs. We define a parametricity theory about programs and a realizability theory for the logic. The logic is expressive enough to internalize both theories. Thanks to the PTS setting, we abstract most idiosyncrasies specific to particular type theories. This confers generality to the results, and reveals parallels between parametricity and realizability.},
	Address = {Berlin, Heidelberg},
	Author = {Bernardy, Jean-Philippe and Lasson, Marc},
	Booktitle = {Proceedings of the 14th {{International Conference}} on {{Foundations}} of {{Software Science}} and {{Computational Structures}}: {{Part}} of the {{Joint European Conferences}} on {{Theory}} and {{Practice}} of {{Software}}},
	Date-Added = {2017-04-28 16:35:28 +0000},
	Date-Modified = {2017-06-12 05:04:29 +0000},
	Isbn = {978-3-642-19804-5},
	Pages = {108--122},
	Publisher = {{Springer-Verlag}},
	Series = {FOSSACS'11/ETAPS'11},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Realizability and Parametricity in Pure Type Systems},
	Urldate = {2014-08-11},
	Year = {2011}}

@inproceedings{Wadler1989theorems,
	Address = {New York, NY, USA},
	Author = {Wadler, Philip},
	Booktitle = {Proceedings of the {{Fourth International Conference}} on {{Functional Programming Languages}} and {{Computer Architecture}}},
	Date-Added = {2017-04-28 14:14:20 +0000},
	Date-Modified = {2017-04-28 14:14:20 +0000},
	Doi = {10.1145/99370.99404},
	File = {ACM Full Text PDF:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/2HHRW8S7/Wadler - 1989 - Theorems for Free!.pdf:application/pdf},
	Isbn = {978-0-89791-328-7},
	Pages = {347--359},
	Publisher = {{ACM}},
	Series = {FPCA '89},
	Timestamp = {2017-04-27T16:58:39Z},
	Title = {Theorems for {{Free}}!},
	Urldate = {2017-04-27},
	Year = {1989},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/99370.99404}}

@article{Pottier2006polymorphic,
	Abstract = {Defunctionalization is a program transformation that eliminates functions as first-class values. We show that defunctionalization can be viewed as a type-preserving transformation of an extension of F with guarded algebraic data types into itself. We also suggest that defunctionalization is an instance of concretization, a more general technique that allows eliminating constructs other than functions. We illustrate this point by presenting two new type-preserving transformations that can be viewed as instances of concretization. One eliminates R{\'e}my-style polymorphic records; the other eliminates the dictionary records introduced by the standard compilation scheme for Haskell's type classes.},
	Author = {Pottier, Fran{\c c}ois and Gauthier, Nadji},
	Date-Added = {2017-04-04 16:13:34 +0000},
	Date-Modified = {2017-04-04 16:13:34 +0000},
	Doi = {10.1007/s10990-006-8611-7},
	File = {Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/QUW7JIR8/10.html:text/html},
	Issn = {1388-3690, 1573-0557},
	Journal = {Higher-Order and Symbolic Computation},
	Language = {en},
	Month = mar,
	Number = {1},
	Pages = {125--162},
	Timestamp = {2017-04-04T16:13:05Z},
	Title = {Polymorphic Typed Defunctionalization and Concretization},
	Urldate = {2017-04-04},
	Volume = {19},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-006-8611-7}}

@inproceedings{Pottier2004polymorphic,
	Abstract = {Defunctionalization is a program transformation that aims to turn a higher-order functional program into a first-order one, that is, to eliminate the use of functions as first-class values. Its purpose is thus identical to that of closure conversion. It differs from closure conversion, however, by storing a tag, instead of a code pointer, within every closure. Defunctionalization has been used both as a reasoning tool and as a compilation technique.Defunctionalization is commonly defined and studied in the setting of a simply-typed $\lambda$-calculus, where it is shown that semantics and well-typedness are preserved. It has been observed that, in the setting of a polymorphic type system, such as ML or System F, defunctionalization is not type-preserving. In this paper, we show that extending System F with guarded algebraic data types allows recovering type preservation. This result allows adding defunctionalization to the toolbox of type-preserving compiler writers.},
	Address = {New York, NY, USA},
	Author = {Pottier, Fran{\c c}ois and Gauthier, Nadji},
	Booktitle = {Proceedings of the 31st {{ACM SIGPLAN}}-{{SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
	Date-Added = {2017-04-01 14:25:01 +0000},
	Date-Modified = {2017-04-01 14:25:01 +0000},
	Doi = {10.1145/964001.964009},
	File = {Pottier_Gauthier - 2004 - Polymorphic Typed Defunctionalization.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/5WH6QFAB/Pottier_Gauthier - 2004 - Polymorphic Typed Defunctionalization.pdf:application/pdf},
	Isbn = {1-58113-729-X},
	Keywords = {_tablet,closure conversion,defunctionalization,polymorphism,type preservation},
	Pages = {89--98},
	Publisher = {{ACM}},
	Series = {POPL '04},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Polymorphic {{Typed Defunctionalization}}},
	Urldate = {2015-11-26},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/964001.964009}}

@phdthesis{Huesca2015incrementality,
	Abstract = {Certified programming is a framework in which any program is correct by construction. Proof assistants and dependently typed programming languages are the representatives of this paradigm where the proof and implementation of a program are done at the same time. However, it has some limitations: a program in Type Theory is built only with pure and total functions. Our objective is to write efficient and certified programs. The contributions of this work are the formalization, in the Simply Typed Lambda Calculus, of two mechanisms to achieve efficiency: to validate impure computations and to optimize computations by incrementality. An impure computation, that is a program with effects, and its validation in a functional and total language is done through a posteriori simulation. The simulation is performed afterwards on a monadic procedure and is guided by a prophecy. An efficient oracle is responsible for producing prophecies which is actually, the monadic procedure itself translated into an effectful programming language. The second contribution is an optimization to perform incremental computations. Incrementality as a way to propagate an input change into a corresponding output change is guided by formal change descriptions over terms and dynamic differentiation of functions. Displaceable types represent data-changes while an extension of the simply typed lambda calculus with differentials and partial derivatives offers a language to reason about incrementality.},
	Author = {Huesca, Lourdes del Carmen Gonzalez},
	Date-Added = {2017-03-16 16:30:53 +0000},
	Date-Modified = {2017-03-16 16:30:53 +0000},
	File = {Huesca - 2015 - Incrementality and effect simulation in the simply typed lambda calculus.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/FR8MMS3M/Huesca - 2015 - Incrementality and effect simulation in the simply typed lambda calculus.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/XKP8BXNQ/tel-01248531.html:text/html},
	Language = {en},
	Month = nov,
	School = {Universite Paris Diderot-Paris VII},
	Timestamp = {2016-02-29T22:13:26Z},
	Title = {Incrementality and Effect Simulation in the Simply Typed Lambda Calculus},
	Urldate = {2016-02-29},
	Year = {2015}}

@inproceedings{Schwaab2013modular,
	Abstract = {Methods for reusing code are widespread and well researched, but methods for reusing proofs are still emerging. We consider the use of dependent types for this purpose, introducing a modular approach for composing mechanized proofs. We show that common techniques for abstracting algorithms over data structures naturally translate to abstractions over proofs. We introduce a language composed of a series of smaller language components, each defined as functors, and tie them together by taking the fixed point of their sum [Malcom, 1990]. We then give proofs of type preservation for each language component and show how to compose these proofs into a proof for the entire language, again by taking the fixed point of a sum of functors.},
	Address = {New York, NY, USA},
	Author = {Schwaab, Christopher and Siek, Jeremy G.},
	Booktitle = {Proceedings of the 7th {{Workshop}} on {{Programming Languages Meets Program Verification}}},
	Date-Added = {2017-03-09 18:49:05 +0000},
	Date-Modified = {2017-03-13 15:51:59 +0000},
	Doi = {10.1145/2428116.2428120},
	File = {Schwaab_Siek - 2013 - Modular Type-safety Proofs in Agda.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/52CDZBKC/Schwaab_Siek - 2013 - Modular Type-safety Proofs in Agda.pdf:application/pdf},
	Isbn = {978-1-4503-1860-0},
	Keywords = {Agda,meta-theory,modularity},
	Pages = {3--12},
	Publisher = {{ACM}},
	Series = {PLPV '13},
	Timestamp = {2017-03-09T18:39:02Z},
	Title = {Modular Type-Safety Proofs in {{Agda}}},
	Urldate = {2017-03-09},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2428116.2428120}}

@inproceedings{Altenkirch1999monadic,
	Abstract = {We present a definition of untyped $\lambda$-terms using a heterogeneous datatype, i.e. an inductively defined operator. This operator can be extended to a Kleisli triple, which is a concise way to verify the substitution laws for $\lambda$-calculus. We also observe that repetitions in the definition of the monad as well as in the proofs can be avoided by using well-founded recursion and induction instead of structural induction. We extend the construction to the simply typed $\lambda$-calculus using dependent types, and show that this is an instance of a generalization of Kleisli triples. The proofs for the untyped case have been checked using the LEGO system.},
	Author = {Altenkirch, Thorsten and Reus, Bernhard},
	Booktitle = {Computer {{Science Logic}}},
	Copyright = {\textcopyright{}1999 Springer-Verlag Berlin Heidelberg},
	Date-Added = {2017-03-05 08:32:32 +0000},
	Date-Modified = {2017-03-05 08:32:32 +0000},
	Doi = {10.1007/3-540-48168-0_32},
	Editor = {Flum, J{\"o}rg and Rodriguez-Artalejo, Mario},
	File = {Altenkirch_Reus - 1999 - Monadic Presentations of Lambda Terms Using Generalized Inductive Types.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/RXCQQMPK/Altenkirch_Reus - 1999 - Monadic Presentations of Lambda Terms Using Generalized Inductive Types.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6SPV7TX9/3-540-48168-0_32.html:text/html},
	Isbn = {978-3-540-66536-6 978-3-540-48168-3},
	Keywords = {Artificial Intelligence (incl. Robotics),category theory,inductive types,Logics and Meanings of Programs,Mathematical Logic and Formal Languages,Mathematical Logic and Foundations,Theory of Computation,type theory,λ-Calculus},
	Language = {en},
	Month = sep,
	Pages = {453--468},
	Publisher = {{Springer Berlin Heidelberg}},
	Series = {Lecture Notes in Computer Science},
	Timestamp = {2017-03-05T07:05:49Z},
	Title = {Monadic {{Presentations}} of {{Lambda Terms Using Generalized Inductive Types}}},
	Urldate = {2017-03-05},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-48168-0_32}}

@inproceedings{Owens2016functional,
	Abstract = {When doing an interactive proof about a piece of software, it is important that the underlying programming language's semantics does not make the proof unnecessarily difficult or unwieldy. Both small-step and big-step semantics are commonly used, and the latter is typically given by an inductively defined relation. In this paper, we consider an alternative: using a recursive function akin{\"\i}\textthreequarters\textquestiondown{}to an interpreter for the language. The advantages include a better induction theorem, less duplication, accessibility to ordinary functional programmers, and the ease of doing symbolic simulation in proofs via rewriting. We believe that this style of semantics is well suited for compiler verification, including proofs of divergence preservation. We do not claim the invention of this style of semantics: our contribution here is to clarify its value, and to explain how it supports several language features that might appear to require a relational or small-step approach. We illustrate the technique on a simple imperative language with C-like for-loops and a break statement, and compare it to a variety of other approaches. We also provide ML and lambda-calculus based examples to illustrate its generality.},
	Address = {New York, NY, USA},
	Author = {Owens, Scott and Myreen, Magnus O. and Kumar, Ramana and Tan, Yong Kiam},
	Booktitle = {Proceedings of the 25th {{European Symposium}} on {{Programming Languages}} and {{Systems}} - {{Volume}} 9632},
	Date-Added = {2017-03-05 06:26:10 +0000},
	Date-Modified = {2017-03-05 06:26:10 +0000},
	Doi = {10.1007/978-3-662-49498-1_23},
	File = {Owens et al - 2016 - Functional Big-Step Semantics.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/FMCDCGVB/Owens et al - 2016 - Functional Big-Step Semantics.pdf:application/pdf},
	Isbn = {978-3-662-49497-4},
	Pages = {589--615},
	Publisher = {{Springer-Verlag New York, Inc.}},
	Timestamp = {2017-02-28T21:24:41Z},
	Title = {Functional {{Big}}-{{Step Semantics}}},
	Urldate = {2017-02-28},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-662-49498-1_23}}

@inproceedings{McBride2010outrageous,
	Abstract = {Tagless interpreters for well-typed terms in some object language are a standard example of the power and benefit of precise indexing in types, whether with dependent types, or generalized algebraic datatypes. The key is to reflect object language types as indices (however they may be constituted) for the term datatype in the host language, so that host type coincidence ensures object type coincidence. Whilst this technique is widespread for simply typed object languages, dependent types have proved a tougher nut with nontrivial computation in type equality. In their type-safe representations, Danielsson [2006] and Chapman [2009] succeed in capturing the equality rules, but at the cost of representing equality derivations explicitly within terms. This article constructs a type-safe representation for a dependently typed object language, dubbed KIPLING, whose computational type equality just appropriates that of its host, Agda. The KIPLING interpreter example is not merely de rigeur - it is key to the construction. At the heart of the technique is that key component of generic programming, the universe.},
	Address = {New York, NY, USA},
	Author = {McBride, Conor},
	Booktitle = {Proceedings of the 6th {{ACM SIGPLAN Workshop}} on {{Generic Programming}}},
	Date-Added = {2017-03-05 05:50:46 +0000},
	Date-Modified = {2017-03-05 05:50:46 +0000},
	Doi = {10.1145/1863495.1863497},
	File = {McBride - 2010 - Outrageous but Meaningful Coincidences - Dependent Type-safe Syntax and Evaluation.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/J5I5KU9E/McBride - 2010 - Outrageous but Meaningful Coincidences - Dependent Type-safe Syntax and Evaluation.pdf:application/pdf},
	Isbn = {978-1-4503-0251-7},
	Keywords = {dependent types,generic programming},
	Pages = {1--12},
	Publisher = {{ACM}},
	Series = {WGP '10},
	Shorttitle = {Outrageous but {{Meaningful Coincidences}}},
	Timestamp = {2016-02-29T23:17:09Z},
	Title = {Outrageous but {{Meaningful Coincidences}}: {{Dependent Type}}-Safe {{Syntax}} and {{Evaluation}}},
	Urldate = {2014-08-08},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1863495.1863497}}

@inproceedings{Augustsson1999exercise,
	Abstract = {The result type of an interpreter written in a typed language is normally a tagged union. By using depent types, we can be more precise about the type of values that the intepreter returns. There is no need for tagging these values with their type, something which opens the door to more efficient interpreters.},
	Author = {Augustsson, Lennart and Carlsson, Magnus},
	Booktitle = {In {{Workshop}} on {{Dependent Types}} in {{Programming}}, {{Gothenburg}}},
	Date-Added = {2017-03-05 05:49:14 +0000},
	Date-Modified = {2017-03-05 05:49:14 +0000},
	File = {Augustsson_Carlsson - 1999 - An exercise in dependent types - A well-typed interpreter.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/78VRS7N7/Augustsson_Carlsson - 1999 - An exercise in dependent types - A well-typed interpreter.pdf:application/pdf;Citeseer - Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/4CEEK5VJ/summary.html:text/html},
	Shorttitle = {An Exercise in Dependent Types},
	Timestamp = {2017-01-18T14:13:48Z},
	Title = {An Exercise in Dependent Types: {{A}} Well-Typed Interpreter},
	Year = {1999}}

@inproceedings{Kiselyov2017stream,
	Abstract = {Stream processing is mainstream (again): Widely-used stream libraries are now available for virtually all modern OO and functional languages, from Java to C\# to Scala to OCaml to Haskell. Yet expressivity and performance are still lacking. For instance, the popular, well-optimized Java 8 streams do not support the zip operator and are still an order of magnitude slower than hand-written loops.   We present the first approach that represents the full generality of stream processing and eliminates overheads, via the use of staging. It is based on an unusually rich semantic model of stream interaction. We support any combination of zipping, nesting (or flat-mapping), sub-ranging, filtering, mapping\textemdash{}of finite or infinite streams. Our model captures idiosyncrasies that a programmer uses in optimizing stream pipelines, such as rate differences and the choice of a ``for'' vs. ``while'' loops. Our approach delivers hand-written\textendash{}like code, but automatically. It explicitly avoids the reliance on black-box optimizers and sufficiently-smart compilers, offering highest, guaranteed and portable performance.   Our approach relies on high-level concepts that are then readily mapped into an implementation. Accordingly, we have two distinct implementations: an OCaml stream library, staged via MetaOCaml, and a Scala library for the JVM, staged via LMS. In both cases, we derive libraries richer and simultaneously many tens of times faster than past work. We greatly exceed in performance the standard stream libraries available in Java, Scala and OCaml, including the well-optimized Java 8 streams.},
	Address = {New York, NY, USA},
	Author = {Kiselyov, Oleg and Biboudis, Aggelos and Palladinos, Nick and Smaragdakis, Yannis},
	Booktitle = {Proceedings of the 44th {{ACM SIGPLAN Symposium}} on {{Principles}} of {{Programming Languages}}},
	Date-Added = {2017-02-02 15:54:34 +0000},
	Date-Modified = {2017-02-02 15:54:34 +0000},
	Doi = {10.1145/3009837.3009880},
	File = {Kiselyov et al - 2017 - Stream Fusion, to Completeness.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/8FWACEKE/Kiselyov et al - 2017 - Stream Fusion, to Completeness.pdf:application/pdf},
	Isbn = {978-1-4503-4660-3},
	Keywords = {code generation,multi-stage programming,optimization,stream fusion,streams},
	Pages = {285--299},
	Publisher = {{ACM}},
	Series = {POPL 2017},
	Timestamp = {2017-01-18T14:02:17Z},
	Title = {Stream {{Fusion}}, to {{Completeness}}},
	Urldate = {2017-01-18},
	Year = {2017},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/3009837.3009880}}

@inproceedings{Jovanovic2014,
	Acmid = {2658771},
	Address = {New York, NY, USA},
	Author = {Jovanovic, Vojin and Shaikhha, Amir and Stucki, Sandro and Nikolaev, Vladimir and Koch, Christoph and Odersky, Martin},
	Booktitle = {Proceedings of the 2014 International Conference on Generative Programming: Concepts and Experiences},
	Date-Added = {2017-02-02 14:44:08 +0000},
	Date-Modified = {2017-02-02 14:44:09 +0000},
	Doi = {10.1145/2658761.2658771},
	Isbn = {978-1-4503-3161-6},
	Keywords = {Deep Embedding, Embedded Domain-Specific Languages, Macros, Reflection, Shallow Embedding},
	Location = {V\&\#228;ster\&\#229;s, Sweden},
	Numpages = {10},
	Pages = {73--82},
	Publisher = {ACM},
	Series = {GPCE 2014},
	Title = {Yin-yang: Concealing the Deep Embedding of DSLs},
	Url = {http://doi.acm.org/10.1145/2658761.2658771},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2658761.2658771},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2658761.2658771}}

@inproceedings{Amin2017,
	Acmid = {3009866},
	Address = {New York, NY, USA},
	Author = {Amin, Nada and Rompf, Tiark},
	Booktitle = {Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages},
	Date-Added = {2017-01-18 14:00:16 +0000},
	Date-Modified = {2017-01-18 14:00:18 +0000},
	Doi = {10.1145/3009837.3009866},
	Isbn = {978-1-4503-4660-3},
	Keywords = {DOT, Definitional interpreters, Scala, dependent object types, type soundness},
	Location = {Paris, France},
	Numpages = {14},
	Pages = {666--679},
	Publisher = {ACM},
	Series = {POPL 2017},
	Title = {Type Soundness Proofs with Definitional Interpreters},
	Url = {http://doi.acm.org/10.1145/3009837.3009866},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3009837.3009866},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/3009837.3009866}}

@inproceedings{Cicek2016type,
	Abstract = {Incremental computation aims to speed up re-runs of a program after its inputs have been modified slightly. It works by recording a trace of the program's first run and propagating changes through the trace in incremental runs, trying to re-use as much of the original trace as possible. The recent work CostIt is a type and effect system to establish the time complexity of incremental runs of a program, as a function of input changes. However, CostIt is limited in two ways. First, it prohibits input changes that influence control flow. This makes it impossible to type programs that, for instance, branch on inputs that may change. Second, the soundness of CostIt is proved relative to an abstract cost semantics, but it is unclear how the semantics can be realized.   In this paper, we address both these limitations. We present DuCostIt, a re-design of CostIt, that combines reasoning about costs of change propagation and costs of from-scratch evaluation. The latter lifts the restriction on control flow changes. To obtain the type system, we refine Flow Caml, a type system for information flow analysis, with cost effects. Additionally, we inherit from CostIt index refinements to track data structure sizes and a co-monadic type. Using a combination of binary and unary step-indexed logical relations, we prove DuCostIt's cost analysis sound relative to not only an abstract cost semantics, but also a concrete semantics, which is obtained by translation to an ML-like language.},
	Address = {New York, NY, USA},
	Author = {{\c C}i{\c c}ek, Ezgi and Paraskevopoulou, Zoe and Garg, Deepak},
	Booktitle = {Proceedings of the 21st {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2017-03-13 17:29:21 +0000},
	Date-Modified = {2017-03-13 17:29:21 +0000},
	Doi = {10.1145/2951913.2951950},
	File = {{\c C}i{\c c}ek et al - 2016 - A Type Theory for Incremental Computational Complexity with Control Flow Changes.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/BUQH5SBT/{\c C}i{\c c}ek et al - 2016 - A Type Theory for Incremental Computational Complexity with Control Flow Changes.pdf:application/pdf},
	Isbn = {978-1-4503-4219-3},
	Keywords = {complexity analysis,incremental computation,type and effect systems},
	Pages = {132--145},
	Publisher = {{ACM}},
	Series = {ICFP 2016},
	Timestamp = {2017-02-07T18:31:46Z},
	Title = {A {{Type Theory}} for {{Incremental Computational Complexity}} with {{Control Flow Changes}}},
	Urldate = {2017-02-07},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2951913.2951950}}

@inproceedings{pitts2010step,
	Author = {Pitts, Andrew M},
	Booktitle = {Dagstuhl Seminar Proceedings},
	Organization = {Schloss Dagstuhl-Leibniz-Zentrum f\"ur Informatik},
	Title = {Step-indexed biorthogonality: a tutorial example},
	Year = {2010}}

@article{Dargaye2010verified,
	Abstract = {Function uncurrying is an important optimization for the efficient execution of functional programming languages. This optimization replaces curried functions by uncurried, multiple-argument functions, while preserving the ability to evaluate partial applications. First-order uncurrying (where curried functions are optimized only in the static scopes of their definitions) is well understood and implemented by many compilers, but its extension to higher-order functions (where uncurrying can also be performed on parameters and results of higher-order functions) is challenging. This article develops a generic framework that expresses higher-order uncurrying optimizations as type-directed insertion of coercions, and prove its correctness. The proof uses step-indexed logical relations and was entirely mechanized using the Coq proof assistant.},
	Author = {Dargaye, Zaynah and Leroy, Xavier},
	Date-Added = {2016-10-11 20:45:04 +0000},
	Date-Modified = {2016-10-11 20:45:04 +0000},
	Doi = {10.1007/s10990-010-9050-z},
	File = {Dargaye_Leroy - 2010 - A verified framework for higher-order uncurrying optimizations.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6ECEX4PR/Dargaye_Leroy - 2010 - A verified framework for higher-order uncurrying optimizations.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/HBGVB6MH/s10990-010-9050-z.html:text/html},
	Issn = {1388-3690, 1573-0557},
	Journal = {Higher-Order and Symbolic Computation},
	Language = {en},
	Month = jan,
	Number = {3},
	Pages = {199--231},
	Timestamp = {2016-10-11T19:59:00Z},
	Title = {A Verified Framework for Higher-Order Uncurrying Optimizations},
	Urldate = {2016-10-11},
	Volume = {22},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-010-9050-z}}

@inproceedings{Erdweg2014captureavoiding,
	Abstract = {Program transformations in terms of abstract syntax trees compromise referential integrity by introducing variable capture. Variable capture occurs when in the generated program a variable declaration accidentally shadows the intended target of a variable reference. Existing transformation systems either do not guarantee the avoidance of variable capture or impair the implementation of transformations.We present an algorithm called name-fix that automatically eliminates variable capture from a generated program by systematically renaming variables. name-fix is guided by a graph representation of the binding structure of a program, and requires name-resolution algorithms for the source language and the target language of a transformation. name-fix is generic and works for arbitrary transformations in any transformation system that supports origin tracking for names. We verify the correctness of name-fix and identify an interesting class of transformations for which name-fix provides hygiene. We demonstrate the applicability of name-fix for implementing capture-avoiding substitution, inlining, lambda lifting, and compilers for two domain-specific languages.},
	Author = {Erdweg, Sebastian and van der Storm, Tijs and Dai, Yi},
	Booktitle = {{{ECOOP}} 2014 \textendash{} {{Object}}-{{Oriented Programming}}},
	Date-Added = {2017-03-26 16:02:13 +0000},
	Date-Modified = {2017-03-26 16:02:13 +0000},
	Doi = {10.1007/978-3-662-44202-9_20},
	File = {Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/HSTVRBKP/978-3-662-44202-9_20.html:text/html},
	Language = {en},
	Month = jul,
	Pages = {489--514},
	Publisher = {{Springer, Berlin, Heidelberg}},
	Timestamp = {2017-03-26T16:00:51Z},
	Title = {Capture-{{Avoiding}} and {{Hygienic Program Transformations}}},
	Urldate = {2017-03-26},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-662-44202-9_20}}

@incollection{Firsov2016purely,
	Abstract = {Many applications have to maintain evolving data sources as well as views on these sources. If sources change, the corresponding views have to be adapted. Complete recomputation of views is typically too expensive. An alternative is to convert source changes into view changes and apply these to the views. This is the key idea of incremental computing. In this paper, we use Haskell to develop an incremental computing framework. We illustrate the concepts behind this framework by implementing several example computations on sequences. Our framework allows the user to implement incremental computations using arbitrary monad families that encapsulate mutable state. This makes it possible to use highly efficient algorithms for core computations.},
	Author = {Firsov, Denis and Jeltsch, Wolfgang},
	Booktitle = {Programming {{Languages}}},
	Copyright = {\textcopyright{}2016 Springer International Publishing Switzerland},
	Date-Added = {2016-10-05 13:39:46 +0000},
	Date-Modified = {2016-10-05 13:39:46 +0000},
	Doi = {10.1007/978-3-319-45279-1_5},
	Editor = {Castor, Fernando and Liu, Yu David},
	File = {Firsov_Jeltsch - 2016 - Purely Functional Incremental Computing.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/KNRAJ55X/Firsov_Jeltsch - 2016 - Purely Functional Incremental Computing.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/63WJJCHZ/978-3-319-45279-1_5.html:text/html},
	Isbn = {978-3-319-45278-4 978-3-319-45279-1},
	Keywords = {Logics and Meanings of Programs,Mathematical Logic and Formal Languages,Programming Languages; Compilers; Interpreters,Programming Techniques,Software Engineering},
	Language = {en},
	Month = sep,
	Number = {9889},
	Pages = {62--77},
	Publisher = {{Springer International Publishing}},
	Series = {Lecture Notes in Computer Science},
	Timestamp = {2016-10-05T13:36:04Z},
	Title = {Purely {{Functional Incremental Computing}}},
	Urldate = {2016-10-05},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-319-45279-1_5}}

@inproceedings{Rompf2015functional,
	Abstract = {We present the design and implementation of a SQL query processor that outperforms existing database systems and is written in just about 500 lines of Scala code -- a convincing case study that high-level functional programming can handily beat C for systems-level programming where the last drop of performance matters. The key enabler is a shift in perspective towards generative programming. The core of the query engine is an interpreter for relational algebra operations, written in Scala. Using the open-source LMS Framework (Lightweight Modular Staging), we turn this interpreter into a query compiler with very low effort. To do so, we capitalize on an old and widely known result from partial evaluation known as Futamura projections, which state that a program that can specialize an interpreter to any given input program is equivalent to a compiler. In this pearl, we discuss LMS programming patterns such as mixed-stage data structures (e.g. data records with static schema and dynamic field components) and techniques to generate low-level C code, including specialized data structures and data loading primitives.},
	Address = {New York, NY, USA},
	Author = {Rompf, Tiark and Amin, Nada},
	Booktitle = {Proceedings of the 20th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2016-11-28 16:40:01 +0000},
	Date-Modified = {2016-11-28 16:40:01 +0000},
	Doi = {10.1145/2784731.2784760},
	File = {Rompf_Amin - 2015 - Functional Pearl - A SQL to C Compiler in 500 Lines of Code.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/3CNA5SET/Rompf_Amin - 2015 - Functional Pearl - A SQL to C Compiler in 500 Lines of Code.pdf:application/pdf},
	Isbn = {978-1-4503-3669-7},
	Keywords = {Futamura projections,generative programming,Query Compilation,sql,staging},
	Pages = {2--9},
	Publisher = {{ACM}},
	Series = {ICFP 2015},
	Shorttitle = {Functional {{Pearl}}},
	Timestamp = {2015-09-09T10:42:51Z},
	Title = {Functional {{Pearl}}: {{A SQL}} to {{C Compiler}} in 500 {{Lines}} of {{Code}}},
	Urldate = {2015-09-09},
	Year = {2015},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2784731.2784760}}

@inproceedings{Lempsink2009typesafe,
	Abstract = {The UNIX diff program finds the difference between two text files using a classic algorithm for determining the longest common subsequence; however, when working with structured input (e.g. program code), we often want to find the difference between tree-like data (e.g. the abstract syntax tree). In a functional programming language such as Haskell, we can represent this data with a family of (mutually recursive) datatypes. In this paper, we describe a functional, datatype-generic implementation of diff (and the associated program patch). Our approach requires advanced type system features to preserve type safety; therefore, we present the code in Agda, a dependently-typed language well-suited to datatype-generic programming. In order to establish the usefulness of our work, we show that its efficiency can be improved with memoization and that it can also be defined in Haskell.},
	Address = {New York, NY, USA},
	Author = {{Lempsink}, Eelco and {Leather}, Sean and {L{\"o}h}, Andres},
	Booktitle = {Proceedings of the 2009 {{ACM SIGPLAN Workshop}} on {{Generic Programming}}},
	Date-Added = {2016-03-24 10:12:28 +0000},
	Date-Modified = {2016-03-24 10:12:28 +0000},
	Doi = {10.1145/1596614.1596624},
	File = {Lempsink et al - 2009 - Type-safe Diff for Families of Datatypes.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/85CGCP4M/Lempsink et al - 2009 - Type-safe Diff for Families of Datatypes.pdf:application/pdf},
	Isbn = {978-1-60558-510-9},
	Keywords = {datatype-generic programming,dependent types,edit distance},
	Pages = {61--72},
	Publisher = {{ACM}},
	Series = {WGP '09},
	Timestamp = {2016-03-09T14:33:35Z},
	Title = {Type-safe {{Diff}} for {{Families}} of {{Datatypes}}},
	Urldate = {2016-03-09},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1596614.1596624}}

@inproceedings{Marlow2004making,
	Abstract = {Higher-order languages that encourage currying are implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other.Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell.Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	Address = {New York, NY, USA},
	Author = {{Marlow}, Simon and {Jones}, Simon Peyton},
	Booktitle = {Proceedings of the ninth {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
	Date-Added = {2016-03-01 10:01:59 +0000},
	Date-Modified = {2016-03-01 10:02:38 +0000},
	Doi = {10.1145/1016850.1016856},
	Isbn = {1-58113-905-5},
	Pages = {4--15},
	Publisher = {{ACM}},
	Series = {ICFP '04},
	Shorttitle = {Making a fast curry},
	Timestamp = {2016-02-29T20:19:58Z},
	Title = {Making a fast curry: push/enter vs. eval/apply for higher-order languages},
	Urldate = {2016-02-29},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1016850.1016856}}

@article{Marlow2006making,
	Abstract = {Higher-order languages that encourage currying are typically implemented using one of two basic evaluation models: push/enter or eval/apply. Implementors use their intuition and qualitative judgements to choose one model or the other. Our goal in this paper is to provide, for the first time, a more substantial basis for this choice, based on our qualitative and quantitative experience of implementing both models in a state-of-the-art compiler for Haskell. Our conclusion is simple, and contradicts our initial intuition: compiled implementations should use eval/apply.},
	Author = {{Marlow}, Simon and {Jones}, Simon Peyton},
	Date-Added = {2016-03-01 10:01:15 +0000},
	Date-Modified = {2016-03-01 10:01:41 +0000},
	Doi = {10.1017/S0956796806005995},
	Issn = {1469-7653},
	Journal = {Journal of Functional Programming},
	Number = {4-5},
	Pages = {415--449},
	Shorttitle = {Making a fast curry},
	Timestamp = {2016-02-29T20:20:03Z},
	Title = {Making a fast curry: push/enter vs. eval/apply for higher-order languages},
	Urldate = {2016-02-29},
	Volume = {16},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/S0956796806005995}}

@inproceedings{Bolingbroke2009types,
	Abstract = {It is common for compilers to derive the calling convention of a function from its type. Doing so is simple and modular but misses many optimisation opportunities, particularly in lazy, higher-order functional languages with extensive use of currying. We restore the lost opportunities by defining Strict Core, a new intermediate language whose type system makes the missing distinctions: laziness is explicit, and functions take multiple arguments and return multiple results.},
	Address = {New York, NY, USA},
	Author = {{Bolingbroke}, Maximilian C. and {Peyton Jones}, Simon L.},
	Booktitle = {Proceedings of the {{2nd ACM SIGPLAN Symposium}} on {{Haskell}}},
	Date-Added = {2016-02-29 20:10:50 +0000},
	Date-Modified = {2016-02-29 20:12:40 +0000},
	Doi = {10.1145/1596638.1596640},
	File = {Bolingbroke_Peyton Jones - 2009 - Types Are Calling Conventions.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/7JN4CHH4/Bolingbroke_Peyton Jones - 2009 - Types Are Calling Conventions.pdf:application/pdf},
	Isbn = {978-1-60558-508-6},
	Keywords = {arity,calling conventions,intermediate language,strictness,unboxing,uncurrying},
	Pages = {1--12},
	Publisher = {{ACM}},
	Series = {Haskell '09},
	Timestamp = {2016-02-08T23:14:19Z},
	Title = {Types Are Calling Conventions},
	Urldate = {2016-02-08},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1596638.1596640}}

@inproceedings{Sergey2014modular,
	Abstract = {Since the mid '80s, compiler writers for functional languages (especially lazy ones) have been writing papers about identifying and exploiting thunks and lambdas that are used only once. However it has proved difficult to achieve both power and simplicity in practice. We describe a new, modular analysis for a higher-order language, which is both simple and effective, and present measurements of its use in a full-scale, state of the art optimising compiler. The analysis finds many single-entry thunks and one-shot lambdas and enables a number of program optimisations.},
	Address = {New York, NY, USA},
	Author = {{Sergey}, Ilya and {Vytiniotis}, Dimitrios and {Peyton Jones}, Simon},
	Booktitle = {Proceedings of the 41st {{ACM SIGPLAN-SIGACT Symposium}} on {{Principles}} of {{Programming Languages}}},
	Date-Added = {2016-03-01 09:29:17 +0000},
	Date-Modified = {2016-03-01 09:29:48 +0000},
	Doi = {10.1145/2535838.2535861},
	File = {Sergey et al - 2014 - Modular, Higher-order Cardinality Analysis in Theory and Practice.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/W5U3IS6V/Sergey et al - 2014 - Modular, Higher-order Cardinality Analysis in Theory and Practice.pdf:application/pdf},
	Isbn = {978-1-4503-2544-8},
	Keywords = {cardinality analysis,Compilers,functional programming languages,haskell,Lazy Evaluation,operational semantics,Program optimisation,static analysis,thunks,types and effects},
	Pages = {335--347},
	Publisher = {{ACM}},
	Series = {POPL '14},
	Timestamp = {2016-03-01T09:25:28Z},
	Title = {Modular, Higher-order Cardinality Analysis in Theory and Practice},
	Urldate = {2016-03-01},
	Year = {2014},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/2535838.2535861}}

@article{amadio2013certifying,
	Abstract = {We present a so-called labelling method to insert cost annotations in a higher-order functional program, to certify their correctness with respect to a standard compilation chain to assembly code including safe memory management, and to reason on them in a higher-order Hoare logic.},
	Author = {Amadio, Roberto M. and R{\'e}gis-Gianas, Yann},
	Date-Added = {2015-08-06 13:46:55 +0000},
	Date-Modified = {2015-08-06 13:47:06 +0000},
	File = {Amadio_R{\'e}gis-Gianas - 2013 - Certifying and reasoning about cost annotations of functional programs.pdf:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/QIMQX25D/Amadio_R{\'e}gis-Gianas - 2013 - Certifying and reasoning about cost annotations of functional programs.pdf:application/pdf;Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/GEU6IAJB/inria-00629473v2.html:text/html},
	Journal = {Higher-Order and Symbolic Computation},
	Language = {en},
	Month = jan,
	Timestamp = {2015-07-02 13:23:15},
	Title = {Certifying and reasoning about cost annotations of functional programs},
	Url = {https://hal.inria.fr/inria-00629473/document},
	Urldate = {2015-03-26},
	Year = {2013},
	Bdsk-Url-1 = {https://hal.inria.fr/inria-00629473/document}}

@article{Dwork84,
	Abstract = {The problem of unification of terms is log-space complete for P. In deriving this lower bound no use is made of the potentially concise representation of terms by directed acyclic graphs. In addition, the problem remains complete even if infinite substitutions are allowed. A consequence of this result is that parallelism cannot significantly improve on the best sequential solutions for unification. However, we show that for the problem of term matching, an important subcase of unification, there is a good parallel algorithm using O(log2n) time and nO(1) processors on a PRAM. For the O(log2n) parallel time upper bound we assume that the terms are represented by directed acyclic graphs; if the longer string representation is used we obtain an O(log n) parallel time bound.},
	Author = {Dwork, Cynthia and Kanellakis, Paris C. and Mitchell, John C.},
	Date-Added = {2015-04-14 13:44:04 +0000},
	Date-Modified = {2015-04-14 13:44:11 +0000},
	Doi = {10.1016/0743-1066(84)90022-0},
	File = {ScienceDirect Snapshot:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/7WQ67ZTB/0743106684900220.html:text/html},
	Issn = {0743-1066},
	Journal = {The Journal of Logic Programming},
	Month = jun,
	Number = {1},
	Pages = {35--50},
	Timestamp = {2015-04-14 13:23:50},
	Title = {On the sequential nature of unification},
	Url = {http://www.sciencedirect.com/science/article/pii/0743106684900220},
	Urldate = {2015-04-14},
	Volume = {1},
	Year = {1984},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0743106684900220},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0743-1066(84)90022-0}}

@inproceedings{Krishnaswami15,
	Author = {Neelakantan R. Krishnaswami and Pierre Pradic and Nick Benton},
	Booktitle = {Principles of Programming Languages (POPL)},
	Date-Added = {2014-11-22 16:57:20 +0000},
	Date-Modified = {2014-11-24 08:41:36 +0000},
	Month = jan,
	Title = {Integrating Linear and Dependent Types},
	Url = {http://www.cs.bham.ac.uk/~krishnan/dlnl-paper.pdf},
	Year = {2015},
	Bdsk-Url-1 = {http://www.cs.bham.ac.uk/~krishnan/dlnl-paper.pdf}}

@article{Burstall1977,
	Abstract = {A system of rules for transforming programs is described, with the programs in the form of recursion equations. An initially very simple, lucid, and hopefully correct program is transformed into a more efficient one by altering the recursion structure. Illustrative examples of program transformations are given, and a tentative implementation is described. Alternative structures for programs are shown, and a possible initial phase for an automatic or semiautomatic program-manipulation system is indicated.},
	Author = {Burstall, R. M. and Darlington, John},
	Date-Added = {2014-04-24 13:01:50 +0000},
	Date-Modified = {2014-04-24 13:01:50 +0000},
	Doi = {10.1145/321992.321996},
	File = {ACM Full Text PDF:/Users/pgiarrusso/Library/Application Support/Zotero/Profiles/0lm7uqnz.default/zotero/storage/6TRIHBF6/Burstall and Darlington - 1977 - A Transformation System for Developing Recursive P.pdf:application/pdf},
	Issn = {0004-5411},
	Journal = {J. ACM},
	Month = jan,
	Number = {1},
	Pages = {44\textendash{}67},
	Title = {A Transformation System for Developing Recursive Programs},
	Url = {http://doi.acm.org/10.1145/321992.321996},
	Urldate = {2014-04-23},
	Volume = {24},
	Year = {1977},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/321992.321996},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/321992.321996}}

@inproceedings{Bernardy10,
	Acmid = {1863592},
	Address = {New York, NY, USA},
	Author = {Bernardy, Jean-Philippe and Jansson, Patrik and Paterson, Ross},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-31 17:47:02 +0000},
	Date-Modified = {2014-03-31 17:47:03 +0000},
	Doi = {10.1145/1863543.1863592},
	Isbn = {978-1-60558-794-3},
	Keywords = {abstraction theorem, free theorems, pure type system},
	Location = {Baltimore, Maryland, USA},
	Numpages = {12},
	Pages = {345--356},
	Publisher = {ACM},
	Series = {ICFP '10},
	Title = {Parametricity and Dependent Types},
	Url = {http://doi.acm.org/10.1145/1863543.1863592},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863592},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863592}}

@inproceedings{Yakushev:2009:GPF,
	Abstract = {Many datatype-generic functions need access to the recursive positions in the structure of the datatype, and therefore adopt a fixed point view on datatypes. Examples include variants of fold that traverse the data following the recursive structure, or the Zipper data structure that enables navigation along the recursive positions. However, Hindley-Milner-inspired type systems with algebraic datatypes make it difficult to express fixed points for anything but regular datatypes. Many real-life examples such as abstract syntax trees are in fact systems of mutually recursive datatypes and therefore excluded. Using Haskell's GADTs and type families, we describe a technique that allows a fixed-point view for systems of mutually recursive datatypes. We demonstrate that our approach is widely applicable by giving several examples of generic functions for this view, most prominently the Zipper.},
	Acmid = {1596585},
	Address = {New York, NY, USA},
	Annote = {Why is compos not recursive?
composRec f = to . f . fmap (composRec f) . from

Sec. 2.2: Can't one just write "derive Functor"?

Sec. 4.1: promoted kinds? (Doesn't work so easily).},
	Author = {Yakushev, Alexey Rodriguez and Holdermans, Stefan and L\"{o}h, Andres and Jeuring, Johan},
	Booktitle = {Proceedings of the 14th ACM SIGPLAN International Conference on Functional Programming},
	Conference = {ICFP},
	Date-Added = {2014-03-13 11:11:47 +0000},
	Date-Modified = {2014-03-13 17:34:12 +0000},
	Doi = {10.1145/1596550.1596585},
	Isbn = {978-1-60558-332-7},
	Keywords = {datatype-generic programming, fixed points, haskell, mutually recursive datatypes},
	Location = {Edinburgh, Scotland},
	Numpages = {12},
	Pages = {233--244},
	Publisher = {ACM},
	Series = {ICFP '09},
	Title = {Generic Programming with Fixed Points for Mutually Recursive Datatypes},
	Url = {http://doi.acm.org/10.1145/1596550.1596585},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596550.1596585},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596550.1596585}}

@inproceedings{Jay11TSP,
	Acmid = {2034808},
	Address = {New York, NY, USA},
	Annote = {They don't distinguish T and Expr T:
> A consequence of the type of B is that our notion of quotation is type-preserving: if a program has type T , then its representation has type T , too. This shows that different quotations may have different types. An alternative would be to follow Rendel, Ostermann, and Hofer and introduce a new type Expr T of program representations so that terms cannot be confused with their representations; we leave this for future work.

Moreover, all their interpreters would also work for terms which haven't been quoted.

So I think this "future work" is impossible --- but they say otherwise in conclusions:
> A more interesting challenge is whether the results in this paper can be applied to a strongly normalising calculus. After all, if the basic calculus is strongly normalising, why shouldn't the interpretations be so too? To put it another way, can the Y operator be replaced by something that is strongly normalising?

[Their self-interpreters seem to work without Y --- but they use let rec, which is desugared to Y.]

> Is there a self-interpreter that is adequate, in the sense of Rendel, Ostermann, and Hofer? This seems plausible, at the price of making everything somewhat more obscure. Is there a self-interpreter for a language with decidable type-checking? This is a harder question, since it is not clear how to factorise the application of a term to a type.

==

Moreover, can one write interesting self-interpreters? Well, at least by now they can show a self-optimizer apparently, so things aren't so bad maybe.

Can we also discuss why they don't fall prey to G{\"o}del's incompleteness theorem/Tarski undefinability theorem? (But they don't have decidable typechecking, nor is theirs a total language?)
(It's also not like they can type everything, say E --- their system is funny there. Also, they don't support explicit type annotations in the source language.).

See also:
7.5 Adequacy
A weakness of our approach is that the type system does not distinguish terms from their quotations. [...] In the meantime, observe that there is not much scope for confusion, as there is a simple test for being a quotation [...]

> The approach of Rendel, Ostermann, and Hofer can be characterised as follows. A function at one level of the type hierarchy can be tagged to become a data structure at the next level. This requires a countable sequence of levels

> The other notable difference is that both applications of terms to types, and type abstractions, are explicit in their work but implicit here. This saves us from having to factorise type applications, but at the cost of type inference being undecidable.

> They presented a self-recogniser (not strong), and left open the problems of writing an equality checker and a self-enactor.},
	Author = {Jay, Barry and Palsberg, Jens},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-22 16:36:20 +0000},
	Date-Modified = {2014-03-30 11:18:26 +0000},
	Doi = {10.1145/2034773.2034808},
	Isbn = {978-1-4503-0865-6},
	Keywords = {pattern matching, self-interpretation},
	Location = {Tokyo, Japan},
	Numpages = {12},
	Pages = {247--258},
	Publisher = {ACM},
	Series = {ICFP '11},
	Title = {Typed Self-interpretation by Pattern Matching},
	Url = {http://doi.acm.org/10.1145/2034773.2034808},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034808},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034808}}

@article{Nanevski08,
	Abstract = { ABSTRACT We consider the problem of reconciling a dependently typed functional language with imperative features such as mutable higher-order state, pointer aliasing, and nontermination. We propose Hoare type theory (HTT), which incorporates Hoare-style specifications into types, making it possible to statically track and enforce correct use of side effects.The main feature of HTT is the Hoare type {P}x:A{Q} specifying computations with precondition P and postcondition Q that return a result of type A. Hoare types can be nested, combined with other types, and abstracted, leading to a smooth integration with higher-order functions and type polymorphism.We further show that in the presence of type polymorphism, it becomes possible to interpret the Hoare types in the ``small footprint'' manner, as advocated by separation logic, whereby specifications tightly describe the state required by the computation.We establish that HTT is sound and compositional, in the sense that separate verifications of individual program components suffice to ensure the correctness of the composite program. },
	Author = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
	Date-Added = {2014-03-16 23:51:29 +0000},
	Date-Modified = {2014-03-16 23:52:01 +0000},
	Doi = {10.1017/S0956796808006953},
	Issn = {1469-7653},
	Issue = {Special Double Issue 5-6},
	Journal = {Journal of Functional Programming},
	Month = {9},
	Numpages = {47},
	Pages = {865--911},
	Title = {Hoare type theory, polymorphism and separation},
	Url = {http://journals.cambridge.org/article_S0956796808006953},
	Volume = {18},
	Year = {2008},
	Bdsk-Url-1 = {http://journals.cambridge.org/article_S0956796808006953},
	Bdsk-Url-2 = {http://dx.doi.org/10.1017/S0956796808006953}}

@inproceedings{Nanevski:2006:PSH,
	Abstract = {In previous work, we proposed a Hoare Type Theory (HTT) which combines effectful higher-order functions, dependent types and Hoare Logic specifications into a unified framework. However, the framework did not support polymorphism, and ailed to provide a modular treatment of state in specifications. In this paper, we address these shortcomings by showing that the addition of polymorphism alone is sufficient for capturing modular state specifications in the style of Separation Logic. Furthermore, we argue that polymorphism is an essential ingredient of the extension, as the treatment of higher-order functions requires operations not encodable via the spatial connectives of Separation Logic.},
	Acmid = {1159812},
	Address = {New York, NY, USA},
	Author = {Nanevski, Aleksandar and Morrisett, Greg and Birkedal, Lars},
	Booktitle = {Proceedings of the Eleventh ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-03-16 12:51:31 +0000},
	Date-Modified = {2014-03-16 12:51:47 +0000},
	Doi = {10.1145/1159803.1159812},
	Isbn = {1-59593-309-3},
	Keywords = {hoare logic, separation logic, type theory},
	Location = {Portland, Oregon, USA},
	Numpages = {12},
	Pages = {62--73},
	Publisher = {ACM},
	Series = {ICFP '06},
	Title = {Polymorphism and Separation in Hoare Type Theory},
	Url = {http://doi.acm.org/10.1145/1159803.1159812},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1159803.1159812},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1159803.1159812}}

@inproceedings{Ahmed09sri,
	Abstract = {Mitchell's notion of representation independence is a particularly useful application of Reynolds' relational parametricity -- two different implementations of an abstract data type can be shown contextually equivalent so long as there exists a relation between their type representations that is preserved by their operations. There have been a number of methods proposed for proving representation independence in various pure extensions of System F (where data abstraction is achieved through existential typing), as well as in Algol- or Java-like languages (where data abstraction is achieved through the use of local mutable state). However, none of these approaches addresses the interaction of existential type abstraction and local state. In particular, none allows one to prove representation independence results for generative ADTs -- i.e. ADTs that both maintain some local state and define abstract types whose internal representations are dependent on that local state.

In this paper, we present a syntactic, logical-relations-based method for proving representation independence of generative ADTs in a language supporting polymorphic types, existential types, general recursive types, and unrestricted ML-style mutable references. We demonstrate the effectiveness of our method by using it to prove several interesting contextual equivalences that involve a close interaction between existential typing and local state, as well as some well-known equivalences from the literature (such as Pitts and Stark's "awkward" example) that have caused trouble for previous logical-relations-based methods.

The success of our method relies on two key technical innovations. First, in order to handle generative ADTs, we develop a possible-worlds model in which relational interpretations of types are allowed to grow over time in a manner that is tightly coupled with changes to some local state. Second, we employ a step-indexed stratification of possible worlds, which facilitates a simplified account of mutable references of higher type.},
	Acmid = {1480925},
	Address = {New York, NY, USA},
	Author = {Ahmed, Amal and Dreyer, Derek and Rossberg, Andreas},
	Booktitle = {Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
	Date-Added = {2014-03-04 21:38:25 +0000},
	Date-Modified = {2014-03-04 21:38:50 +0000},
	Doi = {10.1145/1480881.1480925},
	Isbn = {978-1-60558-379-2},
	Keywords = {abstract data types, existential types, local state, representation independence, step-indexed logical relations},
	Location = {Savannah, GA, USA},
	Numpages = {14},
	Pages = {340--353},
	Publisher = {ACM},
	Series = {POPL '09},
	Title = {State-dependent Representation Independence},
	Url = {http://doi.acm.org/10.1145/1480881.1480925},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480881.1480925},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480881.1480925}}

@article{Appel01,
	Abstract = {The proofs of "traditional" proof carrying code (PCC) are type-specialized in the sense that they require axioms about a specific type system. In contrast, the proofs of foundational PCC explicitly define all required types and explicitly prove all the required properties of those types assuming only a fixed foundation of mathematics such as higher-order logic. Foundational PCC is both more flexible and more secure than type-specialized PCC.For foundational PCC we need semantic models of type systems on von Neumann machines. Previous models have been either too weak (lacking general recursive types and first-class function-pointers), too complex (requiring machine-checkable proofs of large bodies of computability theory), or not obviously applicable to von Neumann machines. Our new model is strong, simple, and works either in λ-calculus or on Pentiums.},
	Acmid = {504712},
	Address = {New York, NY, USA},
	Annote = {This paper "Proposes the ``step-indexed'' logical-relations model, now an essential tool in scaling parametricity to real languages".
I've read Sec. 1 and 2, with a safety proof for omega and Y, and I've been mind-blown.},
	Author = {Appel, Andrew W. and McAllester, David},
	Date-Added = {2014-03-04 14:00:56 +0000},
	Date-Modified = {2014-03-04 14:02:35 +0000},
	Doi = {10.1145/504709.504712},
	Issn = {0164-0925},
	Issue_Date = {September 2001},
	Journal = {ACM Trans. Program. Lang. Syst.},
	Month = sep,
	Number = {5},
	Numpages = {27},
	Pages = {657--683},
	Publisher = {ACM},
	Rating = {5},
	Title = {An Indexed Model of Recursive Types for Foundational Proof-carrying Code},
	Url = {http://doi.acm.org/10.1145/504709.504712},
	Volume = {23},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/504709.504712},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/504709.504712}}

@inproceedings{Dunfield13,
	Abstract = {Bidirectional typechecking, in which terms either synthesize a type or are checked against a known type, has become popular for its scalability (unlike Damas-Milner type inference, bidirectional typing remains decidable even for very expressive type systems), its error reporting, and its relative ease of implementation. Following design principles from proof theory, bidirectional typing can be applied to many type constructs. The principles underlying a bidirectional approach to polymorphism, however, are less obvious. We give a declarative, bidirectional account of higher-rank polymorphism, grounded in proof theory; this calculus enjoys many properties such as eta-reduction and predictability of annotations. We give an algorithm for implementing the declarative system; our algorithm is remarkably simple and well-behaved, despite being both sound and complete.},
	Acmid = {2500582},
	Address = {New York, NY, USA},
	Annote = {> "Following design principles from proof theory, bidirectional typing can be applied to many type constructs."

Related to our "DSL design" paper?},
	Author = {Dunfield, Joshua and Krishnaswami, Neelakantan R.},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN International Conference on Functional Programming},
	Date-Added = {2014-02-11 14:38:41 +0000},
	Date-Modified = {2014-02-11 16:16:53 +0000},
	Doi = {10.1145/2500365.2500582},
	Isbn = {978-1-4503-2326-0},
	Keywords = {bidirectional typechecking, higher-rank polymorphism},
	Location = {Boston, Massachusetts, USA},
	Numpages = {14},
	Pages = {429--442},
	Publisher = {ACM},
	Rating = {4},
	Series = {ICFP '13},
	Title = {Complete and Easy Bidirectional Typechecking for Higher-rank Polymorphism},
	Url = {http://doi.acm.org/10.1145/2500365.2500582},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500582},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500582}}

@article{Peyton-Jones98,
	Abstract = {Many compilers do some of their work by means of correctness-preserving, and hopefully performance-improving, program transformations. The Glasgow Haskell Compiler (GHC) takes this idea of ``compilation by transformation'' as its war-cry, trying to express as much as possible of the compilation process in the form of program transformations.

This paper reports on our practical experience of the transformational approach to compilation, in the context of a substantial compiler.},
	Acmid = {299621},
	Address = {Amsterdam, The Netherlands, The Netherlands},
	Author = {Peyton Jones, Simon L. and Santos, Andr{\'e} L. M.},
	Date-Added = {2014-02-09 22:08:08 +0000},
	Date-Modified = {2014-02-09 23:35:14 +0000},
	Doi = {10.1016/S0167-6423(97)00029-4},
	Issn = {0167-6423},
	Issue_Date = {Sept. 1998},
	Journal = {Sci. Comput. Program.},
	Keywords = {compilers, functional languages, let-floating, linear type system, optimisation, second-order lambda calculus, strictness analysis, transformation},
	Month = sep,
	Number = {1-3},
	Numpages = {45},
	Pages = {3--47},
	Publisher = {Elsevier North-Holland, Inc.},
	Rating = {5},
	Title = {A Transformation-based Optimiser for Haskell},
	Url = {http://dx.doi.org/10.1016/S0167-6423(97)00029-4},
	Volume = {32},
	Year = {1998},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S0167-6423(97)00029-4}}

@incollection{Odersky03,
	Abstract = {We design and study vObj, a calculus and dependent type system for objects and classes which can have types as members. Type members can be aliases, abstract types, or new types. The type system can model the essential concepts of JAVA's inner classes as well as virtual types and family polymorphism found in BETA or GBETA. It can also model most concepts of SML-style module systems, including sharing constraints and higher-order functors, but excluding applicative functors. The type system can thus be used as a basis for unifying concepts that so far existed in parallel in advanced object systems and in module systems. The paper presents results on confluence of the calculus, soundness of the type system, and undecidability of type checking.},
	Author = {Odersky, Martin and Cremet, Vincent and R{\"o}ckl, Christine and Zenger, Matthias},
	Booktitle = {ECOOP 2003 -- Object-Oriented Programming},
	Date-Added = {2013-12-10 15:38:29 +0000},
	Date-Modified = {2013-12-10 15:38:40 +0000},
	Doi = {10.1007/978-3-540-45070-2_10},
	Editor = {Cardelli, Luca},
	Isbn = {978-3-540-40531-3},
	Pages = {201-224},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A Nominal Theory of Objects with Dependent Types},
	Url = {http://dx.doi.org/10.1007/978-3-540-45070-2_10},
	Volume = {2743},
	Year = {2003},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-45070-2_10}}

@article{Rompf13a,
	Author = {Rompf, Tiark and Amin, Nada and Moors, Adriaan and Haller, Philipp and Odersky, Martin},
	Date-Added = {2013-12-10 15:16:28 +0000},
	Date-Modified = {2013-12-10 15:16:31 +0000},
	Doi = {10.1007/s10990-013-9096-9},
	Issn = {1388-3690},
	Journal = {Higher-Order and Symbolic Computation},
	Keywords = {Code generation; Domain-specific languages; Linguistic reuse; Language virtualization},
	Language = {English},
	Pages = {1-43},
	Publisher = {Springer US},
	Title = {Scala-Virtualized: linguistic reuse for deep embeddings},
	Url = {http://dx.doi.org/10.1007/s10990-013-9096-9},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-013-9096-9}}

@inproceedings{Breazu-Tannen91logical,
	Abstract = {We study issues that arise in programming with primitive recursion over non-free datatypes such as lists, bags and sets. Programs written in this style can lack a meaning in the sense that their outputs may be sensitive to the choice of input expression. We are, thus, naturally lead to a set-theoretic denotational semantics with partial functions. We set up a logic for reasoning about the definedness of terms and a deterministic and terminating evaluator. The logic is shown to be sound in the model, and its recursion free fragment is shown to be complete for proving definedness of recursion free programs. The logic is then shown to be as strong as the evaluator, and this implies that the evaluator is compatible with the provable equivalence between different set (or bag, or list) expression . Oftentimes,the same non-free datatype may have different presentations, and it is not clear a priori whether programming and reasoning with the two presentations are equivalent. We formulate these questions, precisely, in the context of alternative presentations of the list, bag, and set datatypes and study some aspects of these questions. In particular, we establish back-and-forth translations between the two presentations, from which it follows that they are equally expressive, and prove results relating proofs of program properties, in the two presentations.},
	Acmid = {758814},
	Address = {London, UK, UK},
	Annote = {This paper discusses denotational, operational and equational semantics for sets, bags and lists, both in cons-nil representation [let's call it insert representation, following Grust] and in empty-singleton-union representation [let's call it union representation, again following Grust]. Among other results, they show that these representations are interconvertible.
Given an algebra (i.e. fold) in union representation, one can build one in insert representation easily:
cons head tail = union (singleton head) tail
nil = empty
Given an algebra (i.e. fold) in insert representation, one can build one in union representation using the functional representation of difference lists, that is, by encoding lists as their prepend function of type [t] -> [t]
empty = id
singleton el = (tail -> cons el tail) = cons el
union x y = (tail -> (x . y) tail) = x . y.

nil is only used to reify difference lists to standard ones.

Meta-notes:
Grust cites this paper in his PhD thesis to show that it is hard to convert from insert queries (that is, folds) into union queries. The reason is that the translation they present is higher-order.},
	Author = {Breazu-Tannen, Val and Subrahmanyam, Ramesh},
	Booktitle = {Proceedings of the 18th International Colloquium on Automata, Languages and Programming},
	Date-Added = {2013-11-23 02:32:24 +0000},
	Date-Modified = {2013-11-23 02:43:46 +0000},
	Isbn = {3-540-54233-7},
	Numpages = {16},
	Pages = {60--75},
	Publisher = {Springer-Verlag},
	Series = {ICALP '91},
	Title = {Logical and Computational Aspects of Programming with Sets/Bags/Lists},
	Url = {http://link.springer.com/chapter/10.1007/3-540-54233-7_125},
	Year = {1991},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=646245.758814},
	Bdsk-Url-2 = {http://dl.acm.org/citation.cfm?id=111713.111718},
	Bdsk-Url-3 = {http://link.springer.com/chapter/10.1007/3-540-54233-7_125}}

@article{Harper93,
	Abstract = {The Edinburgh Logical Framework (LF) provides a means to define (or present) logics. It is based on a general treatment of syntax, rules, and proofs by means of a typed &lgr;-calculus with dependent types. Syntax is treated in a style similar to, but more general than, Martin-L{\"o}f's system of arities. The treatment of rules and proofs focuses on his notion of a judgment. Logics are represented in LF via a new principle, the judgments as types principle, whereby each judgment is identified with the type of its proofs. This allows for a smooth treatment of discharge and variable occurence conditions and leads to a uniform treatment of rules and proofs whereby rules are viewed as proofs of higher-order judgments and proof checking is reduced to type checking. The practical benefit of our treatment of formal systems is that logic-independent tools, such as proof editors and proof checkers, can be constructed.},
	Acmid = {138060},
	Address = {New York, NY, USA},
	Annote = {This paper describes the Edinburgh Logical Framework, LF for short, which is the first part of the foundation of Twelf; this paper includes no logic programming elements.

LF includes a minimal dependent lambda-calculus, where types and values can abstract on values. Nothing can abstract on types; but everything of interest can be represented as values, including types of the embedded logic. By accepting these restrictions, various problems 

When needed, such one can abstract over such values to construct types, exactly like in a universe construction --- for instance obj : holtype -> Type in the encoding of higher-order logic. However, universe constructions need be used even in some cases which would usually be handled via polymorphism (again for higher-order logic, see HOAS abstraction and application for the embedded logic).

Moreover, it includes an approach for embedding logics which includes:

- Sorts of the metatheory of the logic (term, formula, individual, etc.) are represented as types in LF.
- Judgements of the represented theory are represented as types, while proofs are terms inhabiting those types, and proof rules are constructors of those terms. Proof checking reduces to type-checking.
- Martin-L{\"o}f's hypothetical and schematic/general judgements are encoded as types of functions producing judgements and taking, respectively, judgements or individuals.
- Binding is handled through higher-order abstract syntax (not cited by name in the paper, but used in all examples and emphasized as important). This way, the handling of binding is rather easy (as usual with HOAS).
- Derived rules can be proven easily, while proving admissibility is much harder.
- A definition of adequacy for encodings as a biijection which is compositional, that is commutes with substitution.

Many of these ideas are reflected in formalizations present in Harper's "Practical Foundations of Programming Languages".

According to the authors, the encoding is similar to AUTOMATH but separates better object and meta-level.

The writing style is precise but overall rather academic.},
	Author = {Harper, Robert and Honsell, Furio and Plotkin, Gordon},
	Date-Added = {2013-11-19 18:59:05 +0000},
	Date-Modified = {2013-11-19 19:17:39 +0000},
	Doi = {10.1145/138027.138060},
	Issn = {0004-5411},
	Issue_Date = {Jan. 1993},
	Journal = {J. ACM},
	Keywords = {formal systems, interactive theorem proving, proof checking, typed lambda calculus},
	Month = jan,
	Number = {1},
	Numpages = {42},
	Pages = {143--184},
	Publisher = {ACM},
	Rating = {4},
	Read = {1},
	Title = {A Framework for Defining Logics},
	Url = {http://doi.acm.org/10.1145/138027.138060},
	Volume = {40},
	Year = {1993},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/138027.138060},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/138027.138060}}

@inproceedings{Nerella13,
	Abstract = {Object oriented programming languages raised the level of abstraction by supporting the explicit first class query constructs in the programming codes. The query constructs can be optimized by leveraging the techniques of query optimization from the domain of databases. The existing optimization approaches such as JQL, however, incur high run time overhead as optimizations are performed only at run time. Therefore, in this paper, we propose an approach that performs the query optimization at compile time utilizing the metadata annotations in the source code. The proposed approach first collects the data from the sample execution of the program and extracts the essential metadata for the string valued attributes. Then, the annotations consisting of the metadata values associated with string attributes are generated in the source code and the histograms are built using those annotations. The selectivity estimates of the predicates and the joins in the query are computed from the histograms. Next, the query plan is generated at compile time through the maximum selectivity heuristic. The query plan is modified at run time in cases of significant updates to the string data. The approach also incorporates the cache heuristics that determine whether to cache the query result or not. The cached query results are incrementally maintained up-to-date. Our experimental results demonstrate that our approach has reduced the run time of the program more than the earlier approaches such as JQL.},
	Author = {Nerella, Venkata Krishna Suhas and Madria, Sanjay K. and Weigert, Thomas},
	Booktitle = {Computer Software and Applications Conference (COMPSAC), 2013 IEEE 37th Annual},
	Date-Added = {2013-11-19 14:53:53 +0000},
	Date-Modified = {2013-11-19 14:53:55 +0000},
	Doi = {10.1109/COMPSAC.2013.56},
	Keywords = {Benchmark testing;Histograms;Java;Maintenance engineering;Optimization;Query processing;Time-frequency analysis;Annotations;Compile time;Query Plan;Selectivity;string data},
	Pages = {313-318},
	Title = {Optimization of Object Queries on Collections Using Annotations for the String Valued Attributes},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/COMPSAC.2013.56}}

@inproceedings{Aspinall96,
	Abstract = {The need for subtyping in type-systems with dependent types has been realized for some years. But it is hard to prove that systems combining the two features have fundamental properties such as subject reduction. Here we investigate a subtyping extension of the system λP, which is an abstract version of the type system of the Edinburgh Logical Framework LF. By using an equivalent formulation, we establish some important properties of the new system λP⩽, including subject reduction. Our analysis culminates in a complete and terminating algorithm which establishes the decidability of type-checking},
	Author = {Aspinall, D. and Compagnoni, A.},
	Booktitle = {Logic in Computer Science, 1996. LICS '96. Proceedings., Eleventh Annual IEEE Symposium on},
	Date-Added = {2013-11-19 14:52:44 +0000},
	Date-Modified = {2013-11-19 14:52:47 +0000},
	Doi = {10.1109/LICS.1996.561307},
	Issn = {1043-6871},
	Keywords = {decidability;programming theory;type theory;Edinburgh Logical Framework;decidability;dependent types;subject reduction;subtyping;terminating algorithm;type-checking;type-systems;Algorithm design and analysis;Application software;Computer languages;Computer science;Encoding;Laboratories;Logic programming},
	Pages = {86-97},
	Title = {Subtyping dependent types},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LICS.1996.561307}}

@inproceedings{Parr11,
	Abstract = {Despite the power of Parser Expression Grammars (PEGs) and GLR, parsing is not a solved problem. Adding nondeterminism (parser speculation) to traditional LL and LR parsers can lead to unexpected parse-time behavior and introduces practical issues with error handling, single-step debugging, and side-effecting embedded grammar actions. This paper introduces the LL(*) parsing strategy and an associated grammar analysis algorithm that constructs LL(*) parsing decisions from ANTLR grammars. At parse-time, decisions gracefully throttle up from conventional fixed k>=1 lookahead to arbitrary lookahead and, finally, fail over to backtracking depending on the complexity of the parsing decision and the input symbols. LL(*) parsing strength reaches into the context-sensitive languages, in some cases beyond what GLR and PEGs can express. By statically removing as much speculation as possible, LL(*) provides the expressivity of PEGs while retaining LL's good error handling and unrestricted grammar actions. Widespread use of ANTLR (over 70,000 downloads/year) shows that it is effective for a wide variety of applications.},
	Acmid = {1993548},
	Address = {New York, NY, USA},
	Author = {Parr, Terence and Fisher, Kathleen},
	Booktitle = {Proceedings of the 32Nd ACM SIGPLAN Conference on Programming Language Design and Implementation},
	Date-Added = {2013-11-19 11:40:05 +0000},
	Date-Modified = {2013-11-19 11:40:21 +0000},
	Doi = {10.1145/1993498.1993548},
	Isbn = {978-1-4503-0663-8},
	Keywords = {augmented transition networks, backtracking, context-sensitive parsing, deterministic finite automata, glr, memoization, nondeterministic parsing, peg, semantic predicates, subset construction, syntactic predicates},
	Location = {San Jose, California, USA},
	Numpages = {12},
	Pages = {425--436},
	Publisher = {ACM},
	Series = {PLDI '11},
	Title = {LL(*): The Foundation of the ANTLR Parser Generator},
	Url = {http://doi.acm.org/10.1145/1993498.1993548},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1993498.1993548},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1993498.1993548}}

@inproceedings{Eisenberg12,
	Acmid = {2364522},
	Address = {New York, NY, USA},
	Author = {Eisenberg, Richard A. and Weirich, Stephanie},
	Booktitle = {Proceedings of the 2012 symposium on Haskell symposium},
	Date-Added = {2013-11-04 18:05:36 +0000},
	Date-Modified = {2013-11-04 18:05:37 +0000},
	Doi = {10.1145/2364506.2364522},
	Isbn = {978-1-4503-1574-6},
	Keywords = {dependently typed programming, gadts, haskell, singletons},
	Location = {Copenhagen, Denmark},
	Numpages = {14},
	Pages = {117--130},
	Publisher = {ACM},
	Series = {Haskell '12},
	Title = {Dependently typed programming with singletons},
	Url = {http://doi.acm.org/10.1145/2364506.2364522},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2364506.2364522},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2364506.2364522}}

@inproceedings{Sujeeth13Forge,
	Abstract = {Domain-specific languages provide a promising path to automatically compile high-level code to parallel, heterogeneous, and distributed hardware. However, in practice high performance DSLs still require considerable software expertise to develop and force users into tool-chains that hinder prototyping and debugging. To address these problems, we present Forge, a new meta DSL for declaratively specifying high performance embedded DSLs. Forge provides DSL authors with high-level abstractions (e.g., data structures, parallel patterns, effects) for specifying their DSL in a way that permits high performance. From this high-level specification, Forge automatically generates both a na{\"\i}ve Scala library implementation of the DSL and a high performance version using the Delite DSL framework. Users of a Forge-generated DSL can prototype their application using the library version, and then switch to the Delite version to run on multicore CPUs, GPUs, and clusters without changing the application code. Forge-generated Delite DSLs perform within 2x of hand-optimized C++ and up to 40x better than Spark, an alternative high-level distributed programming environment. Compared to a manually implemented Delite DSL, Forge provides a factor of 3-6x reduction in lines of code and does not sacrifice any performance. Furthermore, Forge specifications can be generated from existing Scala libraries, are easy to maintain, shield DSL developers from changes in the Delite framework, and enable DSLs to be retargeted to other frameworks transparently.},
	Acmid = {2517220},
	Address = {New York, NY, USA},
	Author = {Sujeeth, Arvind K. and Gibbons, Austin and Brown, Kevin J. and Lee, HyoukJoong and Rompf, Tiark and Odersky, Martin and Olukotun, Kunle},
	Booktitle = {Proceedings of the 12th international conference on Generative programming: concepts \&\#38; experiences},
	Date-Added = {2013-10-29 02:44:59 +0000},
	Date-Modified = {2013-10-29 02:45:12 +0000},
	Doi = {10.1145/2517208.2517220},
	Isbn = {978-1-4503-2373-4},
	Keywords = {code generation, domain-specific languages, multi-stage programming, parallel programming},
	Location = {Indianapolis, Indiana, USA},
	Numpages = {10},
	Pages = {145--154},
	Publisher = {ACM},
	Series = {GPCE '13},
	Title = {Forge: generating a high performance DSL implementation from a declarative specification},
	Url = {http://doi.acm.org/10.1145/2517208.2517220},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2517208.2517220},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2517208.2517220}}

@inproceedings{Abel13,
	Abstract = {Inductive datatypes provide mechanisms to define finite data such as finite lists and trees via constructors and allow programmers to analyze and manipulate finite data via pattern matching. In this paper, we develop a dual approach for working with infinite data structures such as streams. Infinite data inhabits coinductive datatypes which denote greatest fixpoints. Unlike finite data which is defined by constructors we define infinite data by observations. Dual to pattern matching, a tool for analyzing finite data, we develop the concept of copattern matching, which allows us to synthesize infinite data. This leads to a symmetric language design where pattern matching on finite and infinite data can be mixed.

We present a core language for programming with infinite structures by observations together with its operational semantics based on (co)pattern matching and describe coverage of copatterns. Our language naturally supports both call-by-name and call-by-value interpretations and can be seamlessly integrated into existing languages like Haskell and ML. We prove type soundness for our language and sketch how copatterns open new directions for solving problems in the interaction of coinductive and dependent types.},
	Acmid = {2429075},
	Address = {New York, NY, USA},
	Author = {Abel, Andreas and Pientka, Brigitte and Thibodeau, David and Setzer, Anton},
	Booktitle = {Proceedings of the 40th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-10-24 03:00:20 +0000},
	Date-Modified = {2013-10-24 03:01:07 +0000},
	Doi = {10.1145/2429069.2429075},
	Isbn = {978-1-4503-1832-7},
	Keywords = {coinduction, functional programming, introduction vs. elimination, message passing, pattern matching},
	Location = {Rome, Italy},
	Numpages = {12},
	Pages = {27--38},
	Publisher = {ACM},
	Series = {POPL '13},
	Title = {Copatterns: programming infinite structures by observations},
	Url = {http://doi.acm.org/10.1145/2429069.2429075},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2429069.2429075},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2429069.2429075}}

@inproceedings{Abel13a,
	Abstract = {In this paper, we study strong normalization of a core language based on System F-omega which supports programming with finite and infinite structures. Building on our prior work, finite data such as finite lists and trees are defined via constructors and manipulated via pattern matching, while infinite data such as streams and infinite trees is defined by observations and synthesized via copattern matching. In this work, we take a type-based approach to strong normalization by tracking size information about finite and infinite data in the type. This guarantees compositionality. More importantly, the duality of pattern and copatterns provide a unifying semantic concept which allows us for the first time to elegantly and uniformly support both well-founded induction and coinduction by mere rewriting. The strong normalization proof is structured around Girard's reducibility candidates. As such our system allows for non-determinism and does not rely on coverage. Since System F-omega is general enough that it can be the target of compilation for the Calculus of Constructions, this work is a significant step towards representing observation-centric infinite data in proof assistants such as Coq and Agda.},
	Acmid = {2500591},
	Address = {New York, NY, USA},
	Author = {Abel, Andreas M. and Pientka, Brigitte},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-10-24 02:59:43 +0000},
	Date-Modified = {2013-10-24 03:01:18 +0000},
	Doi = {10.1145/2500365.2500591},
	Isbn = {978-1-4503-2326-0},
	Keywords = {coinduction, pattern matching, productivity, recursion, strong normalization, type-based termination},
	Location = {Boston, Massachusetts, USA},
	Numpages = {12},
	Pages = {185--196},
	Publisher = {ACM},
	Series = {ICFP '13},
	Title = {Wellfounded recursion with copatterns: a unified approach to termination and productivity},
	Url = {http://doi.acm.org/10.1145/2500365.2500591},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500591},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500591}}

@article{Plotkin77,
	Abstract = {The paper studies connections between denotational and operational semantics for a simple programming language based on LCF. It begins with the connection between the behaviour of a program and its denotation. It turns out that a program denotes ⊥ in any of several possible semantics if it does not terminate. From this it follows that if two terms have the same denotation in one of these semantics, they have the same behaviour in all contexts. The converse fails for all the semantics. If, however, the language is extended to allow certain parallel facilities behavioural equivalence does coincide with denotational equivalence in one of the semantics considered, which may therefore be called ``fully abstract''. Next a connection is given which actually determines the semantics up to isomorphism from the behaviour alone. Conversely, by allowing further parallel facilities, every r.e. element of the fully abstract semantics becomes definable, thus characterising the programming language, up to interdefinability, from the set of r.e. elements of the domains of the semantics.},
	Author = {G.D. Plotkin},
	Date-Added = {2013-10-13 03:09:08 +0000},
	Date-Modified = {2013-10-13 03:09:11 +0000},
	Journal = {Theoretical Computer Science},
	Nodoi = {10.1016/0304-3975(77)90044-5},
	Noissn = {0304-3975},
	Nourl = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	Number = 3,
	Pages = {223 - 255},
	Prg = {2013-06-10, Cai},
	Title = {{LCF} considered as a programming language},
	Volume = 5,
	Year = 1977,
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0304397577900445},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0304-3975(77)90044-5}}

@article{Appel97,
	Abstract = {Functional-language compilers often perform optimizations based on beta and delta reduction. To avoid speculative optimizations that can blow up the code size, we might wish to use only shrinking reduction rules guaranteed to make the program smaller: these include dead-variable elimination, constant folding, and a restricted beta rule that inlines only functions that are called just once. The restricted beta rule leads to a shrinking rewrite system that has not previously been studied. We show some efficient normalization algorithms that are immediately useful in optimizing compilers; and we give a confluence proof for our system, showing that the choice of normalization algorithm does not affect final code quality.},
	Author = {Appel, Andrew W. and Jim, Trevor},
	Date-Added = {2013-10-10 15:51:15 +0000},
	Date-Modified = {2013-10-10 15:51:16 +0000},
	Issue = {05},
	Journal = JFP,
	Noissn = {1469-7653},
	Nomonth = sep,
	Nourl = {http://journals.cambridge.org/article_S0956796897002839},
	Numpages = {26},
	Pages = {515--540},
	Title = {Shrinking lambda expressions in linear time},
	Volume = {7},
	Year = {1997}}

@inproceedings{Bhatotia11,
	Abstract = {Many online data sets evolve over time as new entries are slowly added and existing entries are deleted or modified. Taking advantage of this, systems for incremental bulk data processing, such as Google's Percolator, can achieve efficient updates. To achieve this efficiency, however, these systems lose compatibility with the simple programming models offered by non-incremental systems, e.g., MapReduce, and more importantly, requires the programmer to implement application-specific dynamic algorithms, ultimately increasing algorithm and code complexity.

In this paper, we describe the architecture, implementation, and evaluation of Incoop, a generic MapReduce framework for incremental computations. Incoop detects changes to the input and automatically updates the output by employing an efficient, fine-grained result reuse mechanism. To achieve efficiency without sacrificing transparency, we adopt recent advances in the area of programming languages to identify the shortcomings of task-level memoization approaches, and to address these shortcomings by using several novel techniques: a storage system, a contraction phase for Reduce tasks, and an affinity-based scheduling algorithm. We have implemented Incoop by extending the Hadoop framework, and evaluated it by considering several applications and case studies. Our results show significant performance improvements without changing a single line of application code.},
	Acmid = {2038923},
	Address = {New York, NY, USA},
	Articleno = {7},
	Author = {Bhatotia, Pramod and Wieder, Alexander and Rodrigues, Rodrigo and Acar, Umut A. and Pasquin, Rafael},
	Booktitle = {Proceedings of the 2nd ACM Symposium on Cloud Computing},
	Date-Added = {2013-10-09 04:16:34 +0000},
	Date-Modified = {2013-10-09 04:16:58 +0000},
	Doi = {10.1145/2038916.2038923},
	Isbn = {978-1-4503-0976-9},
	Keywords = {memoization, self-adjusting computation, stability},
	Location = {Cascais, Portugal},
	Numpages = {14},
	Pages = {7:1--7:14},
	Publisher = {ACM},
	Series = {SOCC '11},
	Title = {Incoop: MapReduce for incremental computations},
	Url = {http://doi.acm.org/10.1145/2038916.2038923},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2038916.2038923},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2038916.2038923}}

@phdthesis{Acar05,
	Author = {Acar, Umut A},
	Date-Added = {2013-10-08 23:54:44 +0000},
	Date-Modified = {2013-10-08 23:54:50 +0000},
	School = {Princeton University},
	Title = {Self-Adjusting Computation},
	Year = {2005}}

@inproceedings{Axelsson13,
	Acmid = {2500614},
	Address = {New York, NY, USA},
	Author = {Axelsson, Emil and Claessen, Koen},
	Booktitle = {Proceedings of the 18th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-10-02 11:47:06 +0000},
	Date-Modified = {2013-10-02 11:47:07 +0000},
	Doi = {10.1145/2500365.2500614},
	Isbn = {978-1-4503-2326-0},
	Keywords = {circular programming, embedded languages, higher-order syntax},
	Location = {Boston, Massachusetts, USA},
	Numpages = {6},
	Pages = {257--262},
	Publisher = {ACM},
	Series = {ICFP '13},
	Title = {Using circular programs for higher-order syntax: functional pearl},
	Url = {http://doi.acm.org/10.1145/2500365.2500614},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2500365.2500614},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2500365.2500614}}

@inproceedings{Brown11,
	Abstract = {Computing systems are becoming increasingly parallel and heterogeneous, and therefore new applications must be capable of exploiting parallelism in order to continue achieving high performance. However, targeting these emerging devices often requires using multiple disparate programming models and making decisions that can limit forward scalability. In previous work we proposed the use of domain-specific languages (DSLs) to provide high-level abstractions that enable transformations to high performance parallel code without degrading programmer productivity. In this paper we present a new end-to-end system for building, compiling, and executing DSL applications on parallel heterogeneous hardware, the Delite Compiler Framework and Runtime. The framework lifts embedded DSL applications to an intermediate representation (IR), performs generic, parallel, and domain-specific optimizations, and generates an execution graph that targets multiple heterogeneous hardware devices. Finally we present results comparing the performance of several machine learning applications written in OptiML, a DSL for machine learning that utilizes Delite, to C++ and MATLAB implementations. We find that the implicitly parallel OptiML applications achieve single-threaded performance comparable to C++ and outperform explicitly parallel MATLAB in nearly all cases.},
	Author = {Brown, K.J. and Sujeeth, A.K. and Hyouk Joong Lee and Rompf, T. and Chafi, H. and Odersky, M. and Olukotun, K.},
	Booktitle = {Parallel Architectures and Compilation Techniques (PACT), 2011 International Conference on},
	Date-Added = {2013-08-03 15:57:23 +0000},
	Date-Modified = {2013-08-03 15:57:24 +0000},
	Doi = {10.1109/PACT.2011.15},
	Issn = {1089-795X},
	Keywords = {C++ language;learning (artificial intelligence);parallel processing;program compilers;C++ language;Delite compiler framework;Matlab;OptiML;domain-specific language;execution graph;heterogeneous parallel framework;high performance parallel code;high-level abstraction;machine learning application;parallelism;programmer productivity;runtime application;single-threaded performance;DSL;Hardware;Optimization;Parallel processing;Performance evaluation;Programming;Runtime;computer languages;multicore processing;parallel programming},
	Pages = {89-100},
	Title = {A Heterogeneous Parallel Framework for Domain-Specific Languages},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/PACT.2011.15}}

@inproceedings{Odersky05,
	Acmid = {1094815},
	Address = {New York, NY, USA},
	Author = {Odersky, Martin and Zenger, Matthias},
	Booktitle = oopsla,
	Date-Added = {2013-08-03 15:46:57 +0000},
	Date-Modified = {2013-08-03 15:47:12 +0000},
	Doi = {10.1145/1094811.1094815},
	Isbn = {1-59593-031-0},
	Keywords = {Scala, abstract types, classes, components, mixins},
	Location = {San Diego, CA, USA},
	Numpages = {17},
	Pages = {41--57},
	Publisher = {ACM},
	Series = {OOPSLA '05},
	Title = {Scalable component abstractions},
	Url = {http://doi.acm.org/10.1145/1094811.1094815},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094811.1094815},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094811.1094815}}

@article{Guttag78,
	Abstract = {There have been many recent proposals for embedding abstract data types in programming languages. In order to reason about programs using abstract data types, it is desirable to specify their properties at an abstract level, independent of any particular implementation. This paper presents an algebraic technique for such specifications, develops some of the formal properties of the technique, and shows that these provide useful guidelines for the construction of adequate specifications.},
	Author = {Guttag, J.V. and Horning, J.J.},
	Date-Added = {2013-07-13 12:46:23 +0000},
	Date-Modified = {2013-07-13 12:46:23 +0000},
	Doi = {10.1007/BF00260922},
	Issn = {0001-5903},
	Journal = {Acta Informatica},
	Language = {English},
	Number = {1},
	Pages = {27-52},
	Publisher = {Springer-Verlag},
	Title = {The algebraic specification of abstract data types},
	Url = {http://dx.doi.org/10.1007/BF00260922},
	Volume = {10},
	Year = {1978},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BF00260922}}

@article{LiuSkalka11staged,
	Annote = {Staging is a powerful language construct that allows a program at one stage of evaluation to manipulate and specialize a program to be executed at a later stage. We propose a new staged language calculus, 〈ML〉, which extends the programmability of staged languages in two directions. First, 〈ML〉 supports dynamic type specialization: types can be dynamically constructed, abstracted, and passed as arguments, while preserving decidable typechecking via a System F≤-style semantics combined with a restricted form of λ ω -style runtime type construction. With dynamic type specialization the data structure layout of a program can be optimized via staging. Second, 〈ML〉 works in a context where different stages of computation are executed in different process spaces, a property we term staged process separation. Programs at different stages can directly communicate program data in 〈ML〉 via a built-in serialization discipline. The language 〈ML〉 is endowed with a metatheory including type preservation, type safety, and decidability as demonstrated constructively by a sound type checking algorithm. While our language design is general, we are particularly interested in future applications of staging in resource-constrained and embedded systems: these systems have limited space for code and data, as well as limited CPU time, and specializing code for the particular deployment at hand can improve efficiency in all of these dimensions. The combination of dynamic type specialization and staging across processes greatly increases the utility of staged programming in these domains. We illustrate this via wireless sensor network programming examples.},
	Author = {Liu, Yu David and Skalka, Christian and Smith, Scott F.},
	Date-Added = {2013-06-30 06:59:47 +0000},
	Date-Modified = {2013-06-30 07:00:45 +0000},
	Doi = {10.1007/s10990-012-9089-0},
	Issn = {1388-3690},
	Journal = hosc,
	Keywords = {Programming languages; Access control; Wireless sensor networks; Type safety; Program specialization},
	Language = {English},
	Number = {4},
	Pages = {341-385},
	Publisher = {Springer US},
	Title = {Type-specialized staged programming with process separation},
	Url = {http://dx.doi.org/10.1007/s10990-012-9089-0},
	Volume = {24},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s10990-012-9089-0}}

@inproceedings{Salvaneschi13reactive,
	Abstract = {Reactive applications are difficult to implement. Traditional solutions based on event systems and the Observer pattern have a number of inconveniences, but programmers bear them in return for the benefits of OO design. On the other hand, reactive approaches based on automatic updates of dependencies - like functional reactive programming and dataflow languages - provide undoubted advantages but do not fit well with mutable objects. In this paper, we provide a research roadmap to overcome the limitations of the current approaches and to support reactive applications in the OO setting. To establish a solid background for our investigation, we propose a conceptual framework to model the design space of reactive applications and we study the flaws of the existing solutions. Then we highlight how reactive languages have the potential to address those issues and we formulate our research plan.},
	Acmid = {2451442},
	Address = acmaddr,
	Author = {Salvaneschi, Guido and Mezini, Mira},
	Booktitle = aosd,
	Date-Added = {2013-06-27 08:23:04 +0000},
	Date-Modified = {2013-06-27 19:17:18 +0000},
	Keywords = {functional-reactive programming, incremental computation, object-oriented programming, reactive programming},
	Location = {Fukuoka, Japan},
	Nodoi = {10.1145/2451436.2451442},
	Noisbn = {978-1-4503-1766-5},
	Noseries = {AOSD '13},
	Nourl = {http://doi.acm.org/10.1145/2451436.2451442},
	Numpages = {12},
	Pages = {37--48},
	Publisher = acm,
	Title = {Reactive behavior in object-oriented applications: an analysis and a research roadmap},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2451436.2451442},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2451436.2451442}}

@inproceedings{Scherer13GADTSub,
	Abstract = {While generalized algebraic datatypes (GADTs) are now considered well-understood, adding them to a language with a notion of subtyping comes with a few surprises. What does it mean for a GADT parameter to be covariant? The answer turns out to be quite subtle. It involves fine-grained properties of the subtyping relation that raise interesting design questions. We allow variance annotations in GADT definitions, study their soundness, and present a sound and complete algorithm to check them. Our work may be applied to real-world ML-like languages with explicit subtyping such as OCaml, or to languages with general subtyping constraints.},
	Acmid = {2450309},
	Author = {Scherer, Gabriel and R{\'e}my, Didier},
	Booktitle = {ESOP},
	Date-Added = {2013-06-26 19:10:57 +0000},
	Date-Modified = {2013-06-26 19:11:46 +0000},
	Location = {Rome, Italy},
	Noaddress = {Berlin, Heidelberg},
	Nobooktitle = {Proceedings of the 22nd European conference on Programming Languages and Systems},
	Nodoi = {10.1007/978-3-642-37036-6_30},
	Noisbn = {978-3-642-37035-9},
	Noseries = {ESOP'13},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-37036-6_30},
	Numpages = {20},
	Pages = {554--573},
	Publisher = {Springer-Verlag},
	Title = {{GADTs} meet subtyping},
	Year = {2013},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-37036-6_30}}

@inproceedings{Reichenbach12PQL,
	Acmid = {2367169},
	Address = {Berlin, Heidelberg},
	Author = {Reichenbach, Christoph and Smaragdakis, Yannis and Immerman, Neil},
	Booktitle = ecoop,
	Date-Added = {2013-06-25 16:00:48 +0000},
	Date-Modified = {2013-06-25 16:01:10 +0000},
	Doi = {10.1007/978-3-642-31057-7_4},
	Isbn = {978-3-642-31056-0},
	Location = {Beijing, China},
	Numpages = {26},
	Pages = {53--78},
	Publisher = {Springer-Verlag},
	Series = {ECOOP'12},
	Title = {PQL: a purely-declarative {Java} extension for parallel programming},
	Url = {http://dx.doi.org/10.1007/978-3-642-31057-7_4},
	Year = {2012},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-642-31057-7_4}}

@inproceedings{Altenkirch07OE,
	Acmid = {1292608},
	Author = {Altenkirch, Thorsten and McBride, Conor and Swierstra, Wouter},
	Booktitle = plpv,
	Date-Added = {2013-06-25 00:02:01 +0000},
	Date-Modified = {2013-06-25 00:02:20 +0000},
	Keywords = {equality, type theory},
	Location = {Freiburg, Germany},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1292597.1292608},
	Noisbn = {978-1-59593-677-6},
	Noseries = {PLPV '07},
	Nourl = {http://doi.acm.org/10.1145/1292597.1292608},
	Numpages = {12},
	Pages = {57--68},
	Publisher = {ACM},
	Title = {Observational equality, now!},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1292597.1292608},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1292597.1292608}}

@book{Mitchell1996foundations,
	Author = {Mitchell, John C.},
	Date-Added = {2013-06-20 23:23:51 +0000},
	Date-Modified = {2013-06-20 23:23:51 +0000},
	Publisher = {MIT Press},
	Title = {Foundations of programming languages},
	Year = {1996}}

@inproceedings{Jategaonkar88,
	Acmid = {62702},
	Address = {New York, NY, USA},
	Author = {Jategaonkar, Lalita and Mitchell, John},
	Booktitle = {Proceedings of the 1988 ACM conference on LISP and functional programming},
	Date-Added = {2013-06-20 16:24:48 +0000},
	Date-Modified = {2013-06-20 16:24:48 +0000},
	Doi = {10.1145/62678.62702},
	Isbn = {0-89791-273-X},
	Location = {Snowbird, Utah, USA},
	Numpages = {14},
	Pages = {198--211},
	Publisher = {ACM},
	Series = {LFP '88},
	Title = {ML with extended pattern matching and subtypes},
	Url = {http://doi.acm.org/10.1145/62678.62702},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62702},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62702}}

@article{Paige82FDC,
	Acmid = {357177},
	Address = acmaddr,
	Author = {Paige, Robert and Koenig, Shaye},
	Date-Added = {2013-06-20 16:24:35 +0000},
	Date-Modified = {2013-06-20 16:24:35 +0000},
	Issue_Date = {July 1982},
	Journal = toplas,
	Keywords = {incremental computation},
	Month = jul,
	Nodoi = {10.1145/357172.357177},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/357172.357177},
	Number = {3},
	Numpages = {53},
	Pages = {402--454},
	Publisher = {ACM},
	Title = {Finite Differencing of Computable Expressions},
	Volume = {4},
	Year = {1982},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/357172.357177},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/357172.357177}}

@article{Blass92,
	Abstract = {We present a game (or dialogue) semantics in the style of Lorenzen (1959) for Girard's linear logic (1987). Lorenzen suggested that the (constructive) meaning of a proposition ϕ should be specified by telling how to conduct a debate between a proponent P who asserts ϕ and an opponent O who denies ϕ. Thus propositions are interpreted as games, connectives (almost) as operations on games, and validity as existence of a winning strategy for P. (The qualifier `almost' will be discussed later when more details have been presented.) We propose that the connectives of linear logic can be naturally interpreted as the operations on games introduced for entirely different purposes by Blass (1972). We show that affine logic, i.e., linear logic plus the rule of weakening, is sound for this interpretation. We also obtain a completeness theorem for the additive fragment of affine logic, but we show that completeness fails for the multiplicative fragment. On the other hand, for the multiplicative fragment, we obtain a simple characterization of game-semantical validity in terms of classical tautologies. An analysis of the failure of completeness for the multiplicative fragment leads to the conclusion that the game interpretation of the connective ⊗ is weaker than the interpretation implicit in Girard's proof rules; we discuss the differences between the two interpretations and their relative advantages and disadvantages. Finally, we discuss how G{\"o}del's Dialectica interpretation (1958), which was connected to linear logic by de Paiva (1989), fits with game semantics. },
	Author = {Andreas Blass},
	Date-Added = {2013-06-13 10:07:37 +0000},
	Date-Modified = {2013-06-13 10:07:40 +0000},
	Doi = {10.1016/0168-0072(92)90073-9},
	Issn = {0168-0072},
	Journal = {Annals of Pure and Applied Logic},
	Number = {1--3},
	Pages = {183 - 220},
	Title = {A game semantics for linear logic},
	Url = {http://www.sciencedirect.com/science/article/pii/0168007292900739},
	Volume = {56},
	Year = {1992},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0168007292900739},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0168-0072(92)90073-9}}

@inproceedings{Liu99a,
	Acmid = {328700},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Stoller, Scott D.},
	Booktitle = {Proceedings of the 2000 ACM SIGPLAN workshop on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-10 20:44:33 +0000},
	Date-Modified = {2013-06-10 20:44:55 +0000},
	Doi = {10.1145/328690.328700},
	Isbn = {1-58113-201-8},
	Keywords = {incremental computation; optimization},
	Location = {Boston, Massachusetts, USA},
	Numpages = {10},
	Pages = {73--82},
	Publisher = {ACM},
	Series = {PEPM '00},
	Title = {From recursion to iteration: what are the optimizations?},
	Url = {http://doi.acm.org/10.1145/328690.328700},
	Year = {1999},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/328690.328700},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/328690.328700}}

@inproceedings{Emir07Correct,
	Abstract = {Pattern matching makes ML programs more concise and readable, and these qualities are also sought in object-oriented settings. However, objects and classes come with open class hierarchies, extensibility requirements and the need for data abstraction, which all conflict with matching on concrete data types. Extractor-based pattern matching has been proposed to address this conflict. Extractors are user-defined methods that perform the task of value discrimination and deconstruction during pattern matching. In this paper, we give the first formalization of extractor-based matching, using a first-order object-oriented calculus. We give a direct operational semantics and prove it sound. We then present an optimizing translation to a target language without matching, and prove a correctness result stating that an expression is equivalent to its translation.},
	Acmid = {1784782},
	Address = {Berlin, Heidelberg},
	Author = {Emir, Burak and Ma, Qin and Odersky, Martin},
	Booktitle = {Proceedings of the 5th Asian conference on Programming languages and systems},
	Date-Added = {2013-06-09 13:38:40 +0000},
	Date-Modified = {2013-06-09 13:39:51 +0000},
	Isbn = {3-540-76636-7, 978-3-540-76636-0},
	Location = {Singapore},
	Numpages = {17},
	Pages = {54--70},
	Publisher = {Springer-Verlag},
	Series = {APLAS'07},
	Title = {Translation Correctness for First-Order Object-Oriented Pattern Matching},
	Url = {http://dl.acm.org/citation.cfm?id=1784774.1784782},
	Year = {2007},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1784774.1784782}}

@incollection{wadler1993taste,
	Author = {Wadler, Philip},
	Booktitle = {Mathematical Foundations of Computer Science 1993},
	Date-Added = {2013-06-06 17:10:01 +0000},
	Date-Modified = {2013-06-06 17:10:01 +0000},
	Pages = {185--210},
	Publisher = {Springer},
	Title = {A taste of linear logic},
	Year = {1993}}

@book{girard1989proofs,
	Annote = {Wadler cites it in \cite{wadler1993taste} by saying "see the wonderful introduction by Girard, Lafont and Taylor \cite{girard1989proofs}". However, everybody keeps telling me that this book is horrible.},
	Author = {Girard, Jean-Yves and Taylor, Paul and Lafont, Yves},
	Date-Added = {2013-06-06 17:09:13 +0000},
	Date-Modified = {2017-06-29 03:01:52 +0000},
	Publisher = {Cambridge University Press Cambridge},
	Title = {Proofs and types},
	Year = {1989}}

@incollection{Emir06Variance,
	Abstract = {Generic types in C ♯ behave invariantly with respect to subtyping. We propose a system of type-safe variance for C ♯ that supports the declaration of covariant and contravariant type parameters on generic types. To support more widespread application of variance we also generalize the existing constraint mechanism with arbitrary subtype assertions on classes and methods. This extension is useful even in the absence of variance, and subsumes equational constraints proposed for Generalized Algebraic Data Types (GADTs). We formalize the subtype relation in both declarative and syntax-directed style, and describe and prove the correctness of algorithms for constraint closure and subtyping. Finally, we formalize and prove a type safety theorem for a featherweight language with variant classes and generalized constraints.},
	Author = {Emir, Burak and Kennedy, Andrew and Russo, Claudio and Yu, Dachuan},
	Booktitle = ecoop,
	Date-Added = {2013-06-06 16:57:54 +0000},
	Date-Modified = {2013-06-06 16:58:39 +0000},
	Nobooktitle = {ECOOP 2006 -- Object-Oriented Programming},
	Nodoi = {10.1007/11785477_18},
	Noeditor = {Thomas, Dave},
	Noisbn = {978-3-540-35726-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/11785477_18},
	Novolume = {4067},
	Pages = {279-303},
	Publisher = springer,
	Title = {Variance and Generalized Constraints for {C}$^\sharp$ Generics},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11785477_18}}

@inproceedings{Liu95a,
	Abstract = {The paper describes the design and implementation of an interactive, incremental-attribution-based program transformation system, CACHET, that derives incremental programs from non-incremental programs written in a functional language. CACHET is designed as a programming environment and implemented using a language-based editor generator, the Synthesizer Generator, with extensions that support complex transformations. Transformations directly manipulate the program tree and take into consideration information obtained from program analyses. Program analyses are performed via attribute evaluation, which is done incrementally as transformations change the program tree. The overall approach also explores a general framework for describing dynamic program semantics using annotations, which allows interleaving transformations with external input, such as user input. Designing CACHET as a programming environment also facilitates the integration of program derivation and validation with interactive editing, compiling, debugging, and execution},
	Author = {Liu, Y.A.},
	Booktitle = {Proceedings 10th Knowledge-Based Software Engineering Conference.},
	Date-Added = {2013-06-05 13:01:04 +0000},
	Date-Modified = {2013-06-09 15:30:00 +0000},
	Doi = {10.1109/KBSE.1995.490115},
	Issn = {1068-3062},
	Keywords = {attribute grammars;functional programming;incremental compilers;interactive programming;knowledge based systems;program debugging;program verification;programming environments;software tools;system monitoring;CACHET programming environment;Synthesizer Generator;annotations;attribute evaluation;compiling;complex transformations;debugging;dynamic program semantics;execution;external input;functional language;incremental program derivation;interactive editing;interactive incremental-attribution-based program transformation system;interleaving transformations;language-based editor generator;nonincremental programs;program analyses;program derivation;program tree;program validation;user input;Computer science;Contracts;Databases;Information analysis;Interleaved codes;Performance analysis;Performance evaluation;Programming environments;Synthesizers;Usability; incremental computation},
	Pages = {19-26},
	Title = {CACHET: an interactive, incremental-attribution-based program transformation system for deriving incremental programs},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/KBSE.1995.490115}}

@incollection{Liu99,
	Abstract = {Dynamic programming is an important algorithm design technique. It is used for solving problems whose solutions involve recursively solving subproblems that share subsubproblems. While a straightforward recursive program solves common subsubproblems repeatedly and often takes exponential time, a dynamic programming algorithm solves every subsubproblem just once, saves the result, reuses it when the subsubproblem is encountered again, and takes polynomial time. This paper describes a systematic method for transforming programs written as straightforward recursions into programs that use dynamic programming. The method extends the original program to cache all possibly computed values, incrementalizes the extended program with respect to an input increment to use and maintain all cached results, prunes out cached results that are not used in the incremental computation, and uses the resulting incremental program to form an optimized new program. Incrementalization statically exploits semantics of both control structures and data structures and maintains as invariants equalities characterizing cached results. The principle underlying incrementalization is general for achieving drastic program speedups. Compared with previous methods that perform memoization or tabulation, the method based on incrementalization is more powerful and systematic. It has been implemented and applied to numerous problems and succeeded on all of them.},
	Author = {Liu, Yanhong A. and Stoller, Scott D.},
	Booktitle = {Programming Languages and Systems},
	Date-Added = {2013-06-05 12:58:35 +0000},
	Date-Modified = {2014-01-21 11:47:22 +0000},
	Doi = {10.1007/3-540-49099-X_19},
	Editor = {Swierstra, S.Doaitse},
	Isbn = {978-3-540-65699-9},
	Keywords = {incremental computation},
	Language = {English},
	Pages = {288-305},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Dynamic Programming via Static Incrementalization},
	Url = {http://dx.doi.org/10.1007/3-540-49099-X_19},
	Volume = {1576},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-49099-X_19}}

@article{Loader01,
	Abstract = {The question of the decidability of the observational ordering of finitary \{PCF\} was raised (Jung and Stoughton, in: M. Bezem, J.F. Groote (Eds.), Typed Lambda Calculi and Applications, Lecture Notes in Computer Science, vol. 664, Springer, Berlin, 1993, pp. 230--244) to give mathematical content to the full abstraction problem for \{PCF\} (Milner, Theoret. Comput. Sci. 4 (1977) 1--22). We show that the ordering is in fact undecidable. This result places limits on how explicit a representation of the fully abstract model can be. It also gives a slight strengthening of the author's earlier result on typed λ-definability (Loader, in: A. Anderson, M. Zeleny (Eds.), Church Memorial Volume, Kluwer Academic Press, Dordrecht, to appear). },
	Author = {Ralph Loader},
	Date-Added = {2013-06-05 12:45:07 +0000},
	Date-Modified = {2013-06-05 12:57:07 +0000},
	Doi = {10.1016/S0304-3975(00)00194-8},
	Issn = {0304-3975},
	Journal = {Theoretical Computer Science},
	Keywords = {Full abstraction},
	Number = {1--2},
	Pages = {341 - 364},
	Title = {Finitary {PCF} is not decidable},
	Url = {http://www.sciencedirect.com/science/article/pii/S0304397500001948},
	Volume = {266},
	Year = {2001},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0304397500001948},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S0304-3975(00)00194-8}}

@article{Liu00,
	Abstract = {Incremental computation takes advantage of repeated computations on inputs that differ slightly from one another, computing each output efficiently by exploiting the previous output. This paper gives an overview of a general and systematic approach to incrementalization: given a program f and an operation ⊕, the approach yields an incremental program that computes f(x ⊕ y) efficiently by using the result of f(x), the intermediate results of f(x), and auxiliary information of f(x) that can be inexpensively maintained.
Since every non-trivial computation proceeds by iteration or recursion, the approach can be used for achieving efficient computation by computing each iteration incrementally using an appropriate incremental program. This approach has applications in interactive systems, optimizing compilers, transformational programming, and many other areas, where problems were previously solved in less general and systematic ways. This paper also describes the design and implementation of CACHET, a prototype system for incrementalization.},
	Author = {Liu, Yanhong A.},
	Date-Added = {2013-06-04 21:38:00 +0000},
	Date-Modified = {2013-06-04 21:38:12 +0000},
	Journal = hosc,
	Keywords = {caching; incremental computation; incremental programs; incrementalization; program analysis; program optimization; program transformation; programming environments},
	Language = {English},
	Nodoi = {10.1023/A:1026547031739},
	Noissn = {1388-3690},
	Nourl = {http://dx.doi.org/10.1023/A%3A1026547031739},
	Number = {4},
	Pages = {289-313},
	Publisher = kluwer,
	Title = {Efficiency by Incrementalization: An Introduction},
	Volume = {13},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A%3A1026547031739},
	Bdsk-Url-2 = {http://dx.doi.org/10.1023/A:1026547031739}}

@inproceedings{Zhang98,
	Acmid = {289480},
	Address = {New York, NY, USA},
	Author = {Zhang, Yuchen and Lin, Yanhong A.},
	Booktitle = ICFP,
	Date-Added = {2013-06-04 18:00:17 +0000},
	Date-Modified = {2013-06-04 18:04:37 +0000},
	Doi = {10.1145/289423.289480},
	Isbn = {1-58113-024-4},
	Location = {Baltimore, Maryland, USA},
	Pages = {350},
	Publisher = {ACM},
	Series = {ICFP '98},
	Title = {Automating derivation of incremental programs},
	Url = {http://doi.acm.org/10.1145/289423.289480},
	Year = {1998},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/289423.289480},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/289423.289480}}

@inproceedings{Liu95,
	Acmid = {215590},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Teitelbaum, Tim},
	Booktitle = {Proceedings of the 1995 ACM SIGPLAN symposium on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-04 17:18:24 +0000},
	Date-Modified = {2013-06-09 15:30:00 +0000},
	Doi = {10.1145/215465.215590},
	Isbn = {0-89791-720-0},
	Keywords = {incremental computation},
	Location = {La Jolla, California, USA},
	Numpages = {12},
	Pages = {190--201},
	Publisher = {ACM},
	Series = {PEPM '95},
	Title = {Caching intermediate results for program improvement},
	Url = {http://doi.acm.org/10.1145/215465.215590},
	Year = {1995},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/215465.215590},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/215465.215590}}

@article{Liu98,
	Acmid = {291895},
	Address = {New York, NY, USA},
	Author = {Liu, Yanhong A. and Stoller, Scott D. and Teitelbaum, Tim},
	Date-Added = {2013-06-04 17:18:09 +0000},
	Date-Modified = {2013-06-04 17:18:11 +0000},
	Doi = {10.1145/291889.291895},
	Issn = {0164-0925},
	Issue_Date = {May 1998},
	Journal = toplas,
	Keywords = {caching, dependence analysis, incremental computation, incremental programs, intermediate results, memoization, optimization, program efficiency improvement, program transformation, static analysis},
	Month = may,
	Number = {3},
	Numpages = {40},
	Pages = {546--585},
	Publisher = {ACM},
	Title = {Static caching for incremental computation},
	Url = {http://doi.acm.org/10.1145/291889.291895},
	Volume = {20},
	Year = {1998},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/291889.291895},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/291889.291895}}

@inproceedings{Sundaresh91a,
	Acmid = {115875},
	Address = {New York, NY, USA},
	Author = {Sundaresh, R. S.},
	Booktitle = {Proceedings of the 1991 ACM SIGPLAN symposium on Partial evaluation and semantics-based program manipulation},
	Date-Added = {2013-06-04 12:57:23 +0000},
	Date-Modified = {2014-02-08 19:58:00 +0000},
	Doi = {10.1145/115865.115875},
	Isbn = {0-89791-433-3},
	Keywords = {incremental computation},
	Location = {New Haven, Connecticut, USA},
	Numpages = {11},
	Pages = {83--93},
	Publisher = {ACM},
	Series = {PEPM '91},
	Title = {Building incremental programs using partial evaluation},
	Url = {http://doi.acm.org/10.1145/115865.115875},
	Year = {1991},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/115865.115875},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/115865.115875}}

@inproceedings{Sundaresh91,
	Acmid = {99587},
	Address = acmaddr,
	Annote = {Also titled:
Incremental Computation via Partial Evaluation},
	Author = {Sundaresh, R. S. and Hudak, Paul},
	Booktitle = popl,
	Date-Added = {2013-06-04 03:21:53 +0000},
	Date-Modified = {2014-02-08 19:59:08 +0000},
	Keywords = {incremental computation},
	Location = {Orlando, Florida, USA},
	Nodoi = {10.1145/99583.99587},
	Noisbn = {0-89791-419-8},
	Noseries = {POPL '91},
	Nourl = {http://doi.acm.org/10.1145/99583.99587},
	Numpages = {13},
	Pages = {1--13},
	Publisher = {ACM},
	Title = {A theory of incremental computation and its application},
	Year = {1991},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/99583.99587},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/99583.99587}}

@article{Acar09EAS,
	Abstract = {Recent work on adaptive functional programming (AFP) developed techniques for writing programs that can respond to modifications to their data by performing change propagation. To achieve this, executions of programs are represented with dynamic dependence graphs (DDGs) that record data dependences and control dependences in a way that a change-propagation algorithm can update the computation as if the program were from scratch, by re-executing only the parts of the computation affected by the changes. Since change-propagation only re-executes parts of the computation, it can respond to certain incremental modifications asymptotically faster than recomputing from scratch, potentially offering significant speedups. Such asymptotic speedups, however, are rare: for many computations and modifications, change propagation is no faster than recomputing from scratch.

In this article, we realize a duality between dynamic dependence graphs and memoization, and combine them to give a change-propagation algorithm that can dramatically increase computation reuse. The key idea is to use DDGs to identify and re-execute the parts of the computation that are affected by modifications, while using memoization to identify the parts of the computation that remain unaffected by the changes. We refer to this approach as self-adjusting computation. Since DDGs are imperative, but (traditional) memoization requires purely functional computation, reusing computation correctly via memoization becomes a challenge. We overcome this challenge with a technique for remembering and reusing not just the results of function calls (as in conventional memoization), but their executions represented with DDGs. We show that the proposed approach is realistic by describing a library for self-adjusting computation, presenting efficient algorithms for realizing the library, and describing and evaluating an implementation. Our experimental evaluation with a variety of applications, ranging from simple list primitives to more sophisticated computational geometry algorithms, shows that the approach is effective in practice: compared to recomputing from-scratch; self-adjusting programs respond to small modifications to their data orders of magnitude faster.},
	Acmid = {1596530},
	Address = acmaddr,
	Articleno = {3},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Blume, Matthias and Harper, Robert and Tangwongsan, Kanat},
	Date-Added = {2013-05-31 15:54:36 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Issue_Date = {October 2009},
	Journal = toplas,
	Keywords = {Computational geometry, dynamic algorithms, dynamic dependence graphs, memoization, performance, self-adjusting computation; incremental computation},
	Month = nov,
	Nodoi = {10.1145/1596527.1596530},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/1596527.1596530},
	Number = {1},
	Numpages = {53},
	Pages = {3:1--3:53},
	Publisher = {ACM},
	Title = {An experimental analysis of self-adjusting computation},
	Volume = {32},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596527.1596530},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596527.1596530}}

@inproceedings{Acar10TDT,
	Abstract = {Self-adjusting computation provides an evaluation model where computations can respond automatically to modifications to their data by using a mechanism for propagating modifications through the computation. Current approaches to self-adjusting computation guarantee correctness by recording dependencies in a trace at the granularity of individual memory operations. Tracing at the granularity of memory operations, however, has some limitations: it can be asymptotically inefficient (\eg, compared to optimal solutions) because it cannot take advantage of problem-specific structure, it requires keeping a large computation trace (often proportional to the runtime of the program on the current input), and it introduces moderately large constant factors in practice.

In this paper, we extend dependence-tracing to work at the granularity of the query and update operations of arbitrary (abstract) data types, instead of just reads and writes on memory cells. This can significantly reduce the number of dependencies that need to be kept in the trace and followed during an update. We define an interface for supporting a traceable version of a data type, which reports the earliest query that depends on (is changed by) revising operations back in time, and implement several such structures, including priority queues, queues, dictionaries, and counters. We develop a semantics for tracing, extend an existing self-adjusting language, ΔML, and its implementation to support traceable data types, and present an experimental evaluation by considering a number of benchmarks. Our experiments show dramatic improvements on space and time, sometimes by as much as two orders of magnitude.},
	Acmid = {1806650},
	Address = acmaddr,
	Author = {Acar, Umut A. and Blelloch, Guy and Ley-Wild, Ruy and Tangwongsan, Kanat and Turkoglu, Duru},
	Booktitle = pldi,
	Date-Added = {2013-05-31 15:46:14 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation, traceable data types; incremental computation},
	Location = {Toronto, Ontario, Canada},
	Nodoi = {10.1145/1806596.1806650},
	Noisbn = {978-1-4503-0019-3},
	Noseries = {PLDI '10},
	Nourl = {http://doi.acm.org/10.1145/1806596.1806650},
	Numpages = {14},
	Pages = {483--496},
	Publisher = {ACM},
	Title = {Traceable data types for self-adjusting computation},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1806596.1806650},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1806596.1806650}}

@incollection{Acar07,
	Abstract = {This paper presents a semantics of self-adjusting computation and proves that the semantics is correct and consistent. The semantics integrates change propagation with the classic idea of memoization to enable reuse of computations under mutation to memory. During evaluation, reuse of a computation via memoization triggers a change propagation that adjusts the reused computation to reflect the mutated memory. Since the semantics combines memoization and change-propagation, it involves both non-determinism and mutation. Our consistency theorem states that the non-determinism is not harmful: any two evaluations of the same program starting at the same state yield the same result. Our correctness theorem states that mutation is not harmful: self-adjusting programs are consistent with purely functional programming. We formalized the semantics and its meta-theory in the LF logical framework and machine-checked the proofs in Twelf.},
	Author = {Acar, UmutA. and Blume, Matthias and Donham, Jacob},
	Booktitle = {Programming Languages and Systems},
	Date-Added = {2013-05-31 15:36:47 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1007/978-3-540-71316-6_31},
	Editor = {Nicola, Rocco},
	Isbn = {978-3-540-71314-2},
	Keywords = {self-adjusting computation; incremental computation},
	Pages = {458-474},
	Publisher = {Springer Berlin Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A Consistent Semantics of Self-adjusting Computation},
	Url = {http://dx.doi.org/10.1007/978-3-540-71316-6_31},
	Volume = {4421},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-71316-6_31}}

@inproceedings{Acar06experim,
	Abstract = {Dependence graphs and memoization can be used to efficiently update the output of a program as the input changes dynamically. Recent work has studied techniques for combining these approaches to effectively dynamize a wide range of applications. Toward this end various theoretical results were given. In this paper we describe the implementation of a library based on these ideas, and present experimental results on the efficiency of this library on a variety of applications. The results of the experiments indicate that the approach is effective in practice, often requiring orders of magnitude less time than recomputing the output from scratch. We believe this is the first experimental evidence that incremental computation of any type is effective in practice for a reasonably broad set of applications.},
	Acmid = {1133993},
	Address = {New York, NY, USA},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Blume, Matthias and Tangwongsan, Kanat},
	Booktitle = {Proceedings of the 2006 ACM SIGPLAN conference on Programming language design and implementation},
	Date-Added = {2013-05-31 13:43:14 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1133981.1133993},
	Isbn = {1-59593-320-4},
	Keywords = {computational geometry, dynamic algorithms, dynamic dependence graphs, memorization, performance, self-adjusting computation; incremental computation},
	Location = {Ottawa, Ontario, Canada},
	Numpages = {12},
	Pages = {96--107},
	Publisher = {ACM},
	Series = {PLDI '06},
	Title = {An experimental analysis of self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1133981.1133993},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1133981.1133993},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1133981.1133993}}

@article{Acar06Lib,
	Abstract = {We present a Standard ML library for writing programs that automatically adjust to changes to their data. The library combines modifiable references and memoization to achieve efficient updates. We describe an implementation of the library and apply it to the problem of maintaining the convex hull of a dynamically changing set of points. Our experiments show that the overhead of the library is small, and that self-adjusting programs can adjust to small changes three-orders of magnitude faster than recomputing from scratch. The implementation relies on invariants that could be enforced by a modal type system. We show, using an existing language, abstract interfaces for modifiable references and for memoization that ensure the same safety properties without the use of modal types. The interface for memoization, however, does not scale well, suggesting a language-based approach to be preferable after all. },
	Author = {Umut Acar and Guy Blelloch and Matthias Blume and Robert Harper and Kanat Tangwongsan},
	Date-Added = {2013-05-31 13:41:06 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1016/j.entcs.2005.11.043},
	Issn = {1571-0661},
	Journal = {Electronic Notes in Theoretical Computer Science},
	Keywords = {quickhull; self-adjusting computation; incremental computation},
	Note = {<ce:title>Proceedings of the ACM-SIGPLAN Workshop on \{ML\} (ML 2005)</ce:title> <xocs:full-name>ACM-SIGPLAN Workshop on \{ML\} 2005</xocs:full-name>},
	Number = {2},
	Pages = {127 - 154},
	Title = {A Library for Self-Adjusting Computation},
	Url = {http://www.sciencedirect.com/science/article/pii/S1571066106001290},
	Volume = {148},
	Year = {2006},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1571066106001290},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/j.entcs.2005.11.043}}

@inproceedings{Acar09,
	Abstract = {Many applications need to respond to incremental modifications to data. Being incremental, such modification often require incremental modifications to the output, making it possible to respond to them asymptotically faster than recomputing from scratch. In many cases, taking advantage of incrementality therefore dramatically improves performance, especially as the input size increases. As a frame of reference, note that in parallel computing speedups are bounded by the number of processors, often a (small) constant.

Designing and developing applications that respond to incremental modifications, however, is challenging: it often involves developing highly specific, complex algorithms. Self-adjusting computation offers a linguistic approach to this problem. In self-adjusting computation, programs respond automatically and efficiently to modifications to their data by tracking the dynamic data dependences of the computation and incrementally updating their output as needed. In this invited talk, I present an overview of self-adjusting computation and briefly discuss the progress in developing the approach and present some recent advances.},
	Acmid = {1480946},
	Address = acmaddr,
	Author = {Acar, Umut A.},
	Booktitle = pepm,
	Date-Added = {2013-05-31 13:17:25 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {asymptotic complexity, change propagation, compilers, continuations, dependence graphs, incremental modification, language design, performance, self-adjusting computation; incremental computation},
	Location = {Savannah, GA, USA},
	Nodoi = {10.1145/1480945.1480946},
	Noisbn = {978-1-60558-327-3},
	Noseries = {PEPM '09},
	Nourl = {http://doi.acm.org/10.1145/1480945.1480946},
	Numpages = {6},
	Pages = {1--6},
	Publisher = {ACM},
	Read = {1},
	Title = {Self-adjusting computation: (an overview)},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480945.1480946},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480945.1480946}}

@inproceedings{Acar08,
	Abstract = {Self-adjusting computation enables writing programs that can automatically and efficiently respond to changes to their data (e.g., inputs). The idea behind the approach is to store all data that can change over time in modifiable references and to let computations construct traces that can drive change propagation. After changes have occurred, change propagation updates the result of the computation by re-evaluating only those expressions that depend on the changed data. Previous approaches to self-adjusting computation require that modifiable references be written at most once during execution---this makes the model applicable only in a purely functional setting.

In this paper, we present techniques for imperative self-adjusting computation where modifiable references can be written multiple times. We define a language SAIL (Self-Adjusting Imperative Language) and prove consistency, i.e., that change propagation and from-scratch execution are observationally equivalent. Since SAIL programs are imperative, they can create cyclic data structures. To prove equivalence in the presence of cycles in the store, we formulate and use an untyped, step-indexed logical relation, where step indices are used to ensure well-foundedness. We show that SAIL accepts an asymptotically efficient implementation by presenting algorithms and data structures for its implementation. When the number of operations (reads and writes) per modifiable is bounded by a constant, we show that change propagation becomes as efficient as in the non-imperative case. The general case incurs a slowdown that is logarithmic in the maximum number of such operations. We describe a prototype implementation of SAIL as a Standard ML library},
	Acmid = {1328476},
	Address = {New York, NY, USA},
	Author = {Acar, Umut A. and Ahmed, Amal and Blume, Matthias},
	Booktitle = {Proceedings of the 35th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-31 13:16:36 +0000},
	Date-Modified = {2013-05-31 15:58:26 +0000},
	Doi = {10.1145/1328438.1328476},
	Isbn = {978-1-59593-689-9},
	Keywords = {change propagation, imperative programming, incremental computation, memoization, mutable state, self-adjusting computation, step-indexed logical relations},
	Location = {San Francisco, California, USA},
	Numpages = {14},
	Pages = {309--322},
	Publisher = {ACM},
	Series = {POPL '08},
	Title = {Imperative self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1328438.1328476},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1328438.1328476},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1328438.1328476}}

@inproceedings{Ley-Wild09,
	Abstract = {Self-adjusting computation is an evaluation model in which programs can respond efficiently to small changes to their input data by using a change-propagation mechanism that updates computation by re-building only the parts affected by changes. Previous work has proposed language techniques for self-adjusting computation and showed the approach to be effective in a number of application areas. However, due to the complex semantics of change propagation and the indirect nature of previously proposed language techniques, it remains difficult to reason about the efficiency of self-adjusting programs and change propagation.

In this paper, we propose a cost semantics for self-adjusting computation that enables reasoning about its effectiveness. As our source language, we consider a direct-style λ-calculus with first-class mutable references and develop a notion of trace distance for source programs. To facilitate asymptotic analysis, we propose techniques for composing and generalizing concrete distances via trace contexts (traces with holes). We then show how to translate the source language into a self-adjusting target language such that the translation (1) preserves the extensional semantics of the source programs and the cost of from-scratch runs, and (2) ensures that change propagation between two evaluations takes time bounded by their relative distance. We consider several examples and analyze their effectiveness by considering upper and lower bounds.},
	Acmid = {1480907},
	Address = {New York, NY, USA},
	Author = {Ley-Wild, Ruy and Acar, Umut A. and Fluet, Matthew},
	Booktitle = {Proceedings of the 36th annual ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-31 13:14:56 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1480881.1480907},
	Isbn = {978-1-60558-379-2},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Savannah, GA, USA},
	Numpages = {14},
	Pages = {186--199},
	Publisher = {ACM},
	Series = {POPL '09},
	Title = {A cost semantics for self-adjusting computation},
	Url = {http://doi.acm.org/10.1145/1480881.1480907},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1480881.1480907},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1480881.1480907}}

@inproceedings{Ley-Wild08,
	Abstract = {Self-adjusting programs respond automatically and efficiently to input changes by tracking the dynamic data dependences of the computation and incrementally updating the output as needed. In order to identify data dependences, previously proposed approaches require the user to make use of a set of monadic primitives. Rewriting an ordinary program into a self-adjusting program with these primitives, however, can be difficult and error-prone due to various monadic and proper-usage restrictions, some of which cannot be enforced statically. Previous work therefore suggests that self-adjusting computation would benefit from direct language and compiler support.

In this paper, we propose a language-based technique for writing and compiling self-adjusting programs from ordinary programs. To compile self-adjusting programs, we use a continuation-passing style (cps) transformation to automatically infer a conservative approximation of the dynamic data dependences. To prevent the inferred, approximate dependences from degrading the performance of change propagation, we generate memoized versions of cps functions that can reuse previous work even when they are invoked with different continuations. The approach offers a natural programming style that requires minimal changes to existing code, while statically enforcing the invariants required by self-adjusting computation.

We validate the feasibility of our proposal by extending Standard ML and by integrating the transformation into MLton, a whole-program optimizing compiler for Standard ML. Our experiments indicate that the proposed compilation technique can produce self-adjusting programs whose performance is consistent with the asymptotic bounds and experimental results obtained via manual rewriting (up to a constant factor).},
	Acmid = {1411249},
	Address = {New York, NY, USA},
	Author = {Ley-Wild, Ruy and Fluet, Matthew and Acar, Umut A.},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-05-31 13:04:48 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/1411204.1411249},
	Isbn = {978-1-59593-919-7},
	Keywords = {continuation-passing style, memoization, self-adjusting computation; incremental computation},
	Location = {Victoria, BC, Canada},
	Numpages = {14},
	Pages = {321--334},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Compiling self-adjusting programs with continuations},
	Url = {http://doi.acm.org/10.1145/1411204.1411249},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411249},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411249}}

@inproceedings{Sansom95,
	Acmid = {199531},
	Address = {New York, NY, USA},
	Author = {Sansom, Patrick M. and Peyton Jones, Simon L.},
	Booktitle = {Proceedings of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Date-Added = {2013-05-30 09:06:14 +0000},
	Date-Modified = {2013-05-30 09:06:15 +0000},
	Doi = {10.1145/199448.199531},
	Isbn = {0-89791-692-1},
	Location = {San Francisco, California, USA},
	Numpages = {12},
	Pages = {355--366},
	Publisher = {ACM},
	Series = {POPL '95},
	Title = {Time and space profiling for non-strict, higher-order functional languages},
	Url = {http://doi.acm.org/10.1145/199448.199531},
	Year = {1995},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/199448.199531},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/199448.199531}}

@inproceedings{Field90,
	Abstract = {An incremental algorithm is one that takes advantage of the fact that the function it computes is to be evaluated repeatedly on inputs that differ only slightly from one another, avoiding unnecessary duplication of common computations. We define here a new notion of incrementality for reduction in the untyped λ-calculus and describe an incremental reduction algorithm, Λinc. We show that Λinc has the desirable property of performing non-overlapping reductions on related terms, yet is simple enough to allow a practical implementation. The algorithm is based on a novel λ-reduction strategy that may prove useful in a non-incremental setting as well. Incremental λ-reduction can be used to advantage in any setting where an algorithm is specified in a functional or applicative manner.},
	Acmid = {91679},
	Address = {New York, NY, USA},
	Author = {Field, John and Teitelbaum, Tim},
	Booktitle = {Proceedings of the 1990 ACM conference on LISP and functional programming},
	Date-Added = {2013-05-30 08:55:17 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Doi = {10.1145/91556.91679},
	Isbn = {0-89791-368-X},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Nice, France},
	Numpages = {16},
	Pages = {307--322},
	Publisher = {ACM},
	Series = {LFP '90},
	Title = {Incremental reduction in the lambda calculus},
	Url = {http://doi.acm.org/10.1145/91556.91679},
	Year = {1990},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/91556.91679},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/91556.91679}}

@inproceedings{Burckhardt11,
	Abstract = {Parallel or incremental versions of an algorithm can significantly outperform their counterparts, but are often difficult to develop. Programming models that provide appropriate abstractions to decompose data and tasks can simplify parallelization. We show in this work that the same abstractions can enable both parallel and incremental execution. We present a novel algorithm for parallel self-adjusting computation. This algorithm extends a deterministic parallel programming model (concurrent revisions) with support for recording and repeating computations. On record, we construct a dynamic dependence graph of the parallel computation. On repeat, we reexecute only parts whose dependencies have changed.

We implement and evaluate our idea by studying five example programs, including a realistic multi-pass CSS layout algorithm. We describe programming techniques that proved particularly useful to improve the performance of self-adjustment in practice. Our final results show significant speedups on all examples (up to 37x on an 8-core machine). These speedups are well beyond what can be achieved by parallelization alone, while requiring a comparable effort by the programmer.},
	Acmid = {2048101},
	Author = {Burckhardt, Sebastian and Leijen, Daan and Sadowski, Caitlin and Yi, Jaeheon and Ball, Thomas},
	Booktitle = oopsla,
	Date-Added = {2013-05-29 00:10:21 +0000},
	Date-Modified = {2013-06-09 15:30:35 +0000},
	Keywords = {incremental memoization, parallel programming, incremental computation},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/2048066.2048101},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048101},
	Numpages = {18},
	Pages = {427--444},
	Publisher = acm,
	Title = {Two for the price of one: a model for parallel and incremental computation},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048101}}

@inproceedings{Hammer11,
	Abstract = {Self-adjusting computation offers a language-based approach to writing programs that automatically respond to dynamically changing data. Recent work made significant progress in developing sound semantics and associated implementations of self-adjusting computation for high-level, functional languages. These techniques, however, do not address issues that arise for low-level languages, i.e., stack-based imperative languages that lack strong type systems and automatic memory management. In this paper, we describe techniques for self-adjusting computation which are suitable for low-level languages. Necessarily, we take a different approach than previous work: instead of starting with a high-level language with additional primitives to support self-adjusting computation, we start with a low-level intermediate language, whose semantics is given by a stack-based abstract machine. We prove that this semantics is sound: it always updates computations in a way that is consistent with full reevaluation. We give a compiler and runtime system for the intermediate language used by our abstract machine. We present an empirical evaluation that shows that our approach is efficient in practice, and performs favorably compared to prior proposals.},
	Acmid = {2048124},
	Author = {Hammer, Matthew A. and Neis, Georg and Chen, Yan and Acar, Umut A.},
	Booktitle = oopsla,
	Date-Added = {2013-05-29 00:09:57 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation; incremental computation},
	Noaddress = {New York, NY, USA},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048124},
	Numpages = {20},
	Pages = {753--772},
	Publisher = acm,
	Title = {Self-adjusting stack machines},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048124}}

@inproceedings{Chen11,
	Abstract = {Computational problems that involve dynamic data, such as physics simulations and program development environments, have been an important subject of study in programming languages. Building on this work, recent advances in self-adjusting computation have developed techniques that enable programs to respond automatically and efficiently to dynamic changes in their inputs. Self-adjusting programs have been shown to be efficient for a reasonably broad range of problems but the approach still requires an explicit programming style, where the programmer must use specific monadic types and primitives to identify, create and operate on data that can change over time.

We describe techniques for automatically translating purely functional programs into self-adjusting programs. In this implicit approach, the programmer need only annotate the (top-level) input types of the programs to be translated. Type inference finds all other types, and a type-directed translation rewrites the source program into an explicitly self-adjusting target program. The type system is related to information-flow type systems and enjoys decidable type inference via constraint solving. We prove that the translation outputs well-typed self-adjusting programs and preserves the source program's input-output behavior, guaranteeing that translated programs respond correctly to all changes to their data. Using a cost semantics, we also prove that the translation preserves the asymptotic complexity of the source program.},
	Acmid = {2034792},
	Author = {Chen, Yan and Dunfield, Joshua and Hammer, Matthew A. and Acar, Umut A.},
	Booktitle = ICFP,
	Date-Added = {2013-05-28 22:25:49 +0000},
	Date-Modified = {2013-06-09 15:30:39 +0000},
	Keywords = {self-adjusting computation; incremental computation},
	Location = {Tokyo, Japan},
	Noaddress = acmaddr,
	Nodoi = {10.1145/2034773.2034792},
	Noisbn = {978-1-4503-0865-6},
	Noseries = {ICFP '11},
	Nourl = {http://doi.acm.org/10.1145/2034773.2034792},
	Numpages = {13},
	Pages = {129--141},
	Publisher = ACM,
	Title = {Implicit self-adjusting computation for purely functional programs},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034792},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034792}}

@inproceedings{deOliveira13DataMill,
	Acmid = {2479892},
	Address = {New York, NY, USA},
	Author = {de Oliveira, Augusto Born and Petkovich, Jean-Christophe and Reidemeister, Thomas and Fischmeister, Sebastian},
	Booktitle = {Proceedings of the ACM/SPEC International conference on performance engineering},
	Date-Added = {2013-05-10 12:27:41 +0000},
	Date-Modified = {2013-05-10 12:28:28 +0000},
	Doi = {10.1145/2479871.2479892},
	Isbn = {978-1-4503-1636-1},
	Keywords = {datamill, experimentation, infrastructure, performance, repeatability, reproducibility, robustness},
	Location = {Prague, Czech Republic},
	Numpages = {12},
	Pages = {137--148},
	Publisher = {ACM},
	Series = {ICPE '13},
	Title = {DataMill: rigorous performance evaluation made easy},
	Url = {http://doi.acm.org/10.1145/2479871.2479892},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2479871.2479892},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2479871.2479892}}

@inproceedings{Tardieu12,
	Acmid = {2384675},
	Author = {Tardieu, Olivier and Nystrom, Nathaniel and Peshansky, Igor and Saraswat, Vijay},
	Booktitle = oopsla,
	Date-Added = {2013-04-19 17:55:33 +0000},
	Date-Modified = {2013-04-19 17:55:48 +0000},
	Keywords = {X10, constraints, generics, types},
	Location = {Tucson, Arizona, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/2384616.2384675},
	Noisbn = {978-1-4503-1561-6},
	Noseries = {OOPSLA '12},
	Nourl = {http://doi.acm.org/10.1145/2384616.2384675},
	Numpages = {20},
	Pages = {811--830},
	Publisher = ACM,
	Title = {Constrained kinds},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2384616.2384675},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2384616.2384675}}

@inproceedings{ChenDunfieldAcar12,
	Abstract = {Application data often changes slowly or incrementally over time. Since incremental changes to input often result in only small changes in output, it is often feasible to respond to such changes asymptotically more efficiently than by re-running the whole computation. Traditionally, realizing such asymptotic efficiency improvements requires designing problem-specific algorithms known as dynamic or incremental algorithms, which are often significantly more complicated than conventional algorithms to design, analyze, implement, and use. A long-standing open problem is to develop techniques that automatically transform conventional programs so that they correctly and efficiently respond to incremental changes.

In this paper, we describe a significant step towards solving the problem of automatic incrementalization: a programming language and a compiler that can, given a few type annotations describing what can change over time, compile a conventional program that assumes its data to be static (unchanging over time) to an incremental program. Based on recent advances in self-adjusting computation, including a theoretical proposal for translating purely functional programs to self-adjusting programs, we develop techniques for translating conventional Standard ML programs to self-adjusting programs. By extending the Standard ML language, we design a fully featured programming language with higher-order features, a module system, and a powerful type system, and implement a compiler for this language. The resulting programming language, LML, enables translating conventional programs decorated with simple type annotations into incremental programs that can respond to changes in their data correctly and efficiently.

We evaluate the effectiveness of our approach by considering a range of benchmarks involving lists, vectors, and matrices, as well as a ray tracer. For these benchmarks, our compiler incrementalizes existing code with only trivial amounts of annotation. The resulting programs are often asymptotically more efficient, leading to orders of magnitude speedups in practice.},
	Acmid = {2254100},
	Address = {New York, NY, USA},
	Author = {Chen, Yan and Dunfield, Joshua and Acar, Umut A.},
	Booktitle = {Proceedings of the 33rd ACM SIGPLAN conference on Programming Language Design and Implementation},
	Date-Added = {2013-04-18 16:33:55 +0000},
	Date-Modified = {2013-05-31 15:59:40 +0000},
	Doi = {10.1145/2254064.2254100},
	Isbn = {978-1-4503-1205-9},
	Keywords = {compiler optimization, incrementalization, performance, self-adjusting computation, type annotations; Incremental computation; adaptive computation},
	Location = {Beijing, China},
	Numpages = {12},
	Pages = {299--310},
	Publisher = {ACM},
	Series = {PLDI '12},
	Title = {Type-directed automatic incrementalization},
	Url = {http://doi.acm.org/10.1145/2254064.2254100},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2254064.2254100},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2254064.2254100}}

@inproceedings{Chen2014,
	Acmid = {2628150},
	Address = {New York, NY, USA},
	Author = {Chen, Yan and Acar, Umut A. and Tangwongsan, Kanat},
	Booktitle = {Proceedings of the 19th ACM SIGPLAN International Conference on Functional Programming},
	Doi = {10.1145/2628136.2628150},
	Isbn = {978-1-4503-2873-9},
	Keywords = {granularity control, incremental graph algorithms, information-flow type system, performance, self-adjusting computation},
	Location = {Gothenburg, Sweden},
	Numpages = {14},
	Pages = {227--240},
	Publisher = {ACM},
	Series = {ICFP '14},
	Title = {Functional Programming for Dynamic and Large Data with Self-adjusting Computation},
	Url = {http://doi.acm.org/10.1145/2628136.2628150},
	Year = {2014},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2628136.2628150},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2628136.2628150}}

@inproceedings{Hammer2015,
	Acmid = {2814305},
	Address = {New York, NY, USA},
	Author = {Hammer, Matthew A. and Dunfield, Joshua and Headley, Kyle and Labich, Nicholas and Foster, Jeffrey S. and Hicks, Michael and Van Horn, David},
	Booktitle = {Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications},
	Doi = {10.1145/2814270.2814305},
	Isbn = {978-1-4503-3689-5},
	Keywords = {call-by-push-value (CBPV), demanded computation graph (DCG), incremental compu- tation, laziness, memoization, nominal matching, self-adjusting computation, structural matching, thunks},
	Location = {Pittsburgh, PA, USA},
	Numpages = {19},
	Pages = {748--766},
	Publisher = {ACM},
	Series = {OOPSLA 2015},
	Title = {Incremental Computation with Names},
	Url = {http://doi.acm.org/10.1145/2814270.2814305},
	Year = {2015},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2814270.2814305},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2814270.2814305}}

@inproceedings{Kennedy05gadtoo,
	Acmid = {1094814},
	Author = {Kennedy, Andrew and Russo, Claudio V.},
	Booktitle = oopsla,
	Date-Added = {2013-04-18 16:31:43 +0000},
	Date-Modified = {2013-04-18 16:32:21 +0000},
	Keywords = {constraints, generalized algebraic data types, generics},
	Location = {San Diego, CA, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1094811.1094814},
	Noisbn = {1-59593-031-0},
	Noseries = {OOPSLA '05},
	Nourl = {http://doi.acm.org/10.1145/1094811.1094814},
	Numpages = {20},
	Pages = {21--40},
	Publisher = {ACM},
	Title = {Generalized algebraic data types and object-oriented programming},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094811.1094814},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094811.1094814}}

@inproceedings{MacQueen88,
	Acmid = {62704},
	Address = {New York, NY, USA},
	Author = {MacQueen, David},
	Booktitle = {Proceedings of the 1988 ACM conference on LISP and functional programming},
	Date-Added = {2013-04-12 19:31:53 +0000},
	Date-Modified = {2013-04-12 19:32:38 +0000},
	Doi = {10.1145/62678.62704},
	Isbn = {0-89791-273-X},
	Location = {Snowbird, Utah, USA},
	Numpages = {12},
	Pages = {212--223},
	Publisher = {ACM},
	Series = {LFP '88},
	Title = {An implementation of standard ML modules},
	Url = {http://doi.acm.org/10.1145/62678.62704},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62704},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62704}}

@article{Huet97,
	Abstract = {Almost every programmer has faced the problem of representing a tree together with a subtree that is the focus of attention, where that focus may move left, right, up or down the tree. The Zipper is Huet's nifty name for a nifty data structure which fulfills this need. I wish I had known of it when I faced this task, because the solution I came up with was not quite so efficient or elegant as the Zipper.},
	Author = {G{\'e}rard Huet},
	Date-Added = {2013-04-12 13:39:01 +0000},
	Date-Modified = {2013-04-12 16:46:22 +0000},
	Issn = {1469-7653},
	Journal = JFP,
	Month = {8},
	Number = {05},
	Numpages = {6},
	Pages = {549--554},
	Title = {The Zipper},
	Url = {http://journals.cambridge.org/article_S0956796897002864},
	Volume = {7},
	Year = {1997},
	Bdsk-Url-1 = {http://journals.cambridge.org/article_S0956796897002864},
	Bdsk-Url-2 = {http://dx.doi.org/null}}

@inproceedings{Nakamura01,
	Acmid = {504294},
	Address = {New York, NY, USA},
	Author = {Nakamura, Hiroaki},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2013-03-18 16:15:50 +0000},
	Date-Modified = {2013-05-13 09:14:42 +0000},
	Doi = {10.1145/504282.504294},
	Isbn = {1-58113-335-9},
	Keywords = {Incremental computation},
	Location = {Tampa Bay, FL, USA},
	Numpages = {10},
	Pages = {156--165},
	Publisher = {ACM},
	Series = {OOPSLA '01},
	Title = {Incremental computation of complex object queries},
	Url = {http://doi.acm.org/10.1145/504282.504294},
	Year = {2001},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/504282.504294},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/504282.504294}}

@article{Acar06,
	Abstract = {We present techniques for incremental computing by introducing adaptive functional programming. As an adaptive program executes, the underlying system represents the data and control dependences in the execution in the form of a dynamic dependence graph. When the input to the program changes, a change propagation algorithm updates the output and the dynamic dependence graph by propagating changes through the graph and re-executing code where necessary. Adaptive programs adapt their output to any change in the input, small or large.We show that adaptivity techniques are practical by giving an efficient implementation as a small ML library. The library consists of three operations for making a program adaptive, plus two operations for making changes to the input and adapting the output to these changes. We give a general bound on the time it takes to adapt the output, and based on this, show that an adaptive Quicksort adapts its output in logarithmic time when its input is extended by one key.To show the safety and correctness of the mechanism we give a formal definition of AFL, a call-by-value functional language extended with adaptivity primitives. The modal type system of AFL enforces correct usage of the adaptivity mechanism, which can only be checked at run time in the ML library. Based on the AFL dynamic semantics, we formalize thechange-propagation algorithm and prove its correctness.},
	Acmid = {1186634},
	Address = acmaddr,
	Author = {Acar, Umut A. and Blelloch, Guy E. and Harper, Robert},
	Date-Added = {2013-02-15 14:04:59 +0000},
	Date-Modified = {2013-05-31 15:57:21 +0000},
	Issue_Date = {November 2006},
	Journal = toplas,
	Keywords = {Incremental computation, adaptive computation, dynamic algorithms; self-adjusting computation},
	Month = nov,
	Nodoi = {10.1145/1186632.1186634},
	Noissn = {0164-0925},
	Nourl = {http://doi.acm.org/10.1145/1186632.1186634},
	Number = {6},
	Numpages = {45},
	Pages = {990--1034},
	Publisher = {ACM},
	Title = {Adaptive functional programming},
	Volume = {28},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1186632.1186634},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1186632.1186634}}

@inproceedings{Acar02,
	Abstract = {An adaptive computation maintains the relationship between its input and output as the input changes. Although various techniques for adaptive computing have been proposed, they remain limited in their scope of applicability. We propose a general mechanism for adaptive computing that enables one to make any purely-functional program adaptive.We show that the mechanism is practical by giving an efficient implementation as a small ML library. The library consists of three operations for making a program adaptive, plus two operations for making changes to the input and adapting the output to these changes. We give a general bound on the time it takes to adapt the output, and based on this, show that an adaptive Quicksort adapts its output in logarithmic time when its input is extended by one key.To show the safety and correctness of the mechanism we give a formal definition of AFL, a call-by-value functional language extended with adaptivity primitives. The modal type system of AFL enforces correct usage of the adaptivity mechanism, which can only be checked at run time in the ML library. Based on the AFL dynamic semantics, we formalize the change-propagation algorithm and prove its correctness.},
	Acmid = {503296},
	Author = {Acar, Umut A. and Blelloch, Guy E. and Harper, Robert},
	Booktitle = popl,
	Date-Added = {2013-02-15 14:02:01 +0000},
	Date-Modified = {2013-05-31 15:56:55 +0000},
	Keywords = {adaptive computation; Incremental computation; self-adjusting computation},
	Location = {Portland, Oregon},
	Noaddress = {New York, NY, USA},
	Nobooktitle = {Proceedings of the 29th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
	Nodoi = {10.1145/503272.503296},
	Noisbn = {1-58113-450-9},
	Noseries = {POPL '02},
	Nourl = {http://doi.acm.org/10.1145/503272.503296},
	Numpages = {13},
	Pages = {247--259},
	Publisher = {ACM},
	Title = {Adaptive functional programming},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/503272.503296},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/503272.503296}}

@inproceedings{Wang11IUE,
	Acmid = {2034825},
	Address = {New York, NY, USA},
	Author = {Wang, Meng and Gibbons, Jeremy and Wu, Nicolas},
	Booktitle = {Proceedings of the 16th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-28 16:09:26 +0000},
	Date-Modified = {2013-05-13 09:13:17 +0000},
	Doi = {10.1145/2034773.2034825},
	Isbn = {978-1-4503-0865-6},
	Keywords = {bidirectional programming, functional programming, program transformation, view-update problem; Incremental computation},
	Location = {Tokyo, Japan},
	Numpages = {12},
	Pages = {392--403},
	Publisher = {ACM},
	Series = {ICFP '11},
	Title = {Incremental updates for efficient bidirectional transformations},
	Url = {http://doi.acm.org/10.1145/2034773.2034825},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2034773.2034825},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2034773.2034825}}

@inproceedings{Perera05,
	Acmid = {1094871},
	Address = {New York, NY, USA},
	Author = {Perera, Roly and Foster, Jeff and Koch, Gy{\"o}rgy},
	Booktitle = {Companion to the 20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
	Date-Added = {2013-01-28 16:08:30 +0000},
	Date-Modified = {2013-05-31 15:50:37 +0000},
	Doi = {10.1145/1094855.1094871},
	Isbn = {1-59593-193-7},
	Keywords = {adaptive functions, delta-driven execution, incremental computation, lazy memoization, relational programming},
	Location = {San Diego, CA, USA},
	Numpages = {9},
	Pages = {63--71},
	Publisher = {ACM},
	Series = {OOPSLA '05},
	Title = {A delta-driven execution model for semantic computing},
	Url = {http://doi.acm.org/10.1145/1094855.1094871},
	Year = {2005},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1094855.1094871},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1094855.1094871}}

@inproceedings{Mainland08FSF,
	Acmid = {1411251},
	Address = {New York, NY, USA},
	Author = {Mainland, Geoffrey and Morrisett, Greg and Welsh, Matt},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-28 16:04:55 +0000},
	Date-Modified = {2013-01-28 16:05:22 +0000},
	Doi = {10.1145/1411204.1411251},
	Isbn = {978-1-59593-919-7},
	Keywords = {meta programming},
	Location = {Victoria, BC, Canada},
	Numpages = {12},
	Pages = {335--346},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Flask: staged functional programming for sensor networks},
	Url = {http://doi.acm.org/10.1145/1411204.1411251},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411251},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411251}}

@inproceedings{Amin12,
	Abstract = {We propose a new type-theoretic foundation of Scala and
                 languages like it: the Dependent Object Types (DOT)
                 calculus. DOT models Scala's path-dependent types,
                 abstract type members and its mixture of nominal and
                 structural typing through the use of refinement types. The
                 core formalism makes no attempt to model inheritance and
                 mixin composition. DOT normalizes Scala's type system by
                 unifying the constructs for type members and by providing
                 classical intersection and union types which simplify
                 greatest lower bound and least upper bound computations.
                 In this paper, we present the DOT calculus, both formally
                 and informally. We also discuss our work-in-progress to
                 prove typesafety of the calculus.},
	Affiliation = {EPFL},
	Author = {Amin, Nada and Moors, Adriaan and Odersky, Martin},
	Booktitle = {19{t}h {I}nternational {W}orkshop on {F}oundations of {O}bject-{O}riented {L}anguages},
	Date-Added = {2013-01-23 18:13:15 +0000},
	Date-Modified = {2013-01-23 18:13:17 +0000},
	Details = {http://infoscience.epfl.ch/record/183030},
	Documenturl = {http://infoscience.epfl.ch/record/183030/files/fool.pdf},
	Keywords = {calculus; objects; dependent types},
	Location = {Tucson, Arizona, USA},
	Oai-Id = {oai:infoscience.epfl.ch:183030},
	Oai-Set = {conf},
	Review = {REVIEWED},
	Status = {PUBLISHED},
	Submitter = {164625},
	Title = {Dependent {O}bject {T}ypes},
	Unit = {LAMP},
	Url = {https://github.com/namin/dot},
	Year = 2012,
	Bdsk-Url-1 = {https://github.com/namin/dot}}

@inproceedings{Demetrescu11,
	Acmid = {2048100},
	Author = {Demetrescu, Camil and Finocchi, Irene and Ribichini, Andrea},
	Booktitle = oopsla,
	Date-Added = {2013-01-23 17:48:24 +0000},
	Date-Modified = {2013-01-23 17:48:24 +0000},
	Keywords = {constraint solving, data structure repair, dataflow programming, imperative programming, incremental computation, observer design pattern, reactive programming},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/2048066.2048100},
	Noisbn = {978-1-4503-0940-0},
	Nolocation = {Portland, Oregon, USA},
	Noseries = {OOPSLA '11},
	Nourl = {http://doi.acm.org/10.1145/2048066.2048100},
	Numpages = {20},
	Pages = {407--426},
	Publisher = acm,
	Title = {Reactive imperative programming with dataflow constraints},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2048066.2048100}}

@inproceedings{Rompf13,
	Acmid = {2429128},
	Author = {Rompf, Tiark and Sujeeth, Arvind K. and Amin, Nada and Brown, Kevin J. and Jovanovic, Vojin and Lee, HyoukJoong and Jonnalagedda, Manohar and Olukotun, Kunle and Odersky, Martin},
	Booktitle = popl,
	Date-Added = {2013-01-23 16:49:06 +0000},
	Date-Modified = {2013-01-23 17:49:05 +0000},
	Keywords = {code generation, data structures, extensible compilers, staging},
	Location = {Rome, Italy},
	Noaddress = newyork,
	Nodoi = {10.1145/2429069.2429128},
	Noisbn = {978-1-4503-1832-7},
	Noseries = {POPL '13},
	Nourl = {http://doi.acm.org/10.1145/2429069.2429128},
	Numpages = {14},
	Pages = {497--510},
	Publisher = {ACM},
	Title = {Optimizing data structures in high-level programs: new directions for extensible compilers based on staging},
	Year = {2013},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2429069.2429128},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2429069.2429128}}

@incollection{Iu06Queryll,
	Affiliation = {School of Computer and Communication Sciences, EPFL, Lausanne, Switzerland},
	Author = {Iu, Ming-Yee and Zwaenepoel, Willy},
	Booktitle = {Middleware 2006},
	Date-Added = {2013-01-17 15:24:23 +0000},
	Date-Modified = {2013-01-17 15:24:35 +0000},
	Editor = {van Steen, Maarten and Henning, Michi},
	Isbn = {978-3-540-49023-4},
	Keyword = {Computer Science},
	Note = {10.1007/11925071_11},
	Pages = {201-218},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Queryll: Java Database Queries Through Bytecode Rewriting},
	Url = {http://dx.doi.org/10.1007/11925071_11},
	Volume = {4290},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11925071_11}}

@inproceedings{Chafi11,
	Acmid = {1941561},
	Address = {New York, NY, USA},
	Author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
	Booktitle = {Proceedings of the 16th ACM symposium on Principles and practice of parallel programming},
	Date-Added = {2013-01-16 15:08:52 +0000},
	Date-Modified = {2013-01-16 15:08:53 +0000},
	Doi = {10.1145/1941553.1941561},
	Isbn = {978-1-4503-0119-0},
	Keywords = {domain-specific languages, dynamic optimizations, parallel programming, runtimes},
	Location = {San Antonio, TX, USA},
	Numpages = {12},
	Pages = {35--46},
	Publisher = {ACM},
	Series = {PPoPP '11},
	Title = {A domain-specific approach to heterogeneous parallelism},
	Url = {http://doi.acm.org/10.1145/1941553.1941561},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1941553.1941561},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1941553.1941561}}

@article{gibbons2009essence,
	Author = {Gibbons, J. and Oliveira, B.C.S.},
	Date-Added = {2013-01-04 20:04:25 +0000},
	Date-Modified = {2013-01-04 20:04:25 +0000},
	Journal = {Journal of Functional Programming},
	Number = {3-4},
	Pages = {377--402},
	Publisher = {Cambridge Univ Press},
	Title = {The essence of the iterator pattern},
	Volume = {19},
	Year = {2009}}

@article{hinze2006finger,
	Author = {Hinze, R. and Paterson, R.},
	Date-Added = {2013-01-04 17:36:38 +0000},
	Date-Modified = {2013-01-04 17:36:38 +0000},
	Journal = {Journal of Functional Programming},
	Number = {2},
	Pages = {197--218},
	Publisher = {Cambridge Univ Press},
	Title = {Finger trees: a simple general-purpose data structure},
	Volume = {16},
	Year = {2006}}

@inproceedings{Baars02TDT,
	Acmid = {581494},
	Address = {New York, NY, USA},
	Author = {Baars, Arthur I. and Swierstra, S. Doaitse},
	Booktitle = {Proceedings of the seventh ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2013-01-02 02:52:37 +0000},
	Date-Modified = {2013-01-02 02:52:52 +0000},
	Doi = {10.1145/581478.581494},
	Isbn = {1-58113-487-8},
	Keywords = {Haskell, Leibnitz' rule, coercions, dynamic typing, quantified types, static typing, type equality, typed interpreters},
	Location = {Pittsburgh, PA, USA},
	Numpages = {10},
	Pages = {157--166},
	Publisher = {ACM},
	Series = {ICFP '02},
	Title = {Typing dynamic typing},
	Url = {http://doi.acm.org/10.1145/581478.581494},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/581478.581494},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/581478.581494}}

@incollection{Coquand94,
	Affiliation = {Chalmers University of Technology and University of G{\"o}teborg Department of Computer Sciences S-412 96 G{\"o}teborg Sweden S-412 96 G{\"o}teborg Sweden},
	Author = {Coquand, Catarina},
	Booktitle = {Computer Science Logic},
	Date-Added = {2013-01-01 16:27:45 +0000},
	Date-Modified = {2013-01-01 16:27:46 +0000},
	Editor = {B{\"o}rger, Egon and Gurevich, Yuri and Meinke, Karl},
	Isbn = {978-3-540-58277-9},
	Keyword = {Computer Science},
	Note = {10.1007/BFb0049326},
	Pages = {91-105},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {From semantics to rules: A machine assisted analysis},
	Url = {http://dx.doi.org/10.1007/BFb0049326},
	Volume = {832},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0049326}}

@article{Berger06,
	Abstract = {This paper describes formalizations of Tait's normalization proof for the simply typed λ-calculus in the proof assistants Minlog, Coq and Isabelle/HOL. From the formal proofs programs are machine-extracted that implement variants of the well-known normalization-by-evaluation algorithm. The case study is used to test and compare the program extraction machineries of the three proof assistants in a non-trivial setting.},
	Affiliation = {University of Wales Swansea Department of Computer Science Singleton Park Swansea SA2 8PP UK Singleton Park Swansea SA2 8PP UK},
	Author = {Berger, Ulrich and Berghofer, Stefan and Letouzey, Pierre and Schwichtenberg, Helmut},
	Date-Added = {2013-01-01 16:20:55 +0000},
	Date-Modified = {2013-01-01 16:20:55 +0000},
	Issn = {0039-3215},
	Issue = {1},
	Journal = {Studia Logica},
	Keyword = {Humanities, Social Sciences and Law},
	Note = {10.1007/s11225-006-6604-5},
	Pages = {25-49},
	Publisher = {Springer Netherlands},
	Title = {Program Extraction from Normalization Proofs},
	Url = {http://dx.doi.org/10.1007/s11225-006-6604-5},
	Volume = {82},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/s11225-006-6604-5}}

@incollection{Berger93,
	Affiliation = {Mathematisches Institut der Ludwig-Maximilians-Universit{\"a}t M{\"u}nchen Theresienstra{\ss}e 39 8000 M{\"u}nchen 2 Germany Theresienstra{\ss}e 39 8000 M{\"u}nchen 2 Germany},
	Author = {Berger, Ulrich},
	Booktitle = {Typed Lambda Calculi and Applications},
	Date-Added = {2013-01-01 16:18:31 +0000},
	Date-Modified = {2013-01-01 16:18:32 +0000},
	Editor = {Bezem, Marc and Groote, Jan},
	Isbn = {978-3-540-56517-8},
	Keyword = {Computer Science},
	Note = {10.1007/BFb0037100},
	Pages = {91-106},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Program extraction from normalization proofs},
	Url = {http://dx.doi.org/10.1007/BFb0037100},
	Volume = {664},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0037100}}

@article{Elgueta99,
	Abstract = {Given a structure for a first-order language L, two objects of its domain can be indiscernible relative to the properties expressible in L, without using the equality symbol, and without actually being the same. It is this relation that interests us in this paper. It is called Leibniz equality. In the paper we study systematically the problem of its definibility mainly for classes of structures that are the models of some equality-free universal Horn class in an infinitary language L κκ , where κ is an infinite regular cardinal.},
	Affiliation = {Universitat Polit{\`e}cnica de Catalunya Department of Applied Mathematics II Spain Spain},
	Author = {Elgueta, R. and Jansana, R.},
	Date-Added = {2013-01-01 16:16:47 +0000},
	Date-Modified = {2013-01-01 16:16:49 +0000},
	Issn = {0039-3215},
	Issue = {2},
	Journal = {Studia Logica},
	Keyword = {Humanities, Social Sciences and Law},
	Note = {10.1023/A:1005214714620},
	Pages = {223-243},
	Publisher = {Springer Netherlands},
	Title = {Definability of Leibniz Equality},
	Url = {http://dx.doi.org/10.1023/A:1005214714620},
	Volume = {63},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1005214714620}}

@inproceedings{Atkey09,
	Acmid = {1596644},
	Address = {New York, NY, USA},
	Author = {Atkey, Robert and Lindley, Sam and Yallop, Jeremy},
	Booktitle = {Proceedings of the 2nd ACM SIGPLAN symposium on Haskell},
	Date-Added = {2012-12-31 04:06:15 +0000},
	Date-Modified = {2012-12-31 04:06:16 +0000},
	Doi = {10.1145/1596638.1596644},
	Isbn = {978-1-60558-508-6},
	Keywords = {domain-specific languages, higher-order abstract syntax, type classes, unembedding},
	Location = {Edinburgh, Scotland},
	Numpages = {12},
	Pages = {37--48},
	Publisher = {ACM},
	Series = {Haskell '09},
	Title = {Unembedding domain-specific languages},
	Url = {http://doi.acm.org/10.1145/1596638.1596644},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1596638.1596644},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1596638.1596644}}

@inproceedings{Chlipala08,
	Acmid = {1411226},
	Address = {New York, NY, USA},
	Author = {Chlipala, Adam},
	Booktitle = {Proceedings of the 13th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-12-31 04:05:51 +0000},
	Date-Modified = {2012-12-31 04:05:53 +0000},
	Doi = {10.1145/1411204.1411226},
	Isbn = {978-1-59593-919-7},
	Keywords = {compiler verification, dependent types, interactive proof assistants, type-theoretic semantics},
	Location = {Victoria, BC, Canada},
	Numpages = {14},
	Pages = {143--156},
	Publisher = {ACM},
	Series = {ICFP '08},
	Title = {Parametric higher-order abstract syntax for mechanized semantics},
	Url = {http://doi.acm.org/10.1145/1411204.1411226},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1411204.1411226},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1411204.1411226}}

@inproceedings{odersky-zenger:fool05,
	Author = {Martin Odersky and Matthias Zenger},
	Booktitle = {FOOL},
	Date-Added = {2012-12-12 13:27:50 +0000},
	Date-Modified = {2012-12-12 23:10:06 +0000},
	Nomonth = jan,
	Nonote = {\url{http://homepages.inf.ed.ac.uk/wadler/fool}},
	Nourl = {http://lampwww.epfl.ch/~odersky/papers/ExpressionProblem.html},
	Read = {1},
	Title = {Independently Extensible Solutions to the Expression Problem},
	Year = 2005,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QiC4uLy4uLy4uL0Ryb3Bib3gvUGFwZXJzL1Byb2dyYW1taW5nIExhbmd1YWdlcy9TY2FsYS9JbmRlcGVuZGVudGx5IEV4dGVuc2libGUgU29sdXRpb25zIHRvIHRoZSBFeHByZXNzaW9uIFByb2JsZW0gLSBleHByZXNzaW9uUHJvYmxlbS5wZGbSFwsYGVdOUy5kYXRhTxECtgAAAAACtgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzpe500grAAAAFi24H0luZGVwZW5kZW50bHkgRXh0ZW5zIzE2MkRDNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAWLcTM7kSdAAAAAAAAAAAAAwAFAAAJIAAAAAAAAAAAAAAAAAAAAAVTY2FsYQAAEAAIAADOl6vDAAAAEQAIAADM7jaNAAAAAQAYABYtuAAWJ4gAFiZ7ABYh+wANl58AAmSOAAIAbk1hY2ludG9zaCBIRDpVc2VyczoAcGdpYXJydXNzbzoARHJvcGJveDoAUGFwZXJzOgBQcm9ncmFtbWluZyBMYW5ndWFnZXM6AFNjYWxhOgBJbmRlcGVuZGVudGx5IEV4dGVucyMxNjJEQzQucGRmAA4AqgBUAEkAbgBkAGUAcABlAG4AZABlAG4AdABsAHkAIABFAHgAdABlAG4AcwBpAGIAbABlACAAUwBvAGwAdQB0AGkAbwBuAHMAIAB0AG8AIAB0AGgAZQAgAEUAeABwAHIAZQBzAHMAaQBvAG4AIABQAHIAbwBiAGwAZQBtACAALQAgAGUAeABwAHIAZQBzAHMAaQBvAG4AUAByAG8AYgBsAGUAbQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAkFVzZXJzL3BnaWFycnVzc28vRHJvcGJveC9QYXBlcnMvUHJvZ3JhbW1pbmcgTGFuZ3VhZ2VzL1NjYWxhL0luZGVwZW5kZW50bHkgRXh0ZW5zaWJsZSBTb2x1dGlvbnMgdG8gdGhlIEV4cHJlc3Npb24gUHJvYmxlbSAtIGV4cHJlc3Npb25Qcm9ibGVtLnBkZgATAAEvAAAVAAIAEf//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOARkBHgEmA+AD4gPnA/ID+wQJBA0EFAQdBCIELwQyBEQERwRMAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAABE4=}}

@inproceedings{Lindley12EmbeddingF,
	Acmid = {2364402},
	Address = {New York, NY, USA},
	Author = {Lindley, Sam},
	Booktitle = {Proceedings of the 8th ACM SIGPLAN workshop on Generic programming},
	Date-Added = {2012-12-10 19:31:29 +0000},
	Date-Modified = {2012-12-10 19:31:38 +0000},
	Doi = {10.1145/2364394.2364402},
	Isbn = {978-1-4503-1576-0},
	Keywords = {domain specific languages, haskell, higher-order abstract syntax, ocaml, polymorphism},
	Location = {Copenhagen, Denmark},
	Numpages = {12},
	Pages = {45--56},
	Publisher = {ACM},
	Series = {WGP '12},
	Title = {Embedding F},
	Url = {http://doi.acm.org/10.1145/2364394.2364402},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2364394.2364402},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2364394.2364402}}

@incollection{Coquand85,
	Affiliation = {Domaine de Voluceau INRIA 78150 Rocquencourt France 78150 Rocquencourt France},
	Author = {Coquand, Thierry and Huet, G{\'e}rard},
	Booktitle = {EUROCAL '85},
	Date-Added = {2012-10-18 19:41:48 +0200},
	Date-Modified = {2012-10-18 19:41:50 +0200},
	Editor = {Buchberger, Bruno},
	Isbn = {978-3-540-15983-4},
	Keyword = {Computer Science},
	Note = {10.1007/3-540-15983-5_13},
	Pages = {151-184},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Constructions: A higher order proof system for mechanizing mathematics},
	Url = {http://dx.doi.org/10.1007/3-540-15983-5_13},
	Volume = {203},
	Year = {1985},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-15983-5_13}}

@inproceedings{Smaragdakis:1997:DTL,
	Acmid = {1267970},
	Author = {Smaragdakis, Yannis and Batory, Don},
	Booktitle = {Proceedings of the Conference on Domain-Specific Languages on Conference on Domain-Specific Languages (DSL), 1997},
	Date-Added = {2012-08-01 22:08:11 +0200},
	Date-Modified = {2013-05-13 09:15:09 +0000},
	Keywords = {data structures},
	Location = {Santa Barbara, California},
	Noaddress = {Berkeley, CA, USA},
	Numpages = {1},
	Pages = {20--20},
	Publisher = {USENIX Association},
	Series = {DSL'97},
	Title = {DiSTiL: a transformation library for data structures},
	Url = {http://dl.acm.org/citation.cfm?id=1267950.1267970},
	Year = {1997},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1267950.1267970}}

@inproceedings{Chambers10,
	Acmid = {1806638},
	Author = {Chambers, Craig and Raniwala, Ashish and Perry, Frances and Adams, Stephen and Henry, Robert R. and Bradshaw, Robert and Weizenbaum, Nathan},
	Booktitle = pldi,
	Date-Added = {2012-07-30 14:49:22 +0200},
	Date-Modified = {2012-08-07 16:44:46 +0200},
	Keywords = {data-parallel programming, java, mapreduce},
	Location = {Toronto, Ontario, Canada},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1806596.1806638},
	Noisbn = {978-1-4503-0019-3},
	Noseries = {PLDI '10},
	Nourl = {http://doi.acm.org/10.1145/1806596.1806638},
	Numpages = {13},
	Pages = {363--375},
	Publisher = acm,
	Title = {{FlumeJava}: easy, efficient data-parallel pipelines},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1806596.1806638},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1806596.1806638}}

@inproceedings{Yu08,
	Acmid = {1855742},
	Author = {Yu, Yuan and Isard, Michael and Fetterly, Dennis and Budiu, Mihai and Erlingsson, \'{U}lfar and Gunda, Pradeep Kumar and Currey, Jon},
	Booktitle = {Proc. Conf. Operating systems design and implementation},
	Date-Added = {2012-07-09 15:17:25 +0200},
	Date-Modified = {2012-07-09 15:21:47 +0200},
	Location = {San Diego, California},
	Noaddress = {Berkeley, CA, USA},
	Nourl = {http://dl.acm.org/citation.cfm?id=1855741.1855742},
	Numpages = {14},
	Pages = {1--14},
	Publisher = {USENIX Association},
	Series = {OSDI'08},
	Title = {{DryadLINQ}: a system for general-purpose distributed data-parallel computing using a high-level language},
	Year = {2008},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1855741.1855742}}

@inproceedings{AOP,
	Author = {Gregor Kiczales and John Lamping and Anurag Menhdhekar and Chris Maeda and Cristina Lopes and Jean-Marc Loingtier and John Irwin},
	Authorshort = {Gregor Kiczales and others},
	Booktitle = ECOOP,
	Date-Added = {2012-07-06 16:02:53 +0200},
	Date-Modified = {2012-07-09 15:20:52 +0200},
	Noaddress = SpringerAddr,
	Noeditor = {Mehmet Aksit and Satoshi Matsuoka},
	Noisbn = {3-540-63089-9},
	Nomonth = jul,
	Nopublisher = Springer,
	Noseries = LNCS,
	Novolume = {1241},
	Pages = {220--242},
	Title = {Aspect-Oriented Programming},
	Year = 1997}

@incollection{Sorensen94,
	Abstract = {We study four transformation methodologies which are automatic instances of Burstall and Darlington's fold/unfold framework: partial evaluation, deforestation, supercompilation , and generalized partial computation (GPC) . One can classify these and other fold/unfold based transformers by how much information they maintain during transformation.},
	Affiliation = {University of Copenhagen DIKU, Department of Computer Science Universitetsparken 1 DK-2100 Copenhagen {\O} Denmark Universitetsparken 1 DK-2100 Copenhagen {\O} Denmark},
	Author = {S{\o}rensen, Morten and Gl{\"u}ck, Robert and Jones, Neil},
	Booktitle = {Programming Languages and Systems --- ESOP '94},
	Date-Added = {2012-07-03 14:58:26 +0200},
	Date-Modified = {2014-02-08 19:57:31 +0000},
	Editor = {Sannella, Donald},
	Isbn = {978-3-540-57880-2},
	Keyword = {Computer Science},
	Keywords = {partial evaluation},
	Note = {10.1007/3-540-57880-3_32},
	Pages = {485-500},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Towards unifying partial evaluation, deforestation, supercompilation, and GPC},
	Url = {http://dx.doi.org/10.1007/3-540-57880-3_32},
	Volume = {788},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-57880-3_32}}

@inproceedings{danvy99type-directed,
	Author = {Danvy, Olivier},
	Booktitle = {Partial Evaluation - Practice and Theory, DIKU 1998 International Summer School},
	Date-Added = {2012-06-29 16:17:18 +0200},
	Date-Modified = {2012-06-29 16:17:18 +0200},
	Noaddress = London,
	Pages = {367--411},
	Publisher = Springer,
	Title = {Type-Directed Partial Evaluation},
	Url = {http://cs.au.dk/~danvy/tdpe-ln.pdf},
	Year = {1999},
	Bdsk-Url-1 = {http://cs.au.dk/~danvy/tdpe-ln.pdf}}

@inproceedings{Chapman10,
	Acmid = {1863547},
	Author = {Chapman, James and Dagand, Pierre-\'{E}variste and McBride, Conor and Morris, Peter},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-27 14:52:40 +0200},
	Date-Modified = {2013-05-13 09:15:20 +0000},
	Doi = {10.1145/1863543.1863547},
	Isbn = {978-1-60558-794-3},
	Keywords = {data structures, metaprogramming, monads, proof assistants, type systems},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Numpages = {12},
	Pages = {3--14},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {The gentle art of levitation},
	Url = {http://doi.acm.org/10.1145/1863543.1863547},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863547},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863547}}

@inproceedings{Blelloch:2010:FPA:1863543.1863579,
	Acmid = {1863579},
	Author = {Blelloch, Guy E.},
	Booktitle = {Proceedings of the 15th ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-27 14:23:38 +0200},
	Date-Modified = {2012-06-27 14:23:38 +0200},
	Doi = {10.1145/1863543.1863579},
	Isbn = {978-1-60558-794-3},
	Keywords = {functional programming, parallel algorithms},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Numpages = {1},
	Pages = {247--247},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {Functional parallel algorithms},
	Url = {http://doi.acm.org/10.1145/1863543.1863579},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863579},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1863543.1863579}}

@inproceedings{Blelloch96a,
	Acmid = {232650},
	Author = {Blelloch, Guy E. and Greiner, John},
	Booktitle = {Proceedings of the first ACM SIGPLAN international conference on Functional programming},
	Date-Added = {2012-06-23 14:32:17 +0200},
	Date-Modified = {2012-06-23 14:32:20 +0200},
	Doi = {10.1145/232627.232650},
	Isbn = {0-89791-770-7},
	Location = {Philadelphia, Pennsylvania, United States},
	Noaddress = {New York, NY, USA},
	Numpages = {13},
	Pages = {213--225},
	Publisher = acm,
	Series = {ICFP '96},
	Title = {A provable time and space efficient implementation of NESL},
	Url = {http://doi.acm.org/10.1145/232627.232650},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/232627.232650},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/232627.232650}}

@incollection{Chakravarty01Nepal,
	Abstract = {This paper discusses an extension of Haskell by support for nested data-parallel programming in the style of the special-purpose language Nesl . The extension consists of a parallel array type, array comprehensions, and primitive parallel array operations. This extension brings a hitherto unsupported style of parallel programming to Haskell. Moreover, nested data parallelism should receive wider attention when available in a standardised language like Haskell.},
	Affiliation = {University of New South Wales Australia},
	Author = {Chakravarty, Manuel and Keller, Gabriele and Lechtchinsky, Roman and Pfannenstiel, Wolf},
	Booktitle = {Euro-Par 2001 Parallel Processing},
	Date-Added = {2012-06-23 14:19:28 +0200},
	Date-Modified = {2012-06-23 14:20:04 +0200},
	Editor = {Sakellariou, Rizos and Gurd, John and Freeman, Len and Keane, John},
	Isbn = {978-3-540-42495-6},
	Keyword = {Computer Science},
	Keywords = {nested data parallelism, Haskell},
	Note = {10.1007/3-540-44681-8_76},
	Pages = {524-534},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Nepal --- Nested Data Parallelism in Haskell},
	Url = {http://dx.doi.org/10.1007/3-540-44681-8_76},
	Volume = {2150},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-44681-8_76}}

@article{Blelloch90,
	Abstract = {This paper introduces techniques for compiling the nested parallelism of collection-oriented languages onto existing parallel hardware. Programmers of parallel machines encounter nested parallelism whenever they write a routine that performs parallel operations, and then want to call that routine itself in parallel. This occurs naturally in many applications. Most parallel systems, however, do not permit the expression of nested parallelism. This forces the programmer to exploit only one level of parallelism or to implement nested parallelism themselves. Both of these alternatives tend to produce code that is harder to maintain and less modular than code described at a higher level with nested parallel constructs. Not permitting the expression of nested parallelism is analogous to not permitting nested loops in serial languages. This paper describes issues and techniques for taking high-level descriptions of parallelism in the form of operations on nested collections and automatically translating them into flat, single-level parallelism. A compiler that translates a subset of a collection-oriented language,Paralation Lisp, into the instruction set of a flat virtual machine is presented. The instructions of the virtual machine are simple instructions on vectors of atomic values, and can be implemented on a broad class of target architectures, including vector machines, single-instruction parallel machines, and multiple-instruction parallel machines. We have implemented the instructions on the Connection Machine computer (CM-2), a massively parallel, single-instruction computer. As an illustration of the compiler techniques, the paper presents a quicksort example. The example has been tested on the CM-2. The speed of the compiled sort is only a factor of 3 slower than that of the fastest CM-2 sort.},
	Author = {Guy E. Blelloch and Gary W. Sabot},
	Date-Added = {2012-06-23 14:14:27 +0200},
	Date-Modified = {2012-06-23 14:21:33 +0200},
	Doi = {10.1016/0743-7315(90)90087-6},
	Issn = {0743-7315},
	Journal = {Journal of Parallel and Distributed Computing},
	Keywords = {nested data parallelism; parallel programming},
	Number = {2},
	Pages = {119 - 134},
	Title = {Compiling collection-oriented languages onto massively parallel computers},
	Url = {http://www.sciencedirect.com/science/article/pii/0743731590900876},
	Volume = {8},
	Year = {1990},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0743731590900876},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0743-7315(90)90087-6}}

@inproceedings{Kienzle06AopMakesSense,
	Author = {Kienzle, J{\"o}rg and Guerraoui, Rachid},
	Booktitle = ecoop,
	Date-Added = {2012-06-23 14:13:25 +0200},
	Date-Modified = {2012-06-23 14:13:25 +0200},
	Editor = {Magnusson, Boris},
	Pages = {113-121},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {AOP: Does It Make Sense? The Case of Concurrency and Failures},
	Url = {http://dx.doi.org/10.1007/3-540-47993-7_2},
	Volume = {2374},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-47993-7_2}}

@article{Blelloch96,
	Acmid = {227246},
	Author = {Blelloch, Guy E.},
	Date-Added = {2012-06-22 07:08:26 +0200},
	Date-Modified = {2012-06-23 14:21:33 +0200},
	Doi = {10.1145/227234.227246},
	Issn = {0001-0782},
	Issue_Date = {March 1996},
	Journal = {Commun. ACM},
	Keywords = {nested data parallelism; parallel programming},
	Noaddress = {New York, NY, USA},
	Nomonth = mar,
	Number = {3},
	Numpages = {13},
	Pages = {85--97},
	Publisher = acm,
	Title = {Programming parallel algorithms},
	Url = {http://doi.acm.org/10.1145/227234.227246},
	Volume = {39},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/227234.227246},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/227234.227246}}

@incollection{Keller96FlatteningNesl,
	Affiliation = {Technische Universit{\"a}t Berlin Forschungsgruppe Softwaretechnik (FR5-6) Franklinstr. 28/29 D-10587 Berlin Franklinstr. 28/29 D-10587 Berlin},
	Author = {Keller, Gabriele and Simons, Martin},
	Booktitle = {Concurrency and Parallelism, Programming, Networking, and Security},
	Date-Added = {2012-06-22 06:56:59 +0200},
	Date-Modified = {2012-06-23 14:24:26 +0200},
	Editor = {Jaffar, Joxan and Yap, Roland},
	Isbn = {978-3-540-62031-0},
	Keyword = {Computer Science},
	Keywords = {nested data parallelism},
	Note = {10.1007/BFb0027796},
	Pages = {234-243},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {A calculational approach to flattening nested data parallelism in functional languages},
	Url = {http://dx.doi.org/10.1007/BFb0027796},
	Volume = {1179},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/BFb0027796}}

@inproceedings{Odersky01coloredLocal,
	Author = {Martin Odersky and Matthias Zenger and Christoph Zenger},
	Booktitle = {Proc. ACM Symposium on Principles of Programming Languages},
	Date-Added = {2012-04-20 17:27:39 +0200},
	Date-Modified = {2012-04-20 17:28:07 +0200},
	Pages = {41-53},
	Title = {Colored Local Type Inference},
	Year = 2001}

@inproceedings{hofer08polymorphic,
	Author = {Christian Hofer and Klaus Ostermann and Tillmann Rendel and Adriaan Moors},
	Booktitle = gpce,
	Date-Added = {2012-04-14 09:25:19 +0200},
	Date-Modified = {2012-06-23 14:26:16 +0200},
	Keywords = {DSEL},
	Noseries = {GPCE'08},
	Nourl = {http://www.daimi.au.dk/~ko/papers/gpce50_hofer.pdf},
	Pages = {137--148},
	Publisher = acm,
	Title = {Polymorphic Embedding of {DSLs}},
	Year = {2008},
	Bdsk-Url-1 = {http://www.daimi.au.dk/~ko/papers/gpce50_hofer.pdf}}

@book{Pierce02TAPL,
	Abstract = {{A type system is a syntactic method for automatically checking the absence of certain erroneous behaviors by classifying program phrases according to the kinds of values they compute. The study of type systems--and of programming languages from a type-theoretic perspective-has important applications in software engineering, language design, high-performance compilers, and security.<br /> <br /> This text provides a comprehensive introduction both to type systems in computer science and to the basic theory of programming languages. The approach is pragmatic and operational; each new concept is motivated by programming examples and the more theoretical sections are driven by the needs of implementations. Each chapter is accompanied by numerous exercises and solutions, as well as a running implementation, available via the Web. Dependencies between chapters are explicitly identified, allowing readers to choose a variety of paths through the material.<br /> <br /> The core topics include the untyped lambda-calculus, simple type systems, type reconstruction, universal and existential polymorphism, subtyping, bounded quantification, recursive types, kinds, and type operators. Extended case studies develop a variety of approaches to modeling the features of object-oriented languages.}},
	Author = {Pierce, Benjamin C.},
	Citeulike-Article-Id = {105547},
	Citeulike-Linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0262162091},
	Citeulike-Linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0262162091},
	Citeulike-Linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0262162091},
	Citeulike-Linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262162091},
	Citeulike-Linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262162091/citeulike00-21},
	Citeulike-Linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262162091},
	Citeulike-Linkout-6 = {http://www.worldcat.org/isbn/0262162091},
	Citeulike-Linkout-7 = {http://books.google.com/books?vid=ISBN0262162091},
	Citeulike-Linkout-8 = {http://www.amazon.com/gp/search?keywords=0262162091&index=books&linkCode=qs},
	Citeulike-Linkout-9 = {http://www.librarything.com/isbn/0262162091},
	Date-Added = {2012-04-14 05:21:23 +0200},
	Date-Modified = {2012-04-14 05:24:09 +0200},
	Day = {01},
	Edition = {1st},
	Howpublished = {Hardcover},
	Keywords = {getting-started, type-theory},
	Noisbn = {0262162091},
	Nomonth = feb,
	Posted-At = {2008-02-26 22:26:29},
	Priority = {0},
	Publisher = {MIT Press},
	Title = {{Types and Programming Languages}},
	Year = {2002},
	Bdsk-Url-1 = {http://www.worldcat.org/isbn/0262162091}}

@article{carette09finally,
	Author = {Carette, Jacques and Kiselyov, Oleg and Shan, Chung-chieh},
	Date-Added = {2012-04-14 00:18:13 +0200},
	Date-Modified = {2012-06-23 14:23:18 +0200},
	Issue = {5},
	Journal = JFP,
	Keywords = {DSEL},
	Noaddress = NewYork,
	Nomonth = {September},
	Nopublisher = Cambridge,
	Pages = {509--543},
	Title = {Finally Tagless, Partially Evaluated: Tagless Staged Interpreters for Simpler Typed Languages},
	Volume = {19},
	Year = {2009},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?id=1630623.1630626}}

@inproceedings{Peyton-Jones01playingby,
	Author = {Peyton Jones, Simon L. and Andrew Tolmach and Tony Hoare},
	Booktitle = {Proc. Haskell Workshop},
	Date-Added = {2012-04-13 12:22:53 +0200},
	Date-Modified = {2014-02-09 22:53:59 +0000},
	Editor = {Ralf Hinze},
	Keywords = {optimization},
	Pages = {203-233},
	Title = {Playing by the rules: rewriting as a practical optimisation technique in {GHC}},
	Year = {2001}}

@inproceedings{Gill93shortcut,
	Acmid = {165214},
	Author = {Gill, Andrew and Launchbury, John and Peyton Jones, Simon L.},
	Booktitle = fpca,
	Date-Added = {2012-04-11 23:10:44 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {optimization},
	Location = {Copenhagen, Denmark},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/165180.165214},
	Noisbn = {0-89791-595-X},
	Noseries = {FPCA '93},
	Nourl = {http://doi.acm.org/10.1145/165180.165214},
	Numpages = {10},
	Pages = {223--232},
	Publisher = acm,
	Title = {A short cut to deforestation},
	Year = {1993},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/165180.165214},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/165180.165214}}

@article{Wadler90deforest,
	Author = {Wadler, Philip},
	Date-Added = {2012-04-11 23:06:54 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Issue_Date = {June 22, 1990},
	Journal = tcs,
	Keywords = {optimization},
	Noaddress = elsevieraddr,
	Nodoi = {10.1016/0304-3975(90)90147-A},
	Noissn = {0304-3975},
	Nomonth = jun,
	Nourl = {http://dx.doi.org/10.1016/0304-3975(90)90147-A},
	Number = {2},
	Numpages = {18},
	Pages = {231--248},
	Publisher = elsevier,
	Title = {Deforestation: transforming programs to eliminate trees},
	Volume = {73},
	Year = {1990},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/0304-3975(90)90147-A}}

@inproceedings{Coutts07stream,
	Acmid = {1291199},
	Author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
	Booktitle = icfp,
	Date-Added = {2012-04-11 23:01:07 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {deforestation, functional programming, program fusion, program transformation; optimization},
	Location = {Freiburg, Germany},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1291151.1291199},
	Noisbn = {978-1-59593-815-2},
	Nourl = {http://doi.acm.org/10.1145/1291151.1291199},
	Numpages = {12},
	Pages = {315--326},
	Publisher = acm,
	Series = {ICFP '07},
	Title = {Stream fusion: from lists to streams to nothing at all},
	Year = {2007},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1291151.1291199},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1291151.1291199}}

@inproceedings{mitchell10rethinking,
	Acmid = {1863588},
	Author = {Mitchell, Neil},
	Booktitle = icfp,
	Date-Added = {2012-04-11 14:40:35 +0200},
	Date-Modified = {2012-06-23 14:26:52 +0200},
	Keywords = {haskell, optimization, supercompilation},
	Location = {Baltimore, Maryland, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/1863543.1863588},
	Noisbn = {978-1-60558-794-3},
	Nourl = {http://doi.acm.org/10.1145/1863543.1863588},
	Numpages = {12},
	Pages = {309--320},
	Prg = {2011-02-09, Paolo},
	Publisher = acm,
	Series = {ICFP '10},
	Title = {Rethinking Supercompilation},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1863543.1863588}}

@misc{OderskyPimpLib,
	Author = {Martin Odersky},
	Date-Added = {2012-04-10 19:04:50 +0200},
	Date-Modified = {2012-04-10 19:14:33 +0200},
	Note = {Last accessed on 10 April 2012},
	Title = {Pimp my Library},
	Url = {http://www.artima.com/weblogs/viewpost.jsp?thread=179766},
	Urldate = {9 October, 2006},
	Year = {2006},
	Bdsk-Url-1 = {http://www.artima.com/weblogs/viewpost.jsp?thread=179766}}

@article{Steele99Growing,
	Author = {Steele, Guy L.},
	Date-Added = {2012-04-03 07:32:20 +0200},
	Date-Modified = {2012-06-23 14:23:39 +0200},
	Issue = {3},
	Journal = hosc,
	Keyword = {Computer Science},
	Keywords = {DSEL},
	Noissn = {1388-3690},
	Nonote = {10.1023/A:1010085415024},
	Nourl = {http://dx.doi.org/10.1023/A:1010085415024},
	Pages = {221-236},
	Publisher = {Springer Netherlands},
	Title = {Growing a Language},
	Volume = {12},
	Year = {1999},
	Bdsk-Url-1 = {http://dx.doi.org/10.1023/A:1010085415024}}

@inproceedings{Pfenning88,
	Acmid = {62697},
	Author = {Pfenning, Frank},
	Booktitle = lfp,
	Date-Added = {2012-04-03 07:23:20 +0200},
	Date-Modified = {2012-04-03 07:23:23 +0200},
	Location = {Snowbird, Utah, United States},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/62678.62697},
	Noisbn = {0-89791-273-X},
	Nourl = {http://doi.acm.org/10.1145/62678.62697},
	Numpages = {11},
	Pages = {153--163},
	Publisher = acm,
	Series = {LFP '88},
	Title = {Partial polymorphic type inference and higher-order unification},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/62678.62697},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/62678.62697}}

@incollection{Filinski01NormByEval,
	Abstract = {We show how a simple semantic characterization of normalization by evaluation for the λ βη -calculus can be extended to a similar construction for normalization of terms in the computational λ-calculus. Specifically, we show that a suitable residualizing interpretation of base types, constants, and computational effects allows us to extract a syntactic normal form from a term's denotation. The required interpretation can itself be constructed as the meaning of a suitable functional program in an ML-like language, leading directly to a practical normalization algorithm. The results extend easily to product and sum types, and can be seen as a formal basis for call-by-value type-directed partial evaluation.},
	Affiliation = {University of Aarhus BRICS, Department of Computer Science Aarhus},
	Author = {Filinski, Andrzej},
	Booktitle = {Typed Lambda Calculi and Applications},
	Date-Added = {2012-04-01 23:07:33 +0200},
	Date-Modified = {2012-04-01 23:08:32 +0200},
	Editor = {Abramsky, Samson},
	Keyword = {Computer Science},
	Noisbn = {978-3-540-41960-0},
	Nonote = {10.1007/3-540-45413-6\_15},
	Nourl = {http://dx.doi.org/10.1007/3-540-45413-6_15},
	Pages = {151-165},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Normalization by Evaluation for the Computational Lambda-Calculus},
	Volume = {2044},
	Year = {2001},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-45413-6_15}}

@inproceedings{Berger91NormByEval,
	Abstract = {A functional p rarr;e (procedure rarr;expression) that inverts the evaluation functional for typed lambda;-terms in any model of typed lambda;-calculus containing some basic arithmetic is defined. Combined with the evaluation functional, p rarr;e yields an efficient normalization algorithm. The method is extended to lambda;-calculi with constants and is used to normalize (the lambda;-representations of) natural deduction proofs of (higher order) arithmetic. A consequence of theoretical interest is a strong completeness theorem for beta; eta;-reduction. If two lambda;-terms have the same value in some model containing representations of the primitive recursive functions (of level 1) then they are probably equal in the beta; eta;-calculus },
	Author = {Berger, U. and Schwichtenberg, H.},
	Booktitle = {Proc. Symposium on Logic in Computer Science, 1991. LICS '91., Proceedings of Sixth Annual IEEE Symposium on},
	Date-Added = {2012-03-29 13:04:39 +0200},
	Date-Modified = {2012-06-23 14:20:23 +0200},
	Keywords = {lambda-calculi;completeness theorem;constants;evaluation functional;inverse;natural deduction proofs;normalization algorithm;recursive functions;typed lambda-calculus;typed lambda-terms;formal logic;},
	Nodoi = {10.1109/LICS.1991.151645},
	Nomonth = {july},
	Pages = {203 -211},
	Series = {LICS '91},
	Title = {An inverse of the evaluation functional for typed $\lambda$-calculus},
	Year = {1991},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LICS.1991.151645}}

@incollection{Berger98NormByEval,
	Abstract = {We extend normalization by evaluation (first presented in [ 4 ]) from the pure typed λ-calculus to general higher type term rewrite systems. This work also gives a theoretical explanation of the normalization algorithm implemented in the Minlog system},
	Affiliation = {Mathematisches Institut der Universit{\"a}t M{\"u}nchen Germany},
	Author = {Berger, Ulrich and Eberl, Matthias and Schwichtenberg, Helmut},
	Booktitle = {Prospects for Hardware Foundations},
	Date-Added = {2012-03-29 09:52:55 +0200},
	Date-Modified = {2012-03-29 09:53:26 +0200},
	Editor = {M{\"o}ller, Bernhard and Tucker, John},
	Keyword = {Computer Science},
	Noisbn = {978-3-540-65461-2},
	Nonote = {10.1007/3-540-49254-2\_4},
	Nourl = {http://dx.doi.org/10.1007/3-540-49254-2_4},
	Pages = {624-624},
	Publisher = {Springer Berlin / Heidelberg},
	Series = {Lecture Notes in Computer Science},
	Title = {Normalization by Evaluation},
	Volume = {1546},
	Year = {1998},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-49254-2_4}}

@inproceedings{Rompf11BBlocks,
	Author = {Rompf, Tiark and Sujeeth, Arvind K. and Lee, HyoukJoong and Brown, Kevin J. and Chafi, Hassan and Odersky, Martin and Olukotun, Kunle},
	Booktitle = dsl,
	Date-Added = {2012-03-28 15:11:14 +0200},
	Date-Modified = {2012-06-23 14:28:22 +0200},
	Keywords = {DSEL; optimization; multi-stage programming},
	Nodoi = {10.4204/EPTCS.66.5},
	Noeditor = {Danvy, Olivier and Shan, Chung-chieh},
	Nopublisher = {Open Publishing Association},
	Noseries = {EPTCS},
	Novolume = {66},
	Pages = {93-117},
	Title = {Building-Blocks for Performance Oriented {DSLs}},
	Year = {2011},
	Bdsk-Url-1 = {http://dx.doi.org/10.4204/EPTCS.66.5}}

@incollection{Emir07Patterns,
	Abstract = {Data in object-oriented programming is organized in a hierarchy of classes. The problem of object-oriented pattern matching is how to explore this hierarchy from the outside. This usually involves classifying objects by their run-time type, accessing their members, or determining some other characteristic of a group of objects. In this paper we compare six different pattern matching techniques: object-oriented decomposition, visitors, type-tests/type-casts, typecase, case classes, and extractors. The techniques are compared on nine criteria related to conciseness, maintainability and performance. The paper introduces case classes and extractors as two new pattern-matching methods and shows that their combination works well for all of the established criteria.},
	Address = springeraddr,
	Affiliation = {EPFL, 1015 Lausanne Switzerland},
	Author = {Emir, Burak and Odersky, Martin and Williams, John},
	Booktitle = ecoop,
	Date-Added = {2012-03-27 11:24:20 +0200},
	Date-Modified = {2012-03-27 11:25:17 +0200},
	Keyword = {Computer Science},
	Noeditor = {Ernst, Erik},
	Noisbn = {978-3-540-73588-5},
	Nonote = {10.1007/978-3-540-73589-2\_14},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-540-73589-2_14},
	Novolume = {4609},
	Pages = {273-298},
	Publisher = springer,
	Read = {1},
	Title = {Matching Objects with Patterns},
	Year = {2007},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/978-3-540-73589-2_14}}

@incollection{Hajiyev06CodeQuest,
	Abstract = {Source code querying tools allow programmers to explore relations between different parts of the code base. This paper describes such a tool, named codeQuest. It combines two previous proposals, namely the use of logic programming and database systems. As the query language we use safe Datalog , which was originally introduced in the theory of databases. That provides just the right level of expressiveness; in particular recursion is indispensable for source code queries. Safe Datalog is like Prolog, but all queries are guaranteed to terminate, and there is no need for extra-logical annotations. Our implementation of Datalog maps queries to a relational database system. We are thus able to capitalise on the query optimiser provided by such a system. For recursive queries we implement our own optimisations in the translation from Datalog to SQL. Experiments confirm that this strategy yields an efficient, scalable code querying system.},
	Address = springeraddr,
	Affiliation = {Programming Tools Group, Oxford University Computing Laboratory, Wolfson Building, Parks Road, Oxford, OX1 3QD UK},
	Author = {Hajiyev, Elnar and Verbaere, Mathieu and de Moor, Oege},
	Booktitle = ecoop,
	Date-Added = {2012-03-26 20:20:46 +0200},
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Keyword = {Computer Science},
	Keywords = {query constructs},
	Noeditor = {Thomas, Dave},
	Noisbn = {978-3-540-35726-1},
	Nonote = {10.1007/11785477\_2},
	Noseries = lncs,
	Nourl = {http://dx.doi.org/10.1007/11785477_2},
	Novolume = {4067},
	Pages = {2-27},
	Publisher = springerbase,
	Title = {\emph{CodeQuest}: Scalable Source Code Queries with {Datalog}},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/11785477_2}}

@inproceedings{Chafi10LangVirt,
	Acmid = {1869527},
	Author = {Chafi, Hassan and DeVito, Zach and Moors, Adriaan and Rompf, Tiark and Sujeeth, Arvind K. and Hanrahan, Pat and Odersky, Martin and Olukotun, Kunle},
	Booktitle = oopslacomp,
	Date-Added = {2012-03-26 02:48:39 +0200},
	Date-Modified = {2012-03-30 21:34:13 +0200},
	Keywords = {domain specific languages, dynamic optimizations, parallel programming},
	Location = {Reno/Tahoe, Nevada, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1869459.1869527},
	Noisbn = {978-1-4503-0203-6},
	Nourl = {http://doi.acm.org/10.1145/1869459.1869527},
	Numpages = {13},
	Pages = {835--847},
	Publisher = acm,
	Series = {OOPSLA '10},
	Title = {Language virtualization for heterogeneous parallel computing},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1869459.1869527},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1869459.1869527}}

@misc{Moors10TCP,
	Author = {Adriaan Moors},
	Date-Added = {2012-03-25 21:10:39 +0200},
	Date-Modified = {2012-04-11 22:19:53 +0200},
	Note = {Last accessed on 2012-04-11},
	Title = {Type Constructor Polymorphism},
	Url = {http://adriaanm.github.com/research/2010/10/06/new-in-scala-2.8-type-constructor-inference/},
	Year = {2010},
	Bdsk-Url-1 = {http://adriaanm.github.com/research/2010/10/06/new-in-scala-2.8-type-constructor-inference/}}

@misc{ScalaRef,
	Author = {Martin Odersky},
	Date-Added = {2012-03-24 03:02:58 +0100},
	Date-Modified = {2012-03-25 21:16:03 +0200},
	Nomonth = {August},
	Read = {1},
	Title = {The {Scala} Language Specification Version 2.9},
	Year = {2011}}

@inproceedings{Siek10gplml,
	Acmid = {1706358},
	Author = {Siek, Jeremy G.},
	Booktitle = pepm,
	Date-Added = {2012-03-21 17:12:35 +0100},
	Date-Modified = {2012-03-21 17:12:53 +0100},
	Keywords = {domain-specific embedded languages, metaprogramming, multi-stage programming, reflection},
	Location = {Madrid, Spain},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1706356.1706358},
	Noisbn = {978-1-60558-727-1},
	Nourl = {http://doi.acm.org/10.1145/1706356.1706358},
	Numpages = {2},
	Pages = {3},
	Publisher = acm,
	Series = {PEPM '10},
	Title = {General purpose languages should be metalanguages},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1706356.1706358},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1706356.1706358}}

@inproceedings{Pfenning88hoas,
	Acmid = {54010},
	Author = {Pfenning, F. and Elliot, C.},
	Booktitle = pldi,
	Date-Added = {2012-03-21 11:56:39 +0100},
	Date-Modified = {2012-03-21 17:35:06 +0100},
	Location = {Atlanta, Georgia, United States},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/53990.54010},
	Noisbn = {0-89791-269-1},
	Noseries = {PLDI '88},
	Nourl = {http://doi.acm.org/10.1145/53990.54010},
	Numpages = {10},
	Pages = {199--208},
	Publisher = acm,
	Title = {Higher-order abstract syntax},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/53990.54010},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/53990.54010}}

@inproceedings{Oliveira10TCOI,
	Acmid = {1869489},
	Author = {Oliveira, Bruno C.d.S. and Moors, Adriaan and Odersky, Martin},
	Booktitle = oopsla,
	Date-Added = {2012-03-20 15:42:48 +0100},
	Date-Modified = {2012-03-20 15:43:20 +0100},
	Keywords = {abstract datatypes, c++ concepts, scala, type classes},
	Location = {Reno/Tahoe, Nevada, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1869459.1869489},
	Noisbn = {978-1-4503-0203-6},
	Nourl = {http://doi.acm.org/10.1145/1869459.1869489},
	Numpages = {20},
	Pages = {341--360},
	Publisher = acm,
	Series = {OOPSLA '10},
	Title = {Type classes as objects and implicits},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1869459.1869489},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1869459.1869489}}

@inproceedings{Moors12Virtualized,
	Acmid = {2103769},
	Author = {Moors, Adriaan and Rompf, Tiark and Haller, Philipp and Odersky, Martin},
	Booktitle = {Proc.\ Workshop on Partial Evaluation and Semantics-Based Program Manipulation},
	Date-Added = {2012-03-20 14:54:14 +0100},
	Date-Modified = {2012-03-20 14:55:07 +0100},
	Keywords = {code generation, domain-specific languages, language virtualization, multi-stage programming},
	Location = {Philadelphia, Pennsylvania, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/2103746.2103769},
	Noisbn = {978-1-4503-1118-2},
	Nourl = {http://doi.acm.org/10.1145/2103746.2103769},
	Numpages = {4},
	Pages = {117--120},
	Publisher = acm,
	Series = {PEPM '12},
	Title = {Scala-virtualized},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2103746.2103769},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2103746.2103769}}

@book{Odersky11book,
	Author = {Odersky, Martin and Spoon, Lex and Venners, Bill},
	Date-Added = {2012-03-20 09:36:00 +0100},
	Date-Modified = {2012-03-20 10:02:24 +0100},
	Edition = {2nd},
	Howpublished = {Paperback},
	Keywords = {Scala},
	Noisbn = {0981531644},
	Nomonth = jan,
	Nourl = {http://www.worldcat.org/isbn/0981531644},
	Publisher = {Artima Inc},
	Title = {{Programming in Scala}},
	Year = {2011},
	Bdsk-Url-1 = {http://www.worldcat.org/isbn/0981531644}}

@inproceedings{Rothamel08generating,
	Acmid = {1449923},
	Author = {Rothamel, Tom and Liu, Yanhong A.},
	Booktitle = gpce,
	Date-Added = {2012-03-17 12:22:17 +0100},
	Date-Modified = {2013-05-13 09:14:00 +0000},
	Keywords = {automatic incrementalization, optimization, query constructs; Incremental computation},
	Location = {Nashville, TN, USA},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1449913.1449923},
	Noisbn = {978-1-60558-267-2},
	Nourl = {http://doi.acm.org/10.1145/1449913.1449923},
	Numpages = {12},
	Pages = {55--66},
	Publisher = acm,
	Series = {GPCE '08},
	Title = {Generating incremental implementations of object-set queries},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1449913.1449923},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1449913.1449923}}

@inproceedings{rompf2010lightweight,
	Acmid = {1868314},
	Author = {Rompf, Tiark and Odersky, Martin},
	Booktitle = gpce,
	Conference = {GPCE},
	Date-Added = {2012-03-17 11:20:08 +0100},
	Date-Modified = {2012-03-19 02:20:36 +0100},
	Keywords = {code generation, domain-specific languages, language virtualization, multi-stage programming},
	Location = {Eindhoven, The Netherlands},
	Noaddress = {New York, NY, USA},
	Nodoi = {http://doi.acm.org/10.1145/1868294.1868314},
	Noisbn = {978-1-4503-0154-1},
	Noseries = {GPCE '10},
	Nourl = {http://doi.acm.org/10.1145/1868294.1868314},
	Numpages = {10},
	Pages = {127--136},
	Publisher = acm,
	Title = {Lightweight modular staging: a pragmatic approach to runtime code generation and compiled {DSLs}},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1868294.1868314}}

@article{Eini11Pain,
	Acmid = {1978556},
	Author = {Eini, Oren},
	Date-Added = {2012-03-16 17:33:47 +0100},
	Date-Modified = {2012-06-23 14:27:21 +0200},
	Issue_Date = {August 2011},
	Journal = cacm,
	Keywords = {LINQ},
	Noaddress = {New York, NY, USA},
	Nodoi = {10.1145/1978542.1978556},
	Noissn = {0001-0782},
	Nomonth = aug,
	Nourl = {http://doi.acm.org/10.1145/1978542.1978556},
	Number = {8},
	Numpages = {7},
	Pages = {55--61},
	Publisher = acm,
	Title = {The pain of implementing {LINQ} providers},
	Volume = {54},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1978542.1978556},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1978542.1978556}}

@inproceedings{odersky2009fighting,
	Author = {Odersky, M. and Moors, A.},
	Booktitle = {IARCS Conf. Foundations of Software Technology and Theoretical Computer Science},
	Date-Added = {2012-03-16 17:10:11 +0100},
	Date-Modified = {2012-03-16 17:10:49 +0100},
	Pages = {427--451},
	Title = {Fighting Bit Rot with Types (Experience Report: {{Scala}} Collections)},
	Volume = {4},
	Year = {2009}}

@article{Peyton-Jones02,
	Abstract = { ABSTRACT Higher-order languages such as Haskell encourage the programmer to build abstractions by composing functions. A good compiler must inline many of these calls to recover an efficiently executable program. In principle, inlining is dead simple: just replace the call of a function by an instance of its body. But any compiler-writer will tell you that inlining is a black art, full of delicate compromises that work together to give good performance without unnecessary code bloat. The purpose of this paper is, therefore, to articulate the key lessons we learned from a full-scale ``production'' inliner, the one used in the Glasgow Haskell compiler. We focus mainly on the algorithmic aspects, but we also provide some indicative measurements to substantiate the importance of various aspects of the inliner. },
	Author = {Peyton Jones, Simon L. and Marlow, Simon},
	Date-Added = {2012-03-16 16:14:52 +0100},
	Date-Modified = {2014-02-09 22:54:25 +0000},
	Eprint = {http://journals.cambridge.org/article_S0956796802004331},
	Journal = jfp,
	Keywords = {optimization},
	Nodoi = {10.1017/S0956796802004331},
	Nourl = {http://dx.doi.org/10.1017/S0956796802004331},
	Number = {4-5},
	Pages = {393-434},
	Title = {Secrets of the {Glasgow Haskell Compiler} inliner},
	Volume = {12},
	Year = {2002},
	Bdsk-Url-1 = {http://dx.doi.org/10.1017/S0956796802004331}}

@phdthesis{chambers1992design,
	Author = {Chambers, C.},
	Date-Added = {2012-03-16 16:07:06 +0100},
	Date-Modified = {2012-03-16 16:07:25 +0100},
	School = {Stanford University},
	Title = {The design and implementation of the {Self} compiler, an optimizing compiler for object-oriented programming languages},
	Year = {1992}}

@article{kuehne06matters,
	Author = {Thomas Kuehne},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Date-Added = {2012-03-16 16:00:58 +0100},
	Date-Modified = {2012-03-16 16:00:58 +0100},
	Ee = {http://dx.doi.org/10.1007/s10270-006-0017-9},
	Journal = {Software and System Modeling},
	Nourl = {http://homepages.mcs.vuw.ac.nz/~tk/publications/papers/kuehne-matters.pdf},
	Number = {4},
	Pages = {369--385},
	Prg = {2011-08-31, Sebastian},
	Title = {Matters of (Meta-)Modeling},
	Volume = {5},
	Year = {2006},
	Bdsk-Url-1 = {http://homepages.mcs.vuw.ac.nz/~tk/publications/papers/kuehne-matters.pdf}}

@article{elliott03compiling,
	Author = {Elliott, Conal and Finne, Sigbjorn and de Moor, Oege},
	Date-Added = {2012-03-16 15:59:10 +0100},
	Date-Modified = {2012-06-23 14:23:06 +0200},
	Journal = jfp,
	Keywords = {DSEL; deep embedding},
	Nourl = {http://conal.net/papers/jfp-saig/compile-dsel.pdf},
	Number = 2,
	Pages = {455--481},
	Prg = {2011-08-24, Matteo},
	Title = {Compiling Embedded Languages},
	Volume = 13,
	Year = 2003,
	Bdsk-Url-1 = {http://conal.net/papers/jfp-saig/compile-dsel.pdf}}

@proceedings{DBLP:conf/oopsla/2003p,
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {OOPSLA},
	Editor = {Ron Crocker and Guy L. Steele Jr.},
	Noisbn = {1-58113-712-5},
	Publisher = acm,
	Title = {Proceedings of the 2003 ACM SIGPLAN Conference on Object-Oriented Programming Systems, Languages and Applications, OOPSLA 2003, October 26-30, 2003, Anaheim, CA, USA},
	Year = {2003}}

@inproceedings{DBLP:conf/oopsla/Cook92,
	Author = {William R. Cook},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Booktitle = {OOPSLA},
	Pages = {1-15},
	Title = {Interfaces and Specifications for the Smalltalk-80 Collection Classes},
	Year = {1992}}

@inproceedings{Bierman:2007:LTF:1297027.1297063,
	Author = {Bierman, Gavin M. and Meijer, Erik and Torgersen, Mads},
	Booktitle = oopsla,
	Date-Modified = {2012-03-29 10:40:24 +0200},
	Keywords = {C\#, LINQ},
	Noaddress = {New York, NY, USA},
	Noseries = {OOPSLA '07},
	Numpages = {20},
	Pages = {479--498},
	Publisher = acm,
	Title = {Lost in translation: formalizing proposed extensions to {C\#}},
	Year = {2007}}

@inproceedings{Meijer:2006:LRO:1142473.1142552,
	Author = {Meijer, Erik and Beckman, Brian and Bierman, Gavin},
	Booktitle = sigmod,
	Date-Modified = {2012-06-23 14:27:31 +0200},
	Keywords = {LINQ},
	Noaddress = {New York, NY, USA},
	Noseries = {SIGMOD '06},
	Numpages = {1},
	Pages = {706},
	Publisher = acm,
	Title = {{LINQ}: reconciling objects, relations and {XML} in the {.NET} framework},
	Year = {2006}}

@inproceedings{Leijen99DSEC,
	Acmid = {331977},
	Author = {Leijen, Daan and Meijer, Erik},
	Booktitle = dsl,
	Date-Added = {2012-03-26 02:43:28 +0200},
	Date-Modified = {2012-06-23 14:24:16 +0200},
	Keywords = {DSEL},
	Location = {Austin, Texas, United States},
	Noaddress = {Berkeley, CA, USA},
	Nodoi = {10.1145/331960.331977},
	Noisbn = {1-58113-255-7},
	Nopublisher = {USENIX Association},
	Noseries = {DSL '99},
	Nourl = {http://doi.acm.org/10.1145/331960.331977},
	Numpages = {14},
	Pages = {109--122},
	Publisher = acm,
	Title = {Domain specific embedded compilers},
	Year = {1999},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/331960.331977},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/331960.331977}}

@inproceedings{Grust:2009:FDP:1559845.1559982,
	Author = {Grust, Torsten and Mayr, Manuel and Rittinger, Jan and Schreiber, Tom},
	Booktitle = sigmod,
	Date-Modified = {2012-06-23 14:20:36 +0200},
	Keywords = {ferry, linq, pathfinder, sql1999},
	Noaddress = {New York, NY, USA},
	Noseries = {SIGMOD '09},
	Pages = {1063--1066},
	Publisher = acm,
	Title = {{FERRY}: database-supported program execution},
	Year = {2009}}

@article{JOT:issue_2010_07/article3,
	Author = {Miguel Garcia and Anastasia Izmaylova and Sibylle Schupp},
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Journal = {Journal of Object Technology},
	Keywords = {query constructs},
	Nomonth = jul,
	Number = {4},
	Pages = {45-68},
	Title = {Extending {Scala} with Database Query Capability},
	Volume = {9},
	Year = {2010}}

@inproceedings{Spiewak09scalaql:language-integrated,
	Author = {Daniel Spiewak and Tian Zhao},
	Booktitle = sle,
	Date-Modified = {2012-06-23 14:25:50 +0200},
	Keywords = {query constructs},
	Title = {{ScalaQL}: Language-integrated database queries for {Scala}},
	Year = {2009}}

@inproceedings{Wegrzynowicz:2009:GBU:1639950.1640032,
	Author = {W\c{e}grzynowicz, Patrycja and Stencel, Krzysztof},
	Booktitle = oopsla,
	Date-Modified = {2012-04-11 15:09:04 +0200},
	Location = {Orlando, Florida, USA},
	Noaddress = {New York, NY, USA},
	Noseries = {OOPSLA '09},
	Numpages = {2},
	Pages = {821--822},
	Publisher = acm,
	Title = {The good, the bad, and the ugly: three ways to use a semantic code query system},
	Year = {2009}}

@book{DBLP:books/mk/Muchnick1997,
	Author = {Steven S. Muchnick},
	Bibsource = {DBLP, http://dblp.uni-trier.de},
	Isbn = {1-55860-320-4},
	Publisher = {Morgan Kaufmann},
	Title = {Advanced Compiler Design and Implementation},
	Year = {1997}}

@techreport{Amadio94,
	Author = {Amadio, Roberto M. and Curien, Pierre-Lous},
	Institution = {Institut national de recherche en informatique et en automatique},
	Month = {March},
	Number = {161},
	Title = {Selected Domains and Lambda Calculi},
	Year = {1994}}

@inproceedings{Maier2013,
	Author = {Maier, Ingo and Odersky, Martin},
	Booktitle = ecoop,
	Nobooktitle = {ECOOP 2013 -- Object-Oriented Programming},
	Nodoi = {10.1007/978-3-642-39038-8_29},
	Noeditor = {Castagna, Giuseppe},
	Noisbn = {978-3-642-39037-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-39038-8_29},
	Novolume = {7920},
	Pages = {707-731},
	Publisher = Springer,
	Title = {Higher-Order Reactive Programming with Incremental Lists},
	Year = {2013}}

@inproceedings{Arvind13,
	Abstract = {Programmers who need high performance currently rely on low-level, architecture-specific programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Performance optimization with these frameworks usually requires expertise in the specific programming model and a deep understanding of the target architecture. Domain-specific languages (DSLs) are a promising alternative, allowing compilers to map problem-specific abstractions directly to low-level architecture-specific programming models. However, developing DSLs is difficult, and using multiple DSLs together in a single application is even harder because existing compiled solutions do not compose together. In this paper, we present four new performance-oriented DSLs developed with Delite, an extensible DSL compilation framework. We demonstrate new techniques to compose compiled DSLs embedded in a common backend together in a single program and show that generic optimizations can be applied across the different DSL sections. Our new DSLs are implemented with a small number of reusable components (less than 9 parallel operators total) and still achieve performance up to 125x better than library implementations and at worst within 30\% of optimized stand-alone DSLs. The DSLs retain good performance when composed together, and applying cross-DSL optimizations results in up to an additional 1.82x improvement.},
	Author = {Sujeeth, Arvind K. and Rompf, Tiark and Brown, Kevin J. and Lee, HyoukJoong and Chafi, Hassan and Popic, Victoria and Wu, Michael and Prokopec, Aleksandar and Jovanovic, Vojin and Odersky, Martin and Olukotun, Kunle},
	Booktitle = ecoop,
	Nobooktitle = {ECOOP 2013 -- Object-Oriented Programming},
	Nodoi = {10.1007/978-3-642-39038-8_3},
	Noeditor = {Castagna, Giuseppe},
	Noisbn = {978-3-642-39037-1},
	Nopublisher = {Springer Berlin Heidelberg},
	Noseries = {Lecture Notes in Computer Science},
	Nourl = {http://dx.doi.org/10.1007/978-3-642-39038-8_3},
	Novolume = {7920},
	Pages = {52-78},
	Publisher = Springer,
	Title = {Composition and Reuse with Compiled Domain-Specific Languages},
	Year = {2013}}

@book{Hott,
	Address = {Princeton},
	Author = {{The Univalent Foundations Program}},
	Publisher = {Institute for Advanced Study},
	Title = {Homotopy Type Theory: Univalent Foundations of Mathematics},
	Year = 2013}

@incollection{Hofmann96,
	Author = {Hofmann, Martin},
	Booktitle = {Types for Proofs and Programs},
	Nodoi = {10.1007/3-540-61780-9_68},
	Noeditor = {Berardi, Stefano and Coppo, Mario},
	Noisbn = {978-3-540-61780-8},
	Nopublisher = {Springer Berlin Heidelberg},
	Nourl = {http://dx.doi.org/10.1007/3-540-61780-9_68},
	Pages = {153-164},
	Publisher = Springer,
	Series = lncs,
	Title = {Conservativity of equality reflection over intensional type theory},
	Volume = {1158},
	Year = {1996},
	Bdsk-Url-1 = {http://dx.doi.org/10.1007/3-540-61780-9_68}}

@article{Lammel07,
	Author = {L\"{a}mmel, Ralf},
	Date-Modified = {2013-10-09 09:39:56 +0000},
	Issue_Date = {October, 2007},
	Journal = {Sci. Comput. Program.},
	Month = oct,
	Number = {3},
	Numpages = {30},
	Pages = {208--237},
	Publisher = {Elsevier North-Holland, Inc.},
	Title = {Google's {MapReduce} programming model --- Revisited},
	Volume = {68},
	Year = {2007}}

@inproceedings{Elliott:1997:FRA:258948.258973,
	Author = {Elliott, Conal and Hudak, Paul},
	Booktitle = icfp,
	Noaddress = {New York, NY, USA},
	Nobooktitle = {Proceedings of the second ACM SIGPLAN international conference on Functional programming},
	Noseries = {ICFP '97},
	Numpages = {11},
	Pages = {263--273},
	Publisher = acm,
	Title = {Functional reactive animation},
	Year = {1997}}

@misc{agda-head,
	Author = {{Agda Development Team}},
	Date-Modified = {2017-06-29 02:18:26 +0000},
	Howpublished = {\url{http://wiki.portal.chalmers.se/agda/}},
	Note = {Accessed on 2017-06-29.},
	Title = {{The Agda Wiki}},
	Year = {2013}}

@inproceedings{Rendel:2009:TS:1542476.1542509,
	Acmid = {1542509},
	Address = {New York, NY, USA},
	Author = {Rendel, Tillmann and Ostermann, Klaus and Hofer, Christian},
	Booktitle = {Proceedings of the 2009 ACM SIGPLAN Conference on Programming Language Design and Implementation},
	Doi = {10.1145/1542476.1542509},
	Isbn = {978-1-60558-392-1},
	Keywords = {lambda calculus, language design, reflection, self interpretation, types},
	Location = {Dublin, Ireland},
	Numpages = {11},
	Pages = {293--303},
	Publisher = {ACM},
	Series = {PLDI '09},
	Title = {Typed Self-representation},
	Url = {http://doi.acm.org/10.1145/1542476.1542509},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1542476.1542509},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1542476.1542509}}

@inproceedings{Hofer:2010:MDL:1868294.1868307,
	Acmid = {1868307},
	Address = {New York, NY, USA},
	Author = {Hofer, Christian and Ostermann, Klaus},
	Booktitle = {Proceedings of the Ninth International Conference on Generative Programming and Component Engineering},
	Doi = {10.1145/1868294.1868307},
	Isbn = {978-1-4503-0154-1},
	Keywords = {domain-specific languages, embedded languages, scala, term representation, visitor pattern},
	Location = {Eindhoven, The Netherlands},
	Numpages = {10},
	Pages = {83--92},
	Publisher = {ACM},
	Series = {GPCE '10},
	Title = {Modular Domain-specific Language Components in Scala},
	Url = {http://doi.acm.org/10.1145/1868294.1868307},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1868294.1868307},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1868294.1868307}}

@inproceedings{Cook_w.r.:remote,
	Author = {William R. Cook and Ben Wiedermann},
	Booktitle = {In: The 13th International Symposium on Database Programming Languages (DBPL)},
	Title = {Remote batch invocation for SQL databases},
	Year = {2011}}

@inproceedings{fan2012incremental,
	Author = {Fan, Wenfei and Li, Jianzhong and Tang, Nan and Yu, Wenyuan},
	Booktitle = {Data Engineering (ICDE), 2012 IEEE 28th International Conference on},
	Organization = {IEEE},
	Pages = {318--329},
	Title = {Incremental detection of inconsistencies in distributed data},
	Year = {2012}}

@article{sabry1993reasoning,
	Author = {Sabry, Amr and Felleisen, Matthias},
	Journal = {Lisp and symbolic computation},
	Number = {3-4},
	Pages = {289--360},
	Publisher = {Springer},
	Title = {Reasoning about programs in continuation-passing style},
	Volume = {6},
	Year = {1993}}

@inproceedings{Gabriel2012structure,
	Acmid = {2384611},
	Address = {New York, NY, USA},
	Author = {Gabriel, Richard P.},
	Booktitle = {Proceedings of the ACM International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
	Doi = {10.1145/2384592.2384611},
	Isbn = {978-1-4503-1562-3},
	Keywords = {engineering, incommensurability, paradigms, science},
	Location = {Tucson, Arizona, USA},
	Numpages = {20},
	Pages = {195--214},
	Publisher = {ACM},
	Series = {Onward! 2012},
	Title = {The Structure of a Programming Language Revolution},
	Url = {http://doi.acm.org/10.1145/2384592.2384611},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2384592.2384611},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2384592.2384611}}
